diff --git a/components/engine/daemon/logdrivers_linux.go b/components/engine/daemon/logdrivers_linux.go
index 67154a7..25d1684 100644
--- a/components/engine/daemon/logdrivers_linux.go
+++ b/components/engine/daemon/logdrivers_linux.go
@@ -3,14 +3,5 @@ package daemon // import "github.com/docker/docker/daemon"
 import (
 	// Importing packages here only to make sure their init gets called and
 	// therefore they register themselves to the logdriver factory.
-	_ "github.com/docker/docker/daemon/logger/awslogs"
-	_ "github.com/docker/docker/daemon/logger/fluentd"
-	_ "github.com/docker/docker/daemon/logger/gcplogs"
-	_ "github.com/docker/docker/daemon/logger/gelf"
-	_ "github.com/docker/docker/daemon/logger/journald"
-	_ "github.com/docker/docker/daemon/logger/jsonfilelog"
 	_ "github.com/docker/docker/daemon/logger/local"
-	_ "github.com/docker/docker/daemon/logger/logentries"
-	_ "github.com/docker/docker/daemon/logger/splunk"
-	_ "github.com/docker/docker/daemon/logger/syslog"
 )
diff --git a/components/engine/daemon/logger/awslogs/cloudwatchlogs.go b/components/engine/daemon/logger/awslogs/cloudwatchlogs.go
deleted file mode 100644
index f9cf1a9..0000000
--- a/components/engine/daemon/logger/awslogs/cloudwatchlogs.go
+++ /dev/null
@@ -1,865 +0,0 @@
-// Package awslogs provides the logdriver for forwarding container logs to Amazon CloudWatch Logs
-package awslogs // import "github.com/docker/docker/daemon/logger/awslogs"
-
-import (
-	"fmt"
-	"os"
-	"regexp"
-	"runtime"
-	"sort"
-	"strconv"
-	"strings"
-	"sync"
-	"time"
-	"unicode/utf8"
-
-	"github.com/aws/aws-sdk-go/aws"
-	"github.com/aws/aws-sdk-go/aws/awserr"
-	"github.com/aws/aws-sdk-go/aws/credentials/endpointcreds"
-	"github.com/aws/aws-sdk-go/aws/ec2metadata"
-	"github.com/aws/aws-sdk-go/aws/request"
-	"github.com/aws/aws-sdk-go/aws/session"
-	"github.com/aws/aws-sdk-go/service/cloudwatchlogs"
-	"github.com/docker/docker/daemon/logger"
-	"github.com/docker/docker/daemon/logger/loggerutils"
-	"github.com/docker/docker/dockerversion"
-	"github.com/pkg/errors"
-	"github.com/sirupsen/logrus"
-)
-
-const (
-	name                   = "awslogs"
-	regionKey              = "awslogs-region"
-	endpointKey            = "awslogs-endpoint"
-	regionEnvKey           = "AWS_REGION"
-	logGroupKey            = "awslogs-group"
-	logStreamKey           = "awslogs-stream"
-	logCreateGroupKey      = "awslogs-create-group"
-	tagKey                 = "tag"
-	datetimeFormatKey      = "awslogs-datetime-format"
-	multilinePatternKey    = "awslogs-multiline-pattern"
-	credentialsEndpointKey = "awslogs-credentials-endpoint"
-	forceFlushIntervalKey  = "awslogs-force-flush-interval-seconds"
-	maxBufferedEventsKey   = "awslogs-max-buffered-events"
-
-	defaultForceFlushInterval = 5 * time.Second
-	defaultMaxBufferedEvents  = 4096
-
-	// See: http://docs.aws.amazon.com/AmazonCloudWatchLogs/latest/APIReference/API_PutLogEvents.html
-	perEventBytes          = 26
-	maximumBytesPerPut     = 1048576
-	maximumLogEventsPerPut = 10000
-
-	// See: http://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/cloudwatch_limits.html
-	// Because the events are interpreted as UTF-8 encoded Unicode, invalid UTF-8 byte sequences are replaced with the
-	// Unicode replacement character (U+FFFD), which is a 3-byte sequence in UTF-8.  To compensate for that and to avoid
-	// splitting valid UTF-8 characters into invalid byte sequences, we calculate the length of each event assuming that
-	// this replacement happens.
-	maximumBytesPerEvent = 262144 - perEventBytes
-
-	resourceAlreadyExistsCode = "ResourceAlreadyExistsException"
-	dataAlreadyAcceptedCode   = "DataAlreadyAcceptedException"
-	invalidSequenceTokenCode  = "InvalidSequenceTokenException"
-	resourceNotFoundCode      = "ResourceNotFoundException"
-
-	credentialsEndpoint = "http://169.254.170.2"
-
-	userAgentHeader = "User-Agent"
-)
-
-type logStream struct {
-	logStreamName      string
-	logGroupName       string
-	logCreateGroup     bool
-	logNonBlocking     bool
-	forceFlushInterval time.Duration
-	multilinePattern   *regexp.Regexp
-	client             api
-	messages           chan *logger.Message
-	lock               sync.RWMutex
-	closed             bool
-	sequenceToken      *string
-}
-
-type logStreamConfig struct {
-	logStreamName      string
-	logGroupName       string
-	logCreateGroup     bool
-	logNonBlocking     bool
-	forceFlushInterval time.Duration
-	maxBufferedEvents  int
-	multilinePattern   *regexp.Regexp
-}
-
-var _ logger.SizedLogger = &logStream{}
-
-type api interface {
-	CreateLogGroup(*cloudwatchlogs.CreateLogGroupInput) (*cloudwatchlogs.CreateLogGroupOutput, error)
-	CreateLogStream(*cloudwatchlogs.CreateLogStreamInput) (*cloudwatchlogs.CreateLogStreamOutput, error)
-	PutLogEvents(*cloudwatchlogs.PutLogEventsInput) (*cloudwatchlogs.PutLogEventsOutput, error)
-}
-
-type regionFinder interface {
-	Region() (string, error)
-}
-
-type wrappedEvent struct {
-	inputLogEvent *cloudwatchlogs.InputLogEvent
-	insertOrder   int
-}
-type byTimestamp []wrappedEvent
-
-// init registers the awslogs driver
-func init() {
-	if err := logger.RegisterLogDriver(name, New); err != nil {
-		logrus.Fatal(err)
-	}
-	if err := logger.RegisterLogOptValidator(name, ValidateLogOpt); err != nil {
-		logrus.Fatal(err)
-	}
-}
-
-// eventBatch holds the events that are batched for submission and the
-// associated data about it.
-//
-// Warning: this type is not threadsafe and must not be used
-// concurrently. This type is expected to be consumed in a single go
-// routine and never concurrently.
-type eventBatch struct {
-	batch []wrappedEvent
-	bytes int
-}
-
-// New creates an awslogs logger using the configuration passed in on the
-// context.  Supported context configuration variables are awslogs-region,
-// awslogs-endpoint, awslogs-group, awslogs-stream, awslogs-create-group,
-// awslogs-multiline-pattern and awslogs-datetime-format.
-// When available, configuration is also taken from environment variables
-// AWS_REGION, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, the shared credentials
-// file (~/.aws/credentials), and the EC2 Instance Metadata Service.
-func New(info logger.Info) (logger.Logger, error) {
-	containerStreamConfig, err := newStreamConfig(info)
-	if err != nil {
-		return nil, err
-	}
-	client, err := newAWSLogsClient(info)
-	if err != nil {
-		return nil, err
-	}
-
-	containerStream := &logStream{
-		logStreamName:      containerStreamConfig.logStreamName,
-		logGroupName:       containerStreamConfig.logGroupName,
-		logCreateGroup:     containerStreamConfig.logCreateGroup,
-		logNonBlocking:     containerStreamConfig.logNonBlocking,
-		forceFlushInterval: containerStreamConfig.forceFlushInterval,
-		multilinePattern:   containerStreamConfig.multilinePattern,
-		client:             client,
-		messages:           make(chan *logger.Message, containerStreamConfig.maxBufferedEvents),
-	}
-
-	creationDone := make(chan bool)
-	if containerStream.logNonBlocking {
-		go func() {
-			backoff := 1
-			maxBackoff := 32
-			for {
-				// If logger is closed we are done
-				containerStream.lock.RLock()
-				if containerStream.closed {
-					containerStream.lock.RUnlock()
-					break
-				}
-				containerStream.lock.RUnlock()
-				err := containerStream.create()
-				if err == nil {
-					break
-				}
-
-				time.Sleep(time.Duration(backoff) * time.Second)
-				if backoff < maxBackoff {
-					backoff *= 2
-				}
-				logrus.
-					WithError(err).
-					WithField("container-id", info.ContainerID).
-					WithField("container-name", info.ContainerName).
-					Error("Error while trying to initialize awslogs. Retrying in: ", backoff, " seconds")
-			}
-			close(creationDone)
-		}()
-	} else {
-		if err = containerStream.create(); err != nil {
-			return nil, err
-		}
-		close(creationDone)
-	}
-	go containerStream.collectBatch(creationDone)
-
-	return containerStream, nil
-}
-
-// Parses most of the awslogs- options and prepares a config object to be used for newing the actual stream
-// It has been formed out to ease Utest of the New above
-func newStreamConfig(info logger.Info) (*logStreamConfig, error) {
-	logGroupName := info.Config[logGroupKey]
-	logStreamName, err := loggerutils.ParseLogTag(info, "{{.FullID}}")
-	if err != nil {
-		return nil, err
-	}
-	logCreateGroup := false
-	if info.Config[logCreateGroupKey] != "" {
-		logCreateGroup, err = strconv.ParseBool(info.Config[logCreateGroupKey])
-		if err != nil {
-			return nil, err
-		}
-	}
-
-	logNonBlocking := info.Config["mode"] == "non-blocking"
-
-	forceFlushInterval := defaultForceFlushInterval
-	if info.Config[forceFlushIntervalKey] != "" {
-		forceFlushIntervalAsInt, err := strconv.Atoi(info.Config[forceFlushIntervalKey])
-		if err != nil {
-			return nil, err
-		}
-		forceFlushInterval = time.Duration(forceFlushIntervalAsInt) * time.Second
-	}
-
-	maxBufferedEvents := int(defaultMaxBufferedEvents)
-	if info.Config[maxBufferedEventsKey] != "" {
-		maxBufferedEvents, err = strconv.Atoi(info.Config[maxBufferedEventsKey])
-		if err != nil {
-			return nil, err
-		}
-	}
-
-	if info.Config[logStreamKey] != "" {
-		logStreamName = info.Config[logStreamKey]
-	}
-
-	multilinePattern, err := parseMultilineOptions(info)
-	if err != nil {
-		return nil, err
-	}
-
-	containerStreamConfig := &logStreamConfig{
-		logStreamName:      logStreamName,
-		logGroupName:       logGroupName,
-		logCreateGroup:     logCreateGroup,
-		logNonBlocking:     logNonBlocking,
-		forceFlushInterval: forceFlushInterval,
-		maxBufferedEvents:  maxBufferedEvents,
-		multilinePattern:   multilinePattern,
-	}
-
-	return containerStreamConfig, nil
-}
-
-// Parses awslogs-multiline-pattern and awslogs-datetime-format options
-// If awslogs-datetime-format is present, convert the format from strftime
-// to regexp and return.
-// If awslogs-multiline-pattern is present, compile regexp and return
-func parseMultilineOptions(info logger.Info) (*regexp.Regexp, error) {
-	dateTimeFormat := info.Config[datetimeFormatKey]
-	multilinePatternKey := info.Config[multilinePatternKey]
-	// strftime input is parsed into a regular expression
-	if dateTimeFormat != "" {
-		// %. matches each strftime format sequence and ReplaceAllStringFunc
-		// looks up each format sequence in the conversion table strftimeToRegex
-		// to replace with a defined regular expression
-		r := regexp.MustCompile("%.")
-		multilinePatternKey = r.ReplaceAllStringFunc(dateTimeFormat, func(s string) string {
-			return strftimeToRegex[s]
-		})
-	}
-	if multilinePatternKey != "" {
-		multilinePattern, err := regexp.Compile(multilinePatternKey)
-		if err != nil {
-			return nil, errors.Wrapf(err, "awslogs could not parse multiline pattern key %q", multilinePatternKey)
-		}
-		return multilinePattern, nil
-	}
-	return nil, nil
-}
-
-// Maps strftime format strings to regex
-var strftimeToRegex = map[string]string{
-	/*weekdayShort          */ `%a`: `(?:Mon|Tue|Wed|Thu|Fri|Sat|Sun)`,
-	/*weekdayFull           */ `%A`: `(?:Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday)`,
-	/*weekdayZeroIndex      */ `%w`: `[0-6]`,
-	/*dayZeroPadded         */ `%d`: `(?:0[1-9]|[1,2][0-9]|3[0,1])`,
-	/*monthShort            */ `%b`: `(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)`,
-	/*monthFull             */ `%B`: `(?:January|February|March|April|May|June|July|August|September|October|November|December)`,
-	/*monthZeroPadded       */ `%m`: `(?:0[1-9]|1[0-2])`,
-	/*yearCentury           */ `%Y`: `\d{4}`,
-	/*yearZeroPadded        */ `%y`: `\d{2}`,
-	/*hour24ZeroPadded      */ `%H`: `(?:[0,1][0-9]|2[0-3])`,
-	/*hour12ZeroPadded      */ `%I`: `(?:0[0-9]|1[0-2])`,
-	/*AM or PM              */ `%p`: "[A,P]M",
-	/*minuteZeroPadded      */ `%M`: `[0-5][0-9]`,
-	/*secondZeroPadded      */ `%S`: `[0-5][0-9]`,
-	/*microsecondZeroPadded */ `%f`: `\d{6}`,
-	/*utcOffset             */ `%z`: `[+-]\d{4}`,
-	/*tzName                */ `%Z`: `[A-Z]{1,4}T`,
-	/*dayOfYearZeroPadded   */ `%j`: `(?:0[0-9][1-9]|[1,2][0-9][0-9]|3[0-5][0-9]|36[0-6])`,
-	/*milliseconds          */ `%L`: `\.\d{3}`,
-}
-
-// newRegionFinder is a variable such that the implementation
-// can be swapped out for unit tests.
-var newRegionFinder = func() regionFinder {
-	return ec2metadata.New(session.New())
-}
-
-// newSDKEndpoint is a variable such that the implementation
-// can be swapped out for unit tests.
-var newSDKEndpoint = credentialsEndpoint
-
-// newAWSLogsClient creates the service client for Amazon CloudWatch Logs.
-// Customizations to the default client from the SDK include a Docker-specific
-// User-Agent string and automatic region detection using the EC2 Instance
-// Metadata Service when region is otherwise unspecified.
-func newAWSLogsClient(info logger.Info) (api, error) {
-	var region, endpoint *string
-	if os.Getenv(regionEnvKey) != "" {
-		region = aws.String(os.Getenv(regionEnvKey))
-	}
-	if info.Config[regionKey] != "" {
-		region = aws.String(info.Config[regionKey])
-	}
-	if info.Config[endpointKey] != "" {
-		endpoint = aws.String(info.Config[endpointKey])
-	}
-	if region == nil || *region == "" {
-		logrus.Info("Trying to get region from EC2 Metadata")
-		ec2MetadataClient := newRegionFinder()
-		r, err := ec2MetadataClient.Region()
-		if err != nil {
-			logrus.WithFields(logrus.Fields{
-				"error": err,
-			}).Error("Could not get region from EC2 metadata, environment, or log option")
-			return nil, errors.New("Cannot determine region for awslogs driver")
-		}
-		region = &r
-	}
-
-	sess, err := session.NewSession()
-	if err != nil {
-		return nil, errors.New("Failed to create a service client session for awslogs driver")
-	}
-
-	// attach region to cloudwatchlogs config
-	sess.Config.Region = region
-
-	// attach endpoint to cloudwatchlogs config
-	if endpoint != nil {
-		sess.Config.Endpoint = endpoint
-	}
-
-	if uri, ok := info.Config[credentialsEndpointKey]; ok {
-		logrus.Debugf("Trying to get credentials from awslogs-credentials-endpoint")
-
-		endpoint := fmt.Sprintf("%s%s", newSDKEndpoint, uri)
-		creds := endpointcreds.NewCredentialsClient(*sess.Config, sess.Handlers, endpoint,
-			func(p *endpointcreds.Provider) {
-				p.ExpiryWindow = 5 * time.Minute
-			})
-
-		// attach credentials to cloudwatchlogs config
-		sess.Config.Credentials = creds
-	}
-
-	logrus.WithFields(logrus.Fields{
-		"region": *region,
-	}).Debug("Created awslogs client")
-
-	client := cloudwatchlogs.New(sess)
-
-	client.Handlers.Build.PushBackNamed(request.NamedHandler{
-		Name: "DockerUserAgentHandler",
-		Fn: func(r *request.Request) {
-			currentAgent := r.HTTPRequest.Header.Get(userAgentHeader)
-			r.HTTPRequest.Header.Set(userAgentHeader,
-				fmt.Sprintf("Docker %s (%s) %s",
-					dockerversion.Version, runtime.GOOS, currentAgent))
-		},
-	})
-	return client, nil
-}
-
-// Name returns the name of the awslogs logging driver
-func (l *logStream) Name() string {
-	return name
-}
-
-func (l *logStream) BufSize() int {
-	return maximumBytesPerEvent
-}
-
-// Log submits messages for logging by an instance of the awslogs logging driver
-func (l *logStream) Log(msg *logger.Message) error {
-	l.lock.RLock()
-	defer l.lock.RUnlock()
-	if l.closed {
-		return errors.New("awslogs is closed")
-	}
-	if l.logNonBlocking {
-		select {
-		case l.messages <- msg:
-			return nil
-		default:
-			return errors.New("awslogs buffer is full")
-		}
-	}
-	l.messages <- msg
-	return nil
-}
-
-// Close closes the instance of the awslogs logging driver
-func (l *logStream) Close() error {
-	l.lock.Lock()
-	defer l.lock.Unlock()
-	if !l.closed {
-		close(l.messages)
-	}
-	l.closed = true
-	return nil
-}
-
-// create creates log group and log stream for the instance of the awslogs logging driver
-func (l *logStream) create() error {
-	if err := l.createLogStream(); err != nil {
-		if l.logCreateGroup {
-			if awsErr, ok := err.(awserr.Error); ok && awsErr.Code() == resourceNotFoundCode {
-				if err := l.createLogGroup(); err != nil {
-					return errors.Wrap(err, "failed to create Cloudwatch log group")
-				}
-				err := l.createLogStream()
-				if err != nil {
-					return errors.Wrap(err, "failed to create Cloudwatch log stream")
-				}
-				return nil
-			}
-		}
-		if err != nil {
-			return errors.Wrap(err, "failed to create Cloudwatch log stream")
-		}
-	}
-
-	return nil
-}
-
-// createLogGroup creates a log group for the instance of the awslogs logging driver
-func (l *logStream) createLogGroup() error {
-	if _, err := l.client.CreateLogGroup(&cloudwatchlogs.CreateLogGroupInput{
-		LogGroupName: aws.String(l.logGroupName),
-	}); err != nil {
-		if awsErr, ok := err.(awserr.Error); ok {
-			fields := logrus.Fields{
-				"errorCode":      awsErr.Code(),
-				"message":        awsErr.Message(),
-				"origError":      awsErr.OrigErr(),
-				"logGroupName":   l.logGroupName,
-				"logCreateGroup": l.logCreateGroup,
-			}
-			if awsErr.Code() == resourceAlreadyExistsCode {
-				// Allow creation to succeed
-				logrus.WithFields(fields).Info("Log group already exists")
-				return nil
-			}
-			logrus.WithFields(fields).Error("Failed to create log group")
-		}
-		return err
-	}
-	return nil
-}
-
-// createLogStream creates a log stream for the instance of the awslogs logging driver
-func (l *logStream) createLogStream() error {
-	input := &cloudwatchlogs.CreateLogStreamInput{
-		LogGroupName:  aws.String(l.logGroupName),
-		LogStreamName: aws.String(l.logStreamName),
-	}
-
-	_, err := l.client.CreateLogStream(input)
-
-	if err != nil {
-		if awsErr, ok := err.(awserr.Error); ok {
-			fields := logrus.Fields{
-				"errorCode":     awsErr.Code(),
-				"message":       awsErr.Message(),
-				"origError":     awsErr.OrigErr(),
-				"logGroupName":  l.logGroupName,
-				"logStreamName": l.logStreamName,
-			}
-			if awsErr.Code() == resourceAlreadyExistsCode {
-				// Allow creation to succeed
-				logrus.WithFields(fields).Info("Log stream already exists")
-				return nil
-			}
-			logrus.WithFields(fields).Error("Failed to create log stream")
-		}
-	}
-	return err
-}
-
-// newTicker is used for time-based batching.  newTicker is a variable such
-// that the implementation can be swapped out for unit tests.
-var newTicker = func(freq time.Duration) *time.Ticker {
-	return time.NewTicker(freq)
-}
-
-// collectBatch executes as a goroutine to perform batching of log events for
-// submission to the log stream.  If the awslogs-multiline-pattern or
-// awslogs-datetime-format options have been configured, multiline processing
-// is enabled, where log messages are stored in an event buffer until a multiline
-// pattern match is found, at which point the messages in the event buffer are
-// pushed to CloudWatch logs as a single log event.  Multiline messages are processed
-// according to the maximumBytesPerPut constraint, and the implementation only
-// allows for messages to be buffered for a maximum of 2*batchPublishFrequency
-// seconds.  When events are ready to be processed for submission to CloudWatch
-// Logs, the processEvents method is called.  If a multiline pattern is not
-// configured, log events are submitted to the processEvents method immediately.
-func (l *logStream) collectBatch(created chan bool) {
-	// Wait for the logstream/group to be created
-	<-created
-	flushInterval := l.forceFlushInterval
-	if flushInterval <= 0 {
-		flushInterval = defaultForceFlushInterval
-	}
-	ticker := newTicker(flushInterval)
-	var eventBuffer []byte
-	var eventBufferTimestamp int64
-	var batch = newEventBatch()
-	for {
-		select {
-		case t := <-ticker.C:
-			// If event buffer is older than batch publish frequency flush the event buffer
-			if eventBufferTimestamp > 0 && len(eventBuffer) > 0 {
-				eventBufferAge := t.UnixNano()/int64(time.Millisecond) - eventBufferTimestamp
-				eventBufferExpired := eventBufferAge >= int64(flushInterval)/int64(time.Millisecond)
-				eventBufferNegative := eventBufferAge < 0
-				if eventBufferExpired || eventBufferNegative {
-					l.processEvent(batch, eventBuffer, eventBufferTimestamp)
-					eventBuffer = eventBuffer[:0]
-				}
-			}
-			l.publishBatch(batch)
-			batch.reset()
-		case msg, more := <-l.messages:
-			if !more {
-				// Flush event buffer and release resources
-				l.processEvent(batch, eventBuffer, eventBufferTimestamp)
-				eventBuffer = eventBuffer[:0]
-				l.publishBatch(batch)
-				batch.reset()
-				return
-			}
-			if eventBufferTimestamp == 0 {
-				eventBufferTimestamp = msg.Timestamp.UnixNano() / int64(time.Millisecond)
-			}
-			line := msg.Line
-			if l.multilinePattern != nil {
-				lineEffectiveLen := effectiveLen(string(line))
-				if l.multilinePattern.Match(line) || effectiveLen(string(eventBuffer))+lineEffectiveLen > maximumBytesPerEvent {
-					// This is a new log event or we will exceed max bytes per event
-					// so flush the current eventBuffer to events and reset timestamp
-					l.processEvent(batch, eventBuffer, eventBufferTimestamp)
-					eventBufferTimestamp = msg.Timestamp.UnixNano() / int64(time.Millisecond)
-					eventBuffer = eventBuffer[:0]
-				}
-				// Append newline if event is less than max event size
-				if lineEffectiveLen < maximumBytesPerEvent {
-					line = append(line, "\n"...)
-				}
-				eventBuffer = append(eventBuffer, line...)
-				logger.PutMessage(msg)
-			} else {
-				l.processEvent(batch, line, msg.Timestamp.UnixNano()/int64(time.Millisecond))
-				logger.PutMessage(msg)
-			}
-		}
-	}
-}
-
-// processEvent processes log events that are ready for submission to CloudWatch
-// logs.  Batching is performed on time- and size-bases.  Time-based batching
-// occurs at a 5 second interval (defined in the batchPublishFrequency const).
-// Size-based batching is performed on the maximum number of events per batch
-// (defined in maximumLogEventsPerPut) and the maximum number of total bytes in a
-// batch (defined in maximumBytesPerPut).  Log messages are split by the maximum
-// bytes per event (defined in maximumBytesPerEvent).  There is a fixed per-event
-// byte overhead (defined in perEventBytes) which is accounted for in split- and
-// batch-calculations.  Because the events are interpreted as UTF-8 encoded
-// Unicode, invalid UTF-8 byte sequences are replaced with the Unicode
-// replacement character (U+FFFD), which is a 3-byte sequence in UTF-8.  To
-// compensate for that and to avoid splitting valid UTF-8 characters into
-// invalid byte sequences, we calculate the length of each event assuming that
-// this replacement happens.
-func (l *logStream) processEvent(batch *eventBatch, bytes []byte, timestamp int64) {
-	for len(bytes) > 0 {
-		// Split line length so it does not exceed the maximum
-		splitOffset, lineBytes := findValidSplit(string(bytes), maximumBytesPerEvent)
-		line := bytes[:splitOffset]
-		event := wrappedEvent{
-			inputLogEvent: &cloudwatchlogs.InputLogEvent{
-				Message:   aws.String(string(line)),
-				Timestamp: aws.Int64(timestamp),
-			},
-			insertOrder: batch.count(),
-		}
-
-		added := batch.add(event, lineBytes)
-		if added {
-			bytes = bytes[splitOffset:]
-		} else {
-			l.publishBatch(batch)
-			batch.reset()
-		}
-	}
-}
-
-// effectiveLen counts the effective number of bytes in the string, after
-// UTF-8 normalization.  UTF-8 normalization includes replacing bytes that do
-// not constitute valid UTF-8 encoded Unicode codepoints with the Unicode
-// replacement codepoint U+FFFD (a 3-byte UTF-8 sequence, represented in Go as
-// utf8.RuneError)
-func effectiveLen(line string) int {
-	effectiveBytes := 0
-	for _, rune := range line {
-		effectiveBytes += utf8.RuneLen(rune)
-	}
-	return effectiveBytes
-}
-
-// findValidSplit finds the byte offset to split a string without breaking valid
-// Unicode codepoints given a maximum number of total bytes.  findValidSplit
-// returns the byte offset for splitting a string or []byte, as well as the
-// effective number of bytes if the string were normalized to replace invalid
-// UTF-8 encoded bytes with the Unicode replacement character (a 3-byte UTF-8
-// sequence, represented in Go as utf8.RuneError)
-func findValidSplit(line string, maxBytes int) (splitOffset, effectiveBytes int) {
-	for offset, rune := range line {
-		splitOffset = offset
-		if effectiveBytes+utf8.RuneLen(rune) > maxBytes {
-			return splitOffset, effectiveBytes
-		}
-		effectiveBytes += utf8.RuneLen(rune)
-	}
-	splitOffset = len(line)
-	return
-}
-
-// publishBatch calls PutLogEvents for a given set of InputLogEvents,
-// accounting for sequencing requirements (each request must reference the
-// sequence token returned by the previous request).
-func (l *logStream) publishBatch(batch *eventBatch) {
-	if batch.isEmpty() {
-		return
-	}
-	cwEvents := unwrapEvents(batch.events())
-
-	nextSequenceToken, err := l.putLogEvents(cwEvents, l.sequenceToken)
-
-	if err != nil {
-		if awsErr, ok := err.(awserr.Error); ok {
-			if awsErr.Code() == dataAlreadyAcceptedCode {
-				// already submitted, just grab the correct sequence token
-				parts := strings.Split(awsErr.Message(), " ")
-				nextSequenceToken = &parts[len(parts)-1]
-				logrus.WithFields(logrus.Fields{
-					"errorCode":     awsErr.Code(),
-					"message":       awsErr.Message(),
-					"logGroupName":  l.logGroupName,
-					"logStreamName": l.logStreamName,
-				}).Info("Data already accepted, ignoring error")
-				err = nil
-			} else if awsErr.Code() == invalidSequenceTokenCode {
-				// sequence code is bad, grab the correct one and retry
-				parts := strings.Split(awsErr.Message(), " ")
-				token := parts[len(parts)-1]
-				nextSequenceToken, err = l.putLogEvents(cwEvents, &token)
-			}
-		}
-	}
-	if err != nil {
-		logrus.Error(err)
-	} else {
-		l.sequenceToken = nextSequenceToken
-	}
-}
-
-// putLogEvents wraps the PutLogEvents API
-func (l *logStream) putLogEvents(events []*cloudwatchlogs.InputLogEvent, sequenceToken *string) (*string, error) {
-	input := &cloudwatchlogs.PutLogEventsInput{
-		LogEvents:     events,
-		SequenceToken: sequenceToken,
-		LogGroupName:  aws.String(l.logGroupName),
-		LogStreamName: aws.String(l.logStreamName),
-	}
-	resp, err := l.client.PutLogEvents(input)
-	if err != nil {
-		if awsErr, ok := err.(awserr.Error); ok {
-			logrus.WithFields(logrus.Fields{
-				"errorCode":     awsErr.Code(),
-				"message":       awsErr.Message(),
-				"origError":     awsErr.OrigErr(),
-				"logGroupName":  l.logGroupName,
-				"logStreamName": l.logStreamName,
-			}).Error("Failed to put log events")
-		}
-		return nil, err
-	}
-	return resp.NextSequenceToken, nil
-}
-
-// ValidateLogOpt looks for awslogs-specific log options awslogs-region, awslogs-endpoint
-// awslogs-group, awslogs-stream, awslogs-create-group, awslogs-datetime-format,
-// awslogs-multiline-pattern
-func ValidateLogOpt(cfg map[string]string) error {
-	for key := range cfg {
-		switch key {
-		case logGroupKey:
-		case logStreamKey:
-		case logCreateGroupKey:
-		case regionKey:
-		case endpointKey:
-		case tagKey:
-		case datetimeFormatKey:
-		case multilinePatternKey:
-		case credentialsEndpointKey:
-		case forceFlushIntervalKey:
-		case maxBufferedEventsKey:
-		default:
-			return fmt.Errorf("unknown log opt '%s' for %s log driver", key, name)
-		}
-	}
-	if cfg[logGroupKey] == "" {
-		return fmt.Errorf("must specify a value for log opt '%s'", logGroupKey)
-	}
-	if cfg[logCreateGroupKey] != "" {
-		if _, err := strconv.ParseBool(cfg[logCreateGroupKey]); err != nil {
-			return fmt.Errorf("must specify valid value for log opt '%s': %v", logCreateGroupKey, err)
-		}
-	}
-	if cfg[forceFlushIntervalKey] != "" {
-		if value, err := strconv.Atoi(cfg[forceFlushIntervalKey]); err != nil || value <= 0 {
-			return fmt.Errorf("must specify a positive integer for log opt '%s': %v", forceFlushIntervalKey, cfg[forceFlushIntervalKey])
-		}
-	}
-	if cfg[maxBufferedEventsKey] != "" {
-		if value, err := strconv.Atoi(cfg[maxBufferedEventsKey]); err != nil || value <= 0 {
-			return fmt.Errorf("must specify a positive integer for log opt '%s': %v", maxBufferedEventsKey, cfg[maxBufferedEventsKey])
-		}
-	}
-	_, datetimeFormatKeyExists := cfg[datetimeFormatKey]
-	_, multilinePatternKeyExists := cfg[multilinePatternKey]
-	if datetimeFormatKeyExists && multilinePatternKeyExists {
-		return fmt.Errorf("you cannot configure log opt '%s' and '%s' at the same time", datetimeFormatKey, multilinePatternKey)
-	}
-	return nil
-}
-
-// Len returns the length of a byTimestamp slice.  Len is required by the
-// sort.Interface interface.
-func (slice byTimestamp) Len() int {
-	return len(slice)
-}
-
-// Less compares two values in a byTimestamp slice by Timestamp.  Less is
-// required by the sort.Interface interface.
-func (slice byTimestamp) Less(i, j int) bool {
-	iTimestamp, jTimestamp := int64(0), int64(0)
-	if slice != nil && slice[i].inputLogEvent.Timestamp != nil {
-		iTimestamp = *slice[i].inputLogEvent.Timestamp
-	}
-	if slice != nil && slice[j].inputLogEvent.Timestamp != nil {
-		jTimestamp = *slice[j].inputLogEvent.Timestamp
-	}
-	if iTimestamp == jTimestamp {
-		return slice[i].insertOrder < slice[j].insertOrder
-	}
-	return iTimestamp < jTimestamp
-}
-
-// Swap swaps two values in a byTimestamp slice with each other.  Swap is
-// required by the sort.Interface interface.
-func (slice byTimestamp) Swap(i, j int) {
-	slice[i], slice[j] = slice[j], slice[i]
-}
-
-func unwrapEvents(events []wrappedEvent) []*cloudwatchlogs.InputLogEvent {
-	cwEvents := make([]*cloudwatchlogs.InputLogEvent, len(events))
-	for i, input := range events {
-		cwEvents[i] = input.inputLogEvent
-	}
-	return cwEvents
-}
-
-func newEventBatch() *eventBatch {
-	return &eventBatch{
-		batch: make([]wrappedEvent, 0),
-		bytes: 0,
-	}
-}
-
-// events returns a slice of wrappedEvents sorted in order of their
-// timestamps and then by their insertion order (see `byTimestamp`).
-//
-// Warning: this method is not threadsafe and must not be used
-// concurrently.
-func (b *eventBatch) events() []wrappedEvent {
-	sort.Sort(byTimestamp(b.batch))
-	return b.batch
-}
-
-// add adds an event to the batch of events accounting for the
-// necessary overhead for an event to be logged. An error will be
-// returned if the event cannot be added to the batch due to service
-// limits.
-//
-// Warning: this method is not threadsafe and must not be used
-// concurrently.
-func (b *eventBatch) add(event wrappedEvent, size int) bool {
-	addBytes := size + perEventBytes
-
-	// verify we are still within service limits
-	switch {
-	case len(b.batch)+1 > maximumLogEventsPerPut:
-		return false
-	case b.bytes+addBytes > maximumBytesPerPut:
-		return false
-	}
-
-	b.bytes += addBytes
-	b.batch = append(b.batch, event)
-
-	return true
-}
-
-// count is the number of batched events.  Warning: this method
-// is not threadsafe and must not be used concurrently.
-func (b *eventBatch) count() int {
-	return len(b.batch)
-}
-
-// size is the total number of bytes that the batch represents.
-//
-// Warning: this method is not threadsafe and must not be used
-// concurrently.
-func (b *eventBatch) size() int {
-	return b.bytes
-}
-
-func (b *eventBatch) isEmpty() bool {
-	zeroEvents := b.count() == 0
-	zeroSize := b.size() == 0
-	return zeroEvents && zeroSize
-}
-
-// reset prepares the batch for reuse.
-func (b *eventBatch) reset() {
-	b.bytes = 0
-	b.batch = b.batch[:0]
-}
diff --git a/components/engine/daemon/logger/awslogs/cloudwatchlogs_test.go b/components/engine/daemon/logger/awslogs/cloudwatchlogs_test.go
deleted file mode 100644
index 1a32f88..0000000
--- a/components/engine/daemon/logger/awslogs/cloudwatchlogs_test.go
+++ /dev/null
@@ -1,1702 +0,0 @@
-package awslogs // import "github.com/docker/docker/daemon/logger/awslogs"
-
-import (
-	"errors"
-	"fmt"
-	"io/ioutil"
-	"net/http"
-	"net/http/httptest"
-	"os"
-	"reflect"
-	"regexp"
-	"runtime"
-	"strconv"
-	"strings"
-	"testing"
-	"time"
-
-	"github.com/aws/aws-sdk-go/aws"
-	"github.com/aws/aws-sdk-go/aws/awserr"
-	"github.com/aws/aws-sdk-go/aws/request"
-	"github.com/aws/aws-sdk-go/service/cloudwatchlogs"
-	"github.com/docker/docker/daemon/logger"
-	"github.com/docker/docker/daemon/logger/loggerutils"
-	"github.com/docker/docker/dockerversion"
-	"gotest.tools/assert"
-	is "gotest.tools/assert/cmp"
-)
-
-const (
-	groupName         = "groupName"
-	streamName        = "streamName"
-	sequenceToken     = "sequenceToken"
-	nextSequenceToken = "nextSequenceToken"
-	logline           = "this is a log line\r"
-	multilineLogline  = "2017-01-01 01:01:44 This is a multiline log entry\r"
-)
-
-// Generates i multi-line events each with j lines
-func (l *logStream) logGenerator(lineCount int, multilineCount int) {
-	for i := 0; i < multilineCount; i++ {
-		l.Log(&logger.Message{
-			Line:      []byte(multilineLogline),
-			Timestamp: time.Time{},
-		})
-		for j := 0; j < lineCount; j++ {
-			l.Log(&logger.Message{
-				Line:      []byte(logline),
-				Timestamp: time.Time{},
-			})
-		}
-	}
-}
-
-func testEventBatch(events []wrappedEvent) *eventBatch {
-	batch := newEventBatch()
-	for _, event := range events {
-		eventlen := len([]byte(*event.inputLogEvent.Message))
-		batch.add(event, eventlen)
-	}
-	return batch
-}
-
-func TestNewStreamConfig(t *testing.T) {
-	tests := []struct {
-		logStreamName      string
-		logGroupName       string
-		logCreateGroup     string
-		logNonBlocking     string
-		forceFlushInterval string
-		maxBufferedEvents  string
-		datetimeFormat     string
-		multilinePattern   string
-		shouldErr          bool
-		testName           string
-	}{
-		{"", groupName, "", "", "", "", "", "", false, "defaults"},
-		{"", groupName, "invalid create group", "", "", "", "", "", true, "invalid create group"},
-		{"", groupName, "", "", "invalid flush interval", "", "", "", true, "invalid flush interval"},
-		{"", groupName, "", "", "", "invalid max buffered events", "", "", true, "invalid max buffered events"},
-		{"", groupName, "", "", "", "", "", "n{1001}", true, "invalid multiline pattern"},
-		{"", groupName, "", "", "15", "", "", "", false, "flush interval at 15"},
-		{"", groupName, "", "", "", "1024", "", "", false, "max buffered events at 1024"},
-	}
-
-	for _, tc := range tests {
-		t.Run(tc.testName, func(t *testing.T) {
-			cfg := map[string]string{
-				logGroupKey:           tc.logGroupName,
-				logCreateGroupKey:     tc.logCreateGroup,
-				"mode":                tc.logNonBlocking,
-				forceFlushIntervalKey: tc.forceFlushInterval,
-				maxBufferedEventsKey:  tc.maxBufferedEvents,
-				logStreamKey:          tc.logStreamName,
-				datetimeFormatKey:     tc.datetimeFormat,
-				multilinePatternKey:   tc.multilinePattern,
-			}
-
-			info := logger.Info{
-				Config: cfg,
-			}
-			logStreamConfig, err := newStreamConfig(info)
-			if tc.shouldErr {
-				assert.Check(t, err != nil, "Expected an error")
-			} else {
-				assert.Check(t, err == nil, "Unexpected error")
-				assert.Check(t, logStreamConfig.logGroupName == tc.logGroupName, "Unexpected logGroupName")
-				if tc.forceFlushInterval != "" {
-					forceFlushIntervalAsInt, _ := strconv.Atoi(info.Config[forceFlushIntervalKey])
-					assert.Check(t, logStreamConfig.forceFlushInterval == time.Duration(forceFlushIntervalAsInt)*time.Second, "Unexpected forceFlushInterval")
-				}
-				if tc.maxBufferedEvents != "" {
-					maxBufferedEvents, _ := strconv.Atoi(info.Config[maxBufferedEventsKey])
-					assert.Check(t, logStreamConfig.maxBufferedEvents == maxBufferedEvents, "Unexpected maxBufferedEvents")
-				}
-			}
-		})
-	}
-}
-
-func TestNewAWSLogsClientUserAgentHandler(t *testing.T) {
-	info := logger.Info{
-		Config: map[string]string{
-			regionKey: "us-east-1",
-		},
-	}
-
-	client, err := newAWSLogsClient(info)
-	assert.NilError(t, err)
-
-	realClient, ok := client.(*cloudwatchlogs.CloudWatchLogs)
-	assert.Check(t, ok, "Could not cast client to cloudwatchlogs.CloudWatchLogs")
-
-	buildHandlerList := realClient.Handlers.Build
-	request := &request.Request{
-		HTTPRequest: &http.Request{
-			Header: http.Header{},
-		},
-	}
-	buildHandlerList.Run(request)
-	expectedUserAgentString := fmt.Sprintf("Docker %s (%s) %s/%s (%s; %s; %s)",
-		dockerversion.Version, runtime.GOOS, aws.SDKName, aws.SDKVersion, runtime.Version(), runtime.GOOS, runtime.GOARCH)
-	userAgent := request.HTTPRequest.Header.Get("User-Agent")
-	if userAgent != expectedUserAgentString {
-		t.Errorf("Wrong User-Agent string, expected \"%s\" but was \"%s\"",
-			expectedUserAgentString, userAgent)
-	}
-}
-
-func TestNewAWSLogsClientAWSLogsEndpoint(t *testing.T) {
-	endpoint := "mock-endpoint"
-	info := logger.Info{
-		Config: map[string]string{
-			regionKey:   "us-east-1",
-			endpointKey: endpoint,
-		},
-	}
-
-	client, err := newAWSLogsClient(info)
-	assert.NilError(t, err)
-
-	realClient, ok := client.(*cloudwatchlogs.CloudWatchLogs)
-	assert.Check(t, ok, "Could not cast client to cloudwatchlogs.CloudWatchLogs")
-
-	endpointWithScheme := realClient.Endpoint
-	expectedEndpointWithScheme := "https://" + endpoint
-	assert.Equal(t, endpointWithScheme, expectedEndpointWithScheme, "Wrong endpoint")
-}
-
-func TestNewAWSLogsClientRegionDetect(t *testing.T) {
-	info := logger.Info{
-		Config: map[string]string{},
-	}
-
-	mockMetadata := newMockMetadataClient()
-	newRegionFinder = func() regionFinder {
-		return mockMetadata
-	}
-	mockMetadata.regionResult <- &regionResult{
-		successResult: "us-east-1",
-	}
-
-	_, err := newAWSLogsClient(info)
-	assert.NilError(t, err)
-}
-
-func TestCreateSuccess(t *testing.T) {
-	mockClient := newMockClient()
-	stream := &logStream{
-		client:        mockClient,
-		logGroupName:  groupName,
-		logStreamName: streamName,
-	}
-	mockClient.createLogStreamResult <- &createLogStreamResult{}
-
-	err := stream.create()
-
-	if err != nil {
-		t.Errorf("Received unexpected err: %v\n", err)
-	}
-	argument := <-mockClient.createLogStreamArgument
-	if argument.LogGroupName == nil {
-		t.Fatal("Expected non-nil LogGroupName")
-	}
-	if *argument.LogGroupName != groupName {
-		t.Errorf("Expected LogGroupName to be %s", groupName)
-	}
-	if argument.LogStreamName == nil {
-		t.Fatal("Expected non-nil LogStreamName")
-	}
-	if *argument.LogStreamName != streamName {
-		t.Errorf("Expected LogStreamName to be %s", streamName)
-	}
-}
-
-func TestCreateLogGroupSuccess(t *testing.T) {
-	mockClient := newMockClient()
-	stream := &logStream{
-		client:         mockClient,
-		logGroupName:   groupName,
-		logStreamName:  streamName,
-		logCreateGroup: true,
-	}
-	mockClient.createLogGroupResult <- &createLogGroupResult{}
-	mockClient.createLogStreamResult <- &createLogStreamResult{}
-
-	err := stream.create()
-
-	if err != nil {
-		t.Errorf("Received unexpected err: %v\n", err)
-	}
-	argument := <-mockClient.createLogStreamArgument
-	if argument.LogGroupName == nil {
-		t.Fatal("Expected non-nil LogGroupName")
-	}
-	if *argument.LogGroupName != groupName {
-		t.Errorf("Expected LogGroupName to be %s", groupName)
-	}
-	if argument.LogStreamName == nil {
-		t.Fatal("Expected non-nil LogStreamName")
-	}
-	if *argument.LogStreamName != streamName {
-		t.Errorf("Expected LogStreamName to be %s", streamName)
-	}
-}
-
-func TestCreateError(t *testing.T) {
-	mockClient := newMockClient()
-	stream := &logStream{
-		client: mockClient,
-	}
-	mockClient.createLogStreamResult <- &createLogStreamResult{
-		errorResult: errors.New("Error"),
-	}
-
-	err := stream.create()
-
-	if err == nil {
-		t.Fatal("Expected non-nil err")
-	}
-}
-
-func TestCreateAlreadyExists(t *testing.T) {
-	mockClient := newMockClient()
-	stream := &logStream{
-		client: mockClient,
-	}
-	mockClient.createLogStreamResult <- &createLogStreamResult{
-		errorResult: awserr.New(resourceAlreadyExistsCode, "", nil),
-	}
-
-	err := stream.create()
-
-	assert.NilError(t, err)
-}
-
-func TestLogClosed(t *testing.T) {
-	mockClient := newMockClient()
-	stream := &logStream{
-		client: mockClient,
-		closed: true,
-	}
-	err := stream.Log(&logger.Message{})
-	if err == nil {
-		t.Fatal("Expected non-nil error")
-	}
-}
-
-// TestLogBlocking tests that the Log method blocks appropriately when
-// non-blocking behavior is not enabled.  Blocking is achieved through an
-// internal channel that must be drained for Log to return.
-func TestLogBlocking(t *testing.T) {
-	mockClient := newMockClient()
-	stream := &logStream{
-		client:   mockClient,
-		messages: make(chan *logger.Message),
-	}
-
-	errorCh := make(chan error, 1)
-	started := make(chan bool)
-	go func() {
-		started <- true
-		err := stream.Log(&logger.Message{})
-		errorCh <- err
-	}()
-	// block until the goroutine above has started
-	<-started
-	select {
-	case err := <-errorCh:
-		t.Fatal("Expected stream.Log to block: ", err)
-	default:
-	}
-	// assuming it is blocked, we can now try to drain the internal channel and
-	// unblock it
-	select {
-	case <-time.After(10 * time.Millisecond):
-		// if we're unable to drain the channel within 10ms, something seems broken
-		t.Fatal("Expected to be able to read from stream.messages but was unable to")
-	case <-stream.messages:
-	}
-	select {
-	case err := <-errorCh:
-		assert.NilError(t, err)
-
-	case <-time.After(30 * time.Second):
-		t.Fatal("timed out waiting for read")
-	}
-}
-
-func TestLogNonBlockingBufferEmpty(t *testing.T) {
-	mockClient := newMockClient()
-	stream := &logStream{
-		client:         mockClient,
-		messages:       make(chan *logger.Message, 1),
-		logNonBlocking: true,
-	}
-	err := stream.Log(&logger.Message{})
-	assert.NilError(t, err)
-}
-
-func TestLogNonBlockingBufferFull(t *testing.T) {
-	mockClient := newMockClient()
-	stream := &logStream{
-		client:         mockClient,
-		messages:       make(chan *logger.Message, 1),
-		logNonBlocking: true,
-	}
-	stream.messages <- &logger.Message{}
-	errorCh := make(chan error)
-	started := make(chan bool)
-	go func() {
-		started <- true
-		err := stream.Log(&logger.Message{})
-		errorCh <- err
-	}()
-	<-started
-	select {
-	case err := <-errorCh:
-		if err == nil {
-			t.Fatal("Expected non-nil error")
-		}
-	case <-time.After(30 * time.Second):
-		t.Fatal("Expected Log call to not block")
-	}
-}
-func TestPublishBatchSuccess(t *testing.T) {
-	mockClient := newMockClient()
-	stream := &logStream{
-		client:        mockClient,
-		logGroupName:  groupName,
-		logStreamName: streamName,
-		sequenceToken: aws.String(sequenceToken),
-	}
-	mockClient.putLogEventsResult <- &putLogEventsResult{
-		successResult: &cloudwatchlogs.PutLogEventsOutput{
-			NextSequenceToken: aws.String(nextSequenceToken),
-		},
-	}
-	events := []wrappedEvent{
-		{
-			inputLogEvent: &cloudwatchlogs.InputLogEvent{
-				Message: aws.String(logline),
-			},
-		},
-	}
-
-	stream.publishBatch(testEventBatch(events))
-	if stream.sequenceToken == nil {
-		t.Fatal("Expected non-nil sequenceToken")
-	}
-	if *stream.sequenceToken != nextSequenceToken {
-		t.Errorf("Expected sequenceToken to be %s, but was %s", nextSequenceToken, *stream.sequenceToken)
-	}
-	argument := <-mockClient.putLogEventsArgument
-	if argument == nil {
-		t.Fatal("Expected non-nil PutLogEventsInput")
-	}
-	if argument.SequenceToken == nil {
-		t.Fatal("Expected non-nil PutLogEventsInput.SequenceToken")
-	}
-	if *argument.SequenceToken != sequenceToken {
-		t.Errorf("Expected PutLogEventsInput.SequenceToken to be %s, but was %s", sequenceToken, *argument.SequenceToken)
-	}
-	if len(argument.LogEvents) != 1 {
-		t.Errorf("Expected LogEvents to contain 1 element, but contains %d", len(argument.LogEvents))
-	}
-	if argument.LogEvents[0] != events[0].inputLogEvent {
-		t.Error("Expected event to equal input")
-	}
-}
-
-func TestPublishBatchError(t *testing.T) {
-	mockClient := newMockClient()
-	stream := &logStream{
-		client:        mockClient,
-		logGroupName:  groupName,
-		logStreamName: streamName,
-		sequenceToken: aws.String(sequenceToken),
-	}
-	mockClient.putLogEventsResult <- &putLogEventsResult{
-		errorResult: errors.New("Error"),
-	}
-
-	events := []wrappedEvent{
-		{
-			inputLogEvent: &cloudwatchlogs.InputLogEvent{
-				Message: aws.String(logline),
-			},
-		},
-	}
-
-	stream.publishBatch(testEventBatch(events))
-	if stream.sequenceToken == nil {
-		t.Fatal("Expected non-nil sequenceToken")
-	}
-	if *stream.sequenceToken != sequenceToken {
-		t.Errorf("Expected sequenceToken to be %s, but was %s", sequenceToken, *stream.sequenceToken)
-	}
-}
-
-func TestPublishBatchInvalidSeqSuccess(t *testing.T) {
-	mockClient := newMockClientBuffered(2)
-	stream := &logStream{
-		client:        mockClient,
-		logGroupName:  groupName,
-		logStreamName: streamName,
-		sequenceToken: aws.String(sequenceToken),
-	}
-	mockClient.putLogEventsResult <- &putLogEventsResult{
-		errorResult: awserr.New(invalidSequenceTokenCode, "use token token", nil),
-	}
-	mockClient.putLogEventsResult <- &putLogEventsResult{
-		successResult: &cloudwatchlogs.PutLogEventsOutput{
-			NextSequenceToken: aws.String(nextSequenceToken),
-		},
-	}
-
-	events := []wrappedEvent{
-		{
-			inputLogEvent: &cloudwatchlogs.InputLogEvent{
-				Message: aws.String(logline),
-			},
-		},
-	}
-
-	stream.publishBatch(testEventBatch(events))
-	if stream.sequenceToken == nil {
-		t.Fatal("Expected non-nil sequenceToken")
-	}
-	if *stream.sequenceToken != nextSequenceToken {
-		t.Errorf("Expected sequenceToken to be %s, but was %s", nextSequenceToken, *stream.sequenceToken)
-	}
-
-	argument := <-mockClient.putLogEventsArgument
-	if argument == nil {
-		t.Fatal("Expected non-nil PutLogEventsInput")
-	}
-	if argument.SequenceToken == nil {
-		t.Fatal("Expected non-nil PutLogEventsInput.SequenceToken")
-	}
-	if *argument.SequenceToken != sequenceToken {
-		t.Errorf("Expected PutLogEventsInput.SequenceToken to be %s, but was %s", sequenceToken, *argument.SequenceToken)
-	}
-	if len(argument.LogEvents) != 1 {
-		t.Errorf("Expected LogEvents to contain 1 element, but contains %d", len(argument.LogEvents))
-	}
-	if argument.LogEvents[0] != events[0].inputLogEvent {
-		t.Error("Expected event to equal input")
-	}
-
-	argument = <-mockClient.putLogEventsArgument
-	if argument == nil {
-		t.Fatal("Expected non-nil PutLogEventsInput")
-	}
-	if argument.SequenceToken == nil {
-		t.Fatal("Expected non-nil PutLogEventsInput.SequenceToken")
-	}
-	if *argument.SequenceToken != "token" {
-		t.Errorf("Expected PutLogEventsInput.SequenceToken to be %s, but was %s", "token", *argument.SequenceToken)
-	}
-	if len(argument.LogEvents) != 1 {
-		t.Errorf("Expected LogEvents to contain 1 element, but contains %d", len(argument.LogEvents))
-	}
-	if argument.LogEvents[0] != events[0].inputLogEvent {
-		t.Error("Expected event to equal input")
-	}
-}
-
-func TestPublishBatchAlreadyAccepted(t *testing.T) {
-	mockClient := newMockClient()
-	stream := &logStream{
-		client:        mockClient,
-		logGroupName:  groupName,
-		logStreamName: streamName,
-		sequenceToken: aws.String(sequenceToken),
-	}
-	mockClient.putLogEventsResult <- &putLogEventsResult{
-		errorResult: awserr.New(dataAlreadyAcceptedCode, "use token token", nil),
-	}
-
-	events := []wrappedEvent{
-		{
-			inputLogEvent: &cloudwatchlogs.InputLogEvent{
-				Message: aws.String(logline),
-			},
-		},
-	}
-
-	stream.publishBatch(testEventBatch(events))
-	if stream.sequenceToken == nil {
-		t.Fatal("Expected non-nil sequenceToken")
-	}
-	if *stream.sequenceToken != "token" {
-		t.Errorf("Expected sequenceToken to be %s, but was %s", "token", *stream.sequenceToken)
-	}
-
-	argument := <-mockClient.putLogEventsArgument
-	if argument == nil {
-		t.Fatal("Expected non-nil PutLogEventsInput")
-	}
-	if argument.SequenceToken == nil {
-		t.Fatal("Expected non-nil PutLogEventsInput.SequenceToken")
-	}
-	if *argument.SequenceToken != sequenceToken {
-		t.Errorf("Expected PutLogEventsInput.SequenceToken to be %s, but was %s", sequenceToken, *argument.SequenceToken)
-	}
-	if len(argument.LogEvents) != 1 {
-		t.Errorf("Expected LogEvents to contain 1 element, but contains %d", len(argument.LogEvents))
-	}
-	if argument.LogEvents[0] != events[0].inputLogEvent {
-		t.Error("Expected event to equal input")
-	}
-}
-
-func TestCollectBatchSimple(t *testing.T) {
-	mockClient := newMockClient()
-	stream := &logStream{
-		client:        mockClient,
-		logGroupName:  groupName,
-		logStreamName: streamName,
-		sequenceToken: aws.String(sequenceToken),
-		messages:      make(chan *logger.Message),
-	}
-	mockClient.putLogEventsResult <- &putLogEventsResult{
-		successResult: &cloudwatchlogs.PutLogEventsOutput{
-			NextSequenceToken: aws.String(nextSequenceToken),
-		},
-	}
-	ticks := make(chan time.Time)
-	newTicker = func(_ time.Duration) *time.Ticker {
-		return &time.Ticker{
-			C: ticks,
-		}
-	}
-	d := make(chan bool)
-	close(d)
-	go stream.collectBatch(d)
-
-	stream.Log(&logger.Message{
-		Line:      []byte(logline),
-		Timestamp: time.Time{},
-	})
-
-	ticks <- time.Time{}
-	stream.Close()
-
-	argument := <-mockClient.putLogEventsArgument
-	if argument == nil {
-		t.Fatal("Expected non-nil PutLogEventsInput")
-	}
-	if len(argument.LogEvents) != 1 {
-		t.Errorf("Expected LogEvents to contain 1 element, but contains %d", len(argument.LogEvents))
-	}
-	if *argument.LogEvents[0].Message != logline {
-		t.Errorf("Expected message to be %s but was %s", logline, *argument.LogEvents[0].Message)
-	}
-}
-
-func TestCollectBatchTicker(t *testing.T) {
-	mockClient := newMockClient()
-	stream := &logStream{
-		client:        mockClient,
-		logGroupName:  groupName,
-		logStreamName: streamName,
-		sequenceToken: aws.String(sequenceToken),
-		messages:      make(chan *logger.Message),
-	}
-	mockClient.putLogEventsResult <- &putLogEventsResult{
-		successResult: &cloudwatchlogs.PutLogEventsOutput{
-			NextSequenceToken: aws.String(nextSequenceToken),
-		},
-	}
-	ticks := make(chan time.Time)
-	newTicker = func(_ time.Duration) *time.Ticker {
-		return &time.Ticker{
-			C: ticks,
-		}
-	}
-
-	d := make(chan bool)
-	close(d)
-	go stream.collectBatch(d)
-
-	stream.Log(&logger.Message{
-		Line:      []byte(logline + " 1"),
-		Timestamp: time.Time{},
-	})
-	stream.Log(&logger.Message{
-		Line:      []byte(logline + " 2"),
-		Timestamp: time.Time{},
-	})
-
-	ticks <- time.Time{}
-
-	// Verify first batch
-	argument := <-mockClient.putLogEventsArgument
-	if argument == nil {
-		t.Fatal("Expected non-nil PutLogEventsInput")
-	}
-	if len(argument.LogEvents) != 2 {
-		t.Errorf("Expected LogEvents to contain 2 elements, but contains %d", len(argument.LogEvents))
-	}
-	if *argument.LogEvents[0].Message != logline+" 1" {
-		t.Errorf("Expected message to be %s but was %s", logline+" 1", *argument.LogEvents[0].Message)
-	}
-	if *argument.LogEvents[1].Message != logline+" 2" {
-		t.Errorf("Expected message to be %s but was %s", logline+" 2", *argument.LogEvents[0].Message)
-	}
-
-	stream.Log(&logger.Message{
-		Line:      []byte(logline + " 3"),
-		Timestamp: time.Time{},
-	})
-
-	ticks <- time.Time{}
-	argument = <-mockClient.putLogEventsArgument
-	if argument == nil {
-		t.Fatal("Expected non-nil PutLogEventsInput")
-	}
-	if len(argument.LogEvents) != 1 {
-		t.Errorf("Expected LogEvents to contain 1 elements, but contains %d", len(argument.LogEvents))
-	}
-	if *argument.LogEvents[0].Message != logline+" 3" {
-		t.Errorf("Expected message to be %s but was %s", logline+" 3", *argument.LogEvents[0].Message)
-	}
-
-	stream.Close()
-
-}
-
-func TestCollectBatchMultilinePattern(t *testing.T) {
-	mockClient := newMockClient()
-	multilinePattern := regexp.MustCompile("xxxx")
-	stream := &logStream{
-		client:           mockClient,
-		logGroupName:     groupName,
-		logStreamName:    streamName,
-		multilinePattern: multilinePattern,
-		sequenceToken:    aws.String(sequenceToken),
-		messages:         make(chan *logger.Message),
-	}
-	mockClient.putLogEventsResult <- &putLogEventsResult{
-		successResult: &cloudwatchlogs.PutLogEventsOutput{
-			NextSequenceToken: aws.String(nextSequenceToken),
-		},
-	}
-	ticks := make(chan time.Time)
-	newTicker = func(_ time.Duration) *time.Ticker {
-		return &time.Ticker{
-			C: ticks,
-		}
-	}
-
-	d := make(chan bool)
-	close(d)
-	go stream.collectBatch(d)
-
-	stream.Log(&logger.Message{
-		Line:      []byte(logline),
-		Timestamp: time.Now(),
-	})
-	stream.Log(&logger.Message{
-		Line:      []byte(logline),
-		Timestamp: time.Now(),
-	})
-	stream.Log(&logger.Message{
-		Line:      []byte("xxxx " + logline),
-		Timestamp: time.Now(),
-	})
-
-	ticks <- time.Now()
-
-	// Verify single multiline event
-	argument := <-mockClient.putLogEventsArgument
-	assert.Check(t, argument != nil, "Expected non-nil PutLogEventsInput")
-	assert.Check(t, is.Equal(1, len(argument.LogEvents)), "Expected single multiline event")
-	assert.Check(t, is.Equal(logline+"\n"+logline+"\n", *argument.LogEvents[0].Message), "Received incorrect multiline message")
-
-	stream.Close()
-
-	// Verify single event
-	argument = <-mockClient.putLogEventsArgument
-	assert.Check(t, argument != nil, "Expected non-nil PutLogEventsInput")
-	assert.Check(t, is.Equal(1, len(argument.LogEvents)), "Expected single multiline event")
-	assert.Check(t, is.Equal("xxxx "+logline+"\n", *argument.LogEvents[0].Message), "Received incorrect multiline message")
-}
-
-func BenchmarkCollectBatch(b *testing.B) {
-	for i := 0; i < b.N; i++ {
-		mockClient := newMockClient()
-		stream := &logStream{
-			client:        mockClient,
-			logGroupName:  groupName,
-			logStreamName: streamName,
-			sequenceToken: aws.String(sequenceToken),
-			messages:      make(chan *logger.Message),
-		}
-		mockClient.putLogEventsResult <- &putLogEventsResult{
-			successResult: &cloudwatchlogs.PutLogEventsOutput{
-				NextSequenceToken: aws.String(nextSequenceToken),
-			},
-		}
-		ticks := make(chan time.Time)
-		newTicker = func(_ time.Duration) *time.Ticker {
-			return &time.Ticker{
-				C: ticks,
-			}
-		}
-
-		d := make(chan bool)
-		close(d)
-		go stream.collectBatch(d)
-		stream.logGenerator(10, 100)
-		ticks <- time.Time{}
-		stream.Close()
-	}
-}
-
-func BenchmarkCollectBatchMultilinePattern(b *testing.B) {
-	for i := 0; i < b.N; i++ {
-		mockClient := newMockClient()
-		multilinePattern := regexp.MustCompile(`\d{4}-(?:0[1-9]|1[0-2])-(?:0[1-9]|[1,2][0-9]|3[0,1]) (?:[0,1][0-9]|2[0-3]):[0-5][0-9]:[0-5][0-9]`)
-		stream := &logStream{
-			client:           mockClient,
-			logGroupName:     groupName,
-			logStreamName:    streamName,
-			multilinePattern: multilinePattern,
-			sequenceToken:    aws.String(sequenceToken),
-			messages:         make(chan *logger.Message),
-		}
-		mockClient.putLogEventsResult <- &putLogEventsResult{
-			successResult: &cloudwatchlogs.PutLogEventsOutput{
-				NextSequenceToken: aws.String(nextSequenceToken),
-			},
-		}
-		ticks := make(chan time.Time)
-		newTicker = func(_ time.Duration) *time.Ticker {
-			return &time.Ticker{
-				C: ticks,
-			}
-		}
-		d := make(chan bool)
-		close(d)
-		go stream.collectBatch(d)
-		stream.logGenerator(10, 100)
-		ticks <- time.Time{}
-		stream.Close()
-	}
-}
-
-func TestCollectBatchMultilinePatternMaxEventAge(t *testing.T) {
-	mockClient := newMockClient()
-	multilinePattern := regexp.MustCompile("xxxx")
-	stream := &logStream{
-		client:           mockClient,
-		logGroupName:     groupName,
-		logStreamName:    streamName,
-		multilinePattern: multilinePattern,
-		sequenceToken:    aws.String(sequenceToken),
-		messages:         make(chan *logger.Message),
-	}
-	mockClient.putLogEventsResult <- &putLogEventsResult{
-		successResult: &cloudwatchlogs.PutLogEventsOutput{
-			NextSequenceToken: aws.String(nextSequenceToken),
-		},
-	}
-	ticks := make(chan time.Time)
-	newTicker = func(_ time.Duration) *time.Ticker {
-		return &time.Ticker{
-			C: ticks,
-		}
-	}
-
-	d := make(chan bool)
-	close(d)
-	go stream.collectBatch(d)
-
-	stream.Log(&logger.Message{
-		Line:      []byte(logline),
-		Timestamp: time.Now(),
-	})
-
-	// Log an event 1 second later
-	stream.Log(&logger.Message{
-		Line:      []byte(logline),
-		Timestamp: time.Now().Add(time.Second),
-	})
-
-	// Fire ticker defaultForceFlushInterval seconds later
-	ticks <- time.Now().Add(defaultForceFlushInterval + time.Second)
-
-	// Verify single multiline event is flushed after maximum event buffer age (defaultForceFlushInterval)
-	argument := <-mockClient.putLogEventsArgument
-	assert.Check(t, argument != nil, "Expected non-nil PutLogEventsInput")
-	assert.Check(t, is.Equal(1, len(argument.LogEvents)), "Expected single multiline event")
-	assert.Check(t, is.Equal(logline+"\n"+logline+"\n", *argument.LogEvents[0].Message), "Received incorrect multiline message")
-
-	// Log an event 1 second later
-	stream.Log(&logger.Message{
-		Line:      []byte(logline),
-		Timestamp: time.Now().Add(time.Second),
-	})
-
-	// Fire ticker another defaultForceFlushInterval seconds later
-	ticks <- time.Now().Add(2*defaultForceFlushInterval + time.Second)
-
-	// Verify the event buffer is truly flushed - we should only receive a single event
-	argument = <-mockClient.putLogEventsArgument
-	assert.Check(t, argument != nil, "Expected non-nil PutLogEventsInput")
-	assert.Check(t, is.Equal(1, len(argument.LogEvents)), "Expected single multiline event")
-	assert.Check(t, is.Equal(logline+"\n", *argument.LogEvents[0].Message), "Received incorrect multiline message")
-	stream.Close()
-}
-
-func TestCollectBatchMultilinePatternNegativeEventAge(t *testing.T) {
-	mockClient := newMockClient()
-	multilinePattern := regexp.MustCompile("xxxx")
-	stream := &logStream{
-		client:           mockClient,
-		logGroupName:     groupName,
-		logStreamName:    streamName,
-		multilinePattern: multilinePattern,
-		sequenceToken:    aws.String(sequenceToken),
-		messages:         make(chan *logger.Message),
-	}
-	mockClient.putLogEventsResult <- &putLogEventsResult{
-		successResult: &cloudwatchlogs.PutLogEventsOutput{
-			NextSequenceToken: aws.String(nextSequenceToken),
-		},
-	}
-	ticks := make(chan time.Time)
-	newTicker = func(_ time.Duration) *time.Ticker {
-		return &time.Ticker{
-			C: ticks,
-		}
-	}
-
-	d := make(chan bool)
-	close(d)
-	go stream.collectBatch(d)
-
-	stream.Log(&logger.Message{
-		Line:      []byte(logline),
-		Timestamp: time.Now(),
-	})
-
-	// Log an event 1 second later
-	stream.Log(&logger.Message{
-		Line:      []byte(logline),
-		Timestamp: time.Now().Add(time.Second),
-	})
-
-	// Fire ticker in past to simulate negative event buffer age
-	ticks <- time.Now().Add(-time.Second)
-
-	// Verify single multiline event is flushed with a negative event buffer age
-	argument := <-mockClient.putLogEventsArgument
-	assert.Check(t, argument != nil, "Expected non-nil PutLogEventsInput")
-	assert.Check(t, is.Equal(1, len(argument.LogEvents)), "Expected single multiline event")
-	assert.Check(t, is.Equal(logline+"\n"+logline+"\n", *argument.LogEvents[0].Message), "Received incorrect multiline message")
-
-	stream.Close()
-}
-
-func TestCollectBatchMultilinePatternMaxEventSize(t *testing.T) {
-	mockClient := newMockClient()
-	multilinePattern := regexp.MustCompile("xxxx")
-	stream := &logStream{
-		client:           mockClient,
-		logGroupName:     groupName,
-		logStreamName:    streamName,
-		multilinePattern: multilinePattern,
-		sequenceToken:    aws.String(sequenceToken),
-		messages:         make(chan *logger.Message),
-	}
-	mockClient.putLogEventsResult <- &putLogEventsResult{
-		successResult: &cloudwatchlogs.PutLogEventsOutput{
-			NextSequenceToken: aws.String(nextSequenceToken),
-		},
-	}
-	ticks := make(chan time.Time)
-	newTicker = func(_ time.Duration) *time.Ticker {
-		return &time.Ticker{
-			C: ticks,
-		}
-	}
-
-	d := make(chan bool)
-	close(d)
-	go stream.collectBatch(d)
-
-	// Log max event size
-	longline := strings.Repeat("A", maximumBytesPerEvent)
-	stream.Log(&logger.Message{
-		Line:      []byte(longline),
-		Timestamp: time.Now(),
-	})
-
-	// Log short event
-	shortline := strings.Repeat("B", 100)
-	stream.Log(&logger.Message{
-		Line:      []byte(shortline),
-		Timestamp: time.Now(),
-	})
-
-	// Fire ticker
-	ticks <- time.Now().Add(defaultForceFlushInterval)
-
-	// Verify multiline events
-	// We expect a maximum sized event with no new line characters and a
-	// second short event with a new line character at the end
-	argument := <-mockClient.putLogEventsArgument
-	assert.Check(t, argument != nil, "Expected non-nil PutLogEventsInput")
-	assert.Check(t, is.Equal(2, len(argument.LogEvents)), "Expected two events")
-	assert.Check(t, is.Equal(longline, *argument.LogEvents[0].Message), "Received incorrect multiline message")
-	assert.Check(t, is.Equal(shortline+"\n", *argument.LogEvents[1].Message), "Received incorrect multiline message")
-	stream.Close()
-}
-
-func TestCollectBatchClose(t *testing.T) {
-	mockClient := newMockClient()
-	stream := &logStream{
-		client:        mockClient,
-		logGroupName:  groupName,
-		logStreamName: streamName,
-		sequenceToken: aws.String(sequenceToken),
-		messages:      make(chan *logger.Message),
-	}
-	mockClient.putLogEventsResult <- &putLogEventsResult{
-		successResult: &cloudwatchlogs.PutLogEventsOutput{
-			NextSequenceToken: aws.String(nextSequenceToken),
-		},
-	}
-	var ticks = make(chan time.Time)
-	newTicker = func(_ time.Duration) *time.Ticker {
-		return &time.Ticker{
-			C: ticks,
-		}
-	}
-
-	d := make(chan bool)
-	close(d)
-	go stream.collectBatch(d)
-
-	stream.Log(&logger.Message{
-		Line:      []byte(logline),
-		Timestamp: time.Time{},
-	})
-
-	// no ticks
-	stream.Close()
-
-	argument := <-mockClient.putLogEventsArgument
-	if argument == nil {
-		t.Fatal("Expected non-nil PutLogEventsInput")
-	}
-	if len(argument.LogEvents) != 1 {
-		t.Errorf("Expected LogEvents to contain 1 element, but contains %d", len(argument.LogEvents))
-	}
-	if *argument.LogEvents[0].Message != logline {
-		t.Errorf("Expected message to be %s but was %s", logline, *argument.LogEvents[0].Message)
-	}
-}
-
-func TestEffectiveLen(t *testing.T) {
-	tests := []struct {
-		str            string
-		effectiveBytes int
-	}{
-		{"Hello", 5},
-		{string([]byte{1, 2, 3, 4}), 4},
-		{"", 4},
-		{string([]byte{0xFF, 0xFF, 0xFF, 0xFF}), 12},
-		{"He\xff\xffo", 9},
-		{"", 0},
-	}
-	for i, tc := range tests {
-		t.Run(fmt.Sprintf("%d/%s", i, tc.str), func(t *testing.T) {
-			assert.Equal(t, tc.effectiveBytes, effectiveLen(tc.str))
-		})
-	}
-}
-
-func TestFindValidSplit(t *testing.T) {
-	tests := []struct {
-		str               string
-		maxEffectiveBytes int
-		splitOffset       int
-		effectiveBytes    int
-	}{
-		{"", 10, 0, 0},
-		{"Hello", 6, 5, 5},
-		{"Hello", 2, 2, 2},
-		{"Hello", 0, 0, 0},
-		{"", 3, 0, 0},
-		{"", 4, 4, 4},
-		{string([]byte{'a', 0xFF}), 2, 1, 1},
-		{string([]byte{'a', 0xFF}), 4, 2, 4},
-	}
-	for i, tc := range tests {
-		t.Run(fmt.Sprintf("%d/%s", i, tc.str), func(t *testing.T) {
-			splitOffset, effectiveBytes := findValidSplit(tc.str, tc.maxEffectiveBytes)
-			assert.Equal(t, tc.splitOffset, splitOffset, "splitOffset")
-			assert.Equal(t, tc.effectiveBytes, effectiveBytes, "effectiveBytes")
-			t.Log(tc.str[:tc.splitOffset])
-			t.Log(tc.str[tc.splitOffset:])
-		})
-	}
-}
-
-func TestProcessEventEmoji(t *testing.T) {
-	stream := &logStream{}
-	batch := &eventBatch{}
-	bytes := []byte(strings.Repeat("", maximumBytesPerEvent/4+1))
-	stream.processEvent(batch, bytes, 0)
-	assert.Equal(t, 2, len(batch.batch), "should be two events in the batch")
-	assert.Equal(t, strings.Repeat("", maximumBytesPerEvent/4), aws.StringValue(batch.batch[0].inputLogEvent.Message))
-	assert.Equal(t, "", aws.StringValue(batch.batch[1].inputLogEvent.Message))
-}
-
-func TestCollectBatchLineSplit(t *testing.T) {
-	mockClient := newMockClient()
-	stream := &logStream{
-		client:        mockClient,
-		logGroupName:  groupName,
-		logStreamName: streamName,
-		sequenceToken: aws.String(sequenceToken),
-		messages:      make(chan *logger.Message),
-	}
-	mockClient.putLogEventsResult <- &putLogEventsResult{
-		successResult: &cloudwatchlogs.PutLogEventsOutput{
-			NextSequenceToken: aws.String(nextSequenceToken),
-		},
-	}
-	var ticks = make(chan time.Time)
-	newTicker = func(_ time.Duration) *time.Ticker {
-		return &time.Ticker{
-			C: ticks,
-		}
-	}
-
-	d := make(chan bool)
-	close(d)
-	go stream.collectBatch(d)
-
-	longline := strings.Repeat("A", maximumBytesPerEvent)
-	stream.Log(&logger.Message{
-		Line:      []byte(longline + "B"),
-		Timestamp: time.Time{},
-	})
-
-	// no ticks
-	stream.Close()
-
-	argument := <-mockClient.putLogEventsArgument
-	if argument == nil {
-		t.Fatal("Expected non-nil PutLogEventsInput")
-	}
-	if len(argument.LogEvents) != 2 {
-		t.Errorf("Expected LogEvents to contain 2 elements, but contains %d", len(argument.LogEvents))
-	}
-	if *argument.LogEvents[0].Message != longline {
-		t.Errorf("Expected message to be %s but was %s", longline, *argument.LogEvents[0].Message)
-	}
-	if *argument.LogEvents[1].Message != "B" {
-		t.Errorf("Expected message to be %s but was %s", "B", *argument.LogEvents[1].Message)
-	}
-}
-
-func TestCollectBatchLineSplitWithBinary(t *testing.T) {
-	mockClient := newMockClient()
-	stream := &logStream{
-		client:        mockClient,
-		logGroupName:  groupName,
-		logStreamName: streamName,
-		sequenceToken: aws.String(sequenceToken),
-		messages:      make(chan *logger.Message),
-	}
-	mockClient.putLogEventsResult <- &putLogEventsResult{
-		successResult: &cloudwatchlogs.PutLogEventsOutput{
-			NextSequenceToken: aws.String(nextSequenceToken),
-		},
-	}
-	var ticks = make(chan time.Time)
-	newTicker = func(_ time.Duration) *time.Ticker {
-		return &time.Ticker{
-			C: ticks,
-		}
-	}
-
-	d := make(chan bool)
-	close(d)
-	go stream.collectBatch(d)
-
-	longline := strings.Repeat("\xFF", maximumBytesPerEvent/3) // 0xFF is counted as the 3-byte utf8.RuneError
-	stream.Log(&logger.Message{
-		Line:      []byte(longline + "\xFD"),
-		Timestamp: time.Time{},
-	})
-
-	// no ticks
-	stream.Close()
-
-	argument := <-mockClient.putLogEventsArgument
-	if argument == nil {
-		t.Fatal("Expected non-nil PutLogEventsInput")
-	}
-	if len(argument.LogEvents) != 2 {
-		t.Errorf("Expected LogEvents to contain 2 elements, but contains %d", len(argument.LogEvents))
-	}
-	if *argument.LogEvents[0].Message != longline {
-		t.Errorf("Expected message to be %s but was %s", longline, *argument.LogEvents[0].Message)
-	}
-	if *argument.LogEvents[1].Message != "\xFD" {
-		t.Errorf("Expected message to be %s but was %s", "\xFD", *argument.LogEvents[1].Message)
-	}
-}
-
-func TestCollectBatchMaxEvents(t *testing.T) {
-	mockClient := newMockClientBuffered(1)
-	stream := &logStream{
-		client:        mockClient,
-		logGroupName:  groupName,
-		logStreamName: streamName,
-		sequenceToken: aws.String(sequenceToken),
-		messages:      make(chan *logger.Message),
-	}
-	mockClient.putLogEventsResult <- &putLogEventsResult{
-		successResult: &cloudwatchlogs.PutLogEventsOutput{
-			NextSequenceToken: aws.String(nextSequenceToken),
-		},
-	}
-	var ticks = make(chan time.Time)
-	newTicker = func(_ time.Duration) *time.Ticker {
-		return &time.Ticker{
-			C: ticks,
-		}
-	}
-
-	d := make(chan bool)
-	close(d)
-	go stream.collectBatch(d)
-
-	line := "A"
-	for i := 0; i <= maximumLogEventsPerPut; i++ {
-		stream.Log(&logger.Message{
-			Line:      []byte(line),
-			Timestamp: time.Time{},
-		})
-	}
-
-	// no ticks
-	stream.Close()
-
-	argument := <-mockClient.putLogEventsArgument
-	if argument == nil {
-		t.Fatal("Expected non-nil PutLogEventsInput")
-	}
-	if len(argument.LogEvents) != maximumLogEventsPerPut {
-		t.Errorf("Expected LogEvents to contain %d elements, but contains %d", maximumLogEventsPerPut, len(argument.LogEvents))
-	}
-
-	argument = <-mockClient.putLogEventsArgument
-	if argument == nil {
-		t.Fatal("Expected non-nil PutLogEventsInput")
-	}
-	if len(argument.LogEvents) != 1 {
-		t.Errorf("Expected LogEvents to contain %d elements, but contains %d", 1, len(argument.LogEvents))
-	}
-}
-
-func TestCollectBatchMaxTotalBytes(t *testing.T) {
-	expectedPuts := 2
-	mockClient := newMockClientBuffered(expectedPuts)
-	stream := &logStream{
-		client:        mockClient,
-		logGroupName:  groupName,
-		logStreamName: streamName,
-		sequenceToken: aws.String(sequenceToken),
-		messages:      make(chan *logger.Message),
-	}
-	for i := 0; i < expectedPuts; i++ {
-		mockClient.putLogEventsResult <- &putLogEventsResult{
-			successResult: &cloudwatchlogs.PutLogEventsOutput{
-				NextSequenceToken: aws.String(nextSequenceToken),
-			},
-		}
-	}
-
-	var ticks = make(chan time.Time)
-	newTicker = func(_ time.Duration) *time.Ticker {
-		return &time.Ticker{
-			C: ticks,
-		}
-	}
-
-	d := make(chan bool)
-	close(d)
-	go stream.collectBatch(d)
-
-	numPayloads := maximumBytesPerPut / (maximumBytesPerEvent + perEventBytes)
-	// maxline is the maximum line that could be submitted after
-	// accounting for its overhead.
-	maxline := strings.Repeat("A", maximumBytesPerPut-(perEventBytes*numPayloads))
-	// This will be split and batched up to the `maximumBytesPerPut'
-	// (+/- `maximumBytesPerEvent'). This /should/ be aligned, but
-	// should also tolerate an offset within that range.
-	stream.Log(&logger.Message{
-		Line:      []byte(maxline[:len(maxline)/2]),
-		Timestamp: time.Time{},
-	})
-	stream.Log(&logger.Message{
-		Line:      []byte(maxline[len(maxline)/2:]),
-		Timestamp: time.Time{},
-	})
-	stream.Log(&logger.Message{
-		Line:      []byte("B"),
-		Timestamp: time.Time{},
-	})
-
-	// no ticks, guarantee batch by size (and chan close)
-	stream.Close()
-
-	argument := <-mockClient.putLogEventsArgument
-	if argument == nil {
-		t.Fatal("Expected non-nil PutLogEventsInput")
-	}
-
-	// Should total to the maximum allowed bytes.
-	eventBytes := 0
-	for _, event := range argument.LogEvents {
-		eventBytes += len(*event.Message)
-	}
-	eventsOverhead := len(argument.LogEvents) * perEventBytes
-	payloadTotal := eventBytes + eventsOverhead
-	// lowestMaxBatch allows the payload to be offset if the messages
-	// don't lend themselves to align with the maximum event size.
-	lowestMaxBatch := maximumBytesPerPut - maximumBytesPerEvent
-
-	if payloadTotal > maximumBytesPerPut {
-		t.Errorf("Expected <= %d bytes but was %d", maximumBytesPerPut, payloadTotal)
-	}
-	if payloadTotal < lowestMaxBatch {
-		t.Errorf("Batch to be no less than %d but was %d", lowestMaxBatch, payloadTotal)
-	}
-
-	argument = <-mockClient.putLogEventsArgument
-	if len(argument.LogEvents) != 1 {
-		t.Errorf("Expected LogEvents to contain 1 elements, but contains %d", len(argument.LogEvents))
-	}
-	message := *argument.LogEvents[len(argument.LogEvents)-1].Message
-	if message[len(message)-1:] != "B" {
-		t.Errorf("Expected message to be %s but was %s", "B", message[len(message)-1:])
-	}
-}
-
-func TestCollectBatchMaxTotalBytesWithBinary(t *testing.T) {
-	expectedPuts := 2
-	mockClient := newMockClientBuffered(expectedPuts)
-	stream := &logStream{
-		client:        mockClient,
-		logGroupName:  groupName,
-		logStreamName: streamName,
-		sequenceToken: aws.String(sequenceToken),
-		messages:      make(chan *logger.Message),
-	}
-	for i := 0; i < expectedPuts; i++ {
-		mockClient.putLogEventsResult <- &putLogEventsResult{
-			successResult: &cloudwatchlogs.PutLogEventsOutput{
-				NextSequenceToken: aws.String(nextSequenceToken),
-			},
-		}
-	}
-
-	var ticks = make(chan time.Time)
-	newTicker = func(_ time.Duration) *time.Ticker {
-		return &time.Ticker{
-			C: ticks,
-		}
-	}
-
-	d := make(chan bool)
-	close(d)
-	go stream.collectBatch(d)
-
-	// maxline is the maximum line that could be submitted after
-	// accounting for its overhead.
-	maxline := strings.Repeat("\xFF", (maximumBytesPerPut-perEventBytes)/3) // 0xFF is counted as the 3-byte utf8.RuneError
-	// This will be split and batched up to the `maximumBytesPerPut'
-	// (+/- `maximumBytesPerEvent'). This /should/ be aligned, but
-	// should also tolerate an offset within that range.
-	stream.Log(&logger.Message{
-		Line:      []byte(maxline),
-		Timestamp: time.Time{},
-	})
-	stream.Log(&logger.Message{
-		Line:      []byte("B"),
-		Timestamp: time.Time{},
-	})
-
-	// no ticks, guarantee batch by size (and chan close)
-	stream.Close()
-
-	argument := <-mockClient.putLogEventsArgument
-	if argument == nil {
-		t.Fatal("Expected non-nil PutLogEventsInput")
-	}
-
-	// Should total to the maximum allowed bytes.
-	eventBytes := 0
-	for _, event := range argument.LogEvents {
-		eventBytes += effectiveLen(*event.Message)
-	}
-	eventsOverhead := len(argument.LogEvents) * perEventBytes
-	payloadTotal := eventBytes + eventsOverhead
-	// lowestMaxBatch allows the payload to be offset if the messages
-	// don't lend themselves to align with the maximum event size.
-	lowestMaxBatch := maximumBytesPerPut - maximumBytesPerEvent
-
-	if payloadTotal > maximumBytesPerPut {
-		t.Errorf("Expected <= %d bytes but was %d", maximumBytesPerPut, payloadTotal)
-	}
-	if payloadTotal < lowestMaxBatch {
-		t.Errorf("Batch to be no less than %d but was %d", lowestMaxBatch, payloadTotal)
-	}
-
-	argument = <-mockClient.putLogEventsArgument
-	message := *argument.LogEvents[len(argument.LogEvents)-1].Message
-	if message[len(message)-1:] != "B" {
-		t.Errorf("Expected message to be %s but was %s", "B", message[len(message)-1:])
-	}
-}
-
-func TestCollectBatchWithDuplicateTimestamps(t *testing.T) {
-	mockClient := newMockClient()
-	stream := &logStream{
-		client:        mockClient,
-		logGroupName:  groupName,
-		logStreamName: streamName,
-		sequenceToken: aws.String(sequenceToken),
-		messages:      make(chan *logger.Message),
-	}
-	mockClient.putLogEventsResult <- &putLogEventsResult{
-		successResult: &cloudwatchlogs.PutLogEventsOutput{
-			NextSequenceToken: aws.String(nextSequenceToken),
-		},
-	}
-	ticks := make(chan time.Time)
-	newTicker = func(_ time.Duration) *time.Ticker {
-		return &time.Ticker{
-			C: ticks,
-		}
-	}
-
-	d := make(chan bool)
-	close(d)
-	go stream.collectBatch(d)
-
-	var expectedEvents []*cloudwatchlogs.InputLogEvent
-	times := maximumLogEventsPerPut
-	timestamp := time.Now()
-	for i := 0; i < times; i++ {
-		line := fmt.Sprintf("%d", i)
-		if i%2 == 0 {
-			timestamp.Add(1 * time.Nanosecond)
-		}
-		stream.Log(&logger.Message{
-			Line:      []byte(line),
-			Timestamp: timestamp,
-		})
-		expectedEvents = append(expectedEvents, &cloudwatchlogs.InputLogEvent{
-			Message:   aws.String(line),
-			Timestamp: aws.Int64(timestamp.UnixNano() / int64(time.Millisecond)),
-		})
-	}
-
-	ticks <- time.Time{}
-	stream.Close()
-
-	argument := <-mockClient.putLogEventsArgument
-	if argument == nil {
-		t.Fatal("Expected non-nil PutLogEventsInput")
-	}
-	if len(argument.LogEvents) != times {
-		t.Errorf("Expected LogEvents to contain %d elements, but contains %d", times, len(argument.LogEvents))
-	}
-	for i := 0; i < times; i++ {
-		if !reflect.DeepEqual(*argument.LogEvents[i], *expectedEvents[i]) {
-			t.Errorf("Expected event to be %v but was %v", *expectedEvents[i], *argument.LogEvents[i])
-		}
-	}
-}
-
-func TestParseLogOptionsMultilinePattern(t *testing.T) {
-	info := logger.Info{
-		Config: map[string]string{
-			multilinePatternKey: "^xxxx",
-		},
-	}
-
-	multilinePattern, err := parseMultilineOptions(info)
-	assert.Check(t, err, "Received unexpected error")
-	assert.Check(t, multilinePattern.MatchString("xxxx"), "No multiline pattern match found")
-}
-
-func TestParseLogOptionsDatetimeFormat(t *testing.T) {
-	datetimeFormatTests := []struct {
-		format string
-		match  string
-	}{
-		{"%d/%m/%y %a %H:%M:%S%L %Z", "31/12/10 Mon 08:42:44.345 NZDT"},
-		{"%Y-%m-%d %A %I:%M:%S.%f%p%z", "2007-12-04 Monday 08:42:44.123456AM+1200"},
-		{"%b|%b|%b|%b|%b|%b|%b|%b|%b|%b|%b|%b", "Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec"},
-		{"%B|%B|%B|%B|%B|%B|%B|%B|%B|%B|%B|%B", "January|February|March|April|May|June|July|August|September|October|November|December"},
-		{"%A|%A|%A|%A|%A|%A|%A", "Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday"},
-		{"%a|%a|%a|%a|%a|%a|%a", "Mon|Tue|Wed|Thu|Fri|Sat|Sun"},
-		{"Day of the week: %w, Day of the year: %j", "Day of the week: 4, Day of the year: 091"},
-	}
-	for _, dt := range datetimeFormatTests {
-		t.Run(dt.match, func(t *testing.T) {
-			info := logger.Info{
-				Config: map[string]string{
-					datetimeFormatKey: dt.format,
-				},
-			}
-			multilinePattern, err := parseMultilineOptions(info)
-			assert.Check(t, err, "Received unexpected error")
-			assert.Check(t, multilinePattern.MatchString(dt.match), "No multiline pattern match found")
-		})
-	}
-}
-
-func TestValidateLogOptionsDatetimeFormatAndMultilinePattern(t *testing.T) {
-	cfg := map[string]string{
-		multilinePatternKey: "^xxxx",
-		datetimeFormatKey:   "%Y-%m-%d",
-		logGroupKey:         groupName,
-	}
-	conflictingLogOptionsError := "you cannot configure log opt 'awslogs-datetime-format' and 'awslogs-multiline-pattern' at the same time"
-
-	err := ValidateLogOpt(cfg)
-	assert.Check(t, err != nil, "Expected an error")
-	assert.Check(t, is.Equal(err.Error(), conflictingLogOptionsError), "Received invalid error")
-}
-
-func TestValidateLogOptionsForceFlushIntervalSeconds(t *testing.T) {
-	tests := []struct {
-		input     string
-		shouldErr bool
-	}{
-		{"0", true},
-		{"-1", true},
-		{"a", true},
-		{"10", false},
-	}
-
-	for _, tc := range tests {
-		t.Run(tc.input, func(t *testing.T) {
-			cfg := map[string]string{
-				forceFlushIntervalKey: tc.input,
-				logGroupKey:           groupName,
-			}
-
-			err := ValidateLogOpt(cfg)
-			if tc.shouldErr {
-				expectedErr := "must specify a positive integer for log opt 'awslogs-force-flush-interval-seconds': " + tc.input
-				assert.Error(t, err, expectedErr)
-			} else {
-				assert.NilError(t, err)
-			}
-		})
-	}
-}
-
-func TestValidateLogOptionsMaxBufferedEvents(t *testing.T) {
-	tests := []struct {
-		input     string
-		shouldErr bool
-	}{
-		{"0", true},
-		{"-1", true},
-		{"a", true},
-		{"10", false},
-	}
-
-	for _, tc := range tests {
-		t.Run(tc.input, func(t *testing.T) {
-			cfg := map[string]string{
-				maxBufferedEventsKey: tc.input,
-				logGroupKey:          groupName,
-			}
-
-			err := ValidateLogOpt(cfg)
-			if tc.shouldErr {
-				expectedErr := "must specify a positive integer for log opt 'awslogs-max-buffered-events': " + tc.input
-				assert.Error(t, err, expectedErr)
-			} else {
-				assert.NilError(t, err)
-			}
-		})
-	}
-}
-
-func TestCreateTagSuccess(t *testing.T) {
-	mockClient := newMockClient()
-	info := logger.Info{
-		ContainerName: "/test-container",
-		ContainerID:   "container-abcdefghijklmnopqrstuvwxyz01234567890",
-		Config:        map[string]string{"tag": "{{.Name}}/{{.FullID}}"},
-	}
-	logStreamName, e := loggerutils.ParseLogTag(info, loggerutils.DefaultTemplate)
-	if e != nil {
-		t.Errorf("Error generating tag: %q", e)
-	}
-	stream := &logStream{
-		client:        mockClient,
-		logGroupName:  groupName,
-		logStreamName: logStreamName,
-	}
-	mockClient.createLogStreamResult <- &createLogStreamResult{}
-
-	err := stream.create()
-
-	assert.NilError(t, err)
-	argument := <-mockClient.createLogStreamArgument
-
-	if *argument.LogStreamName != "test-container/container-abcdefghijklmnopqrstuvwxyz01234567890" {
-		t.Errorf("Expected LogStreamName to be %s", "test-container/container-abcdefghijklmnopqrstuvwxyz01234567890")
-	}
-}
-
-func BenchmarkUnwrapEvents(b *testing.B) {
-	events := make([]wrappedEvent, maximumLogEventsPerPut)
-	for i := 0; i < maximumLogEventsPerPut; i++ {
-		mes := strings.Repeat("0", maximumBytesPerEvent)
-		events[i].inputLogEvent = &cloudwatchlogs.InputLogEvent{
-			Message: &mes,
-		}
-	}
-
-	b.ResetTimer()
-	for i := 0; i < b.N; i++ {
-		res := unwrapEvents(events)
-		assert.Check(b, is.Len(res, maximumLogEventsPerPut))
-	}
-}
-
-func TestNewAWSLogsClientCredentialEndpointDetect(t *testing.T) {
-	// required for the cloudwatchlogs client
-	os.Setenv("AWS_REGION", "us-west-2")
-	defer os.Unsetenv("AWS_REGION")
-
-	credsResp := `{
-		"AccessKeyId" :    "test-access-key-id",
-		"SecretAccessKey": "test-secret-access-key"
-		}`
-
-	expectedAccessKeyID := "test-access-key-id"
-	expectedSecretAccessKey := "test-secret-access-key"
-
-	testServer := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
-		w.Header().Set("Content-Type", "application/json")
-		fmt.Fprintln(w, credsResp)
-	}))
-	defer testServer.Close()
-
-	// set the SDKEndpoint in the driver
-	newSDKEndpoint = testServer.URL
-
-	info := logger.Info{
-		Config: map[string]string{},
-	}
-
-	info.Config["awslogs-credentials-endpoint"] = "/creds"
-
-	c, err := newAWSLogsClient(info)
-	assert.Check(t, err)
-
-	client := c.(*cloudwatchlogs.CloudWatchLogs)
-
-	creds, err := client.Config.Credentials.Get()
-	assert.Check(t, err)
-
-	assert.Check(t, is.Equal(expectedAccessKeyID, creds.AccessKeyID))
-	assert.Check(t, is.Equal(expectedSecretAccessKey, creds.SecretAccessKey))
-}
-
-func TestNewAWSLogsClientCredentialEnvironmentVariable(t *testing.T) {
-	// required for the cloudwatchlogs client
-	os.Setenv("AWS_REGION", "us-west-2")
-	defer os.Unsetenv("AWS_REGION")
-
-	expectedAccessKeyID := "test-access-key-id"
-	expectedSecretAccessKey := "test-secret-access-key"
-
-	os.Setenv("AWS_ACCESS_KEY_ID", expectedAccessKeyID)
-	defer os.Unsetenv("AWS_ACCESS_KEY_ID")
-
-	os.Setenv("AWS_SECRET_ACCESS_KEY", expectedSecretAccessKey)
-	defer os.Unsetenv("AWS_SECRET_ACCESS_KEY")
-
-	info := logger.Info{
-		Config: map[string]string{},
-	}
-
-	c, err := newAWSLogsClient(info)
-	assert.Check(t, err)
-
-	client := c.(*cloudwatchlogs.CloudWatchLogs)
-
-	creds, err := client.Config.Credentials.Get()
-	assert.Check(t, err)
-
-	assert.Check(t, is.Equal(expectedAccessKeyID, creds.AccessKeyID))
-	assert.Check(t, is.Equal(expectedSecretAccessKey, creds.SecretAccessKey))
-}
-
-func TestNewAWSLogsClientCredentialSharedFile(t *testing.T) {
-	// required for the cloudwatchlogs client
-	os.Setenv("AWS_REGION", "us-west-2")
-	defer os.Unsetenv("AWS_REGION")
-
-	expectedAccessKeyID := "test-access-key-id"
-	expectedSecretAccessKey := "test-secret-access-key"
-
-	contentStr := `
-	[default]
-	aws_access_key_id = "test-access-key-id"
-	aws_secret_access_key =  "test-secret-access-key"
-	`
-	content := []byte(contentStr)
-
-	tmpfile, err := ioutil.TempFile("", "example")
-	defer os.Remove(tmpfile.Name()) // clean up
-	assert.Check(t, err)
-
-	_, err = tmpfile.Write(content)
-	assert.Check(t, err)
-
-	err = tmpfile.Close()
-	assert.Check(t, err)
-
-	os.Unsetenv("AWS_ACCESS_KEY_ID")
-	os.Unsetenv("AWS_SECRET_ACCESS_KEY")
-
-	os.Setenv("AWS_SHARED_CREDENTIALS_FILE", tmpfile.Name())
-	defer os.Unsetenv("AWS_SHARED_CREDENTIALS_FILE")
-
-	info := logger.Info{
-		Config: map[string]string{},
-	}
-
-	c, err := newAWSLogsClient(info)
-	assert.Check(t, err)
-
-	client := c.(*cloudwatchlogs.CloudWatchLogs)
-
-	creds, err := client.Config.Credentials.Get()
-	assert.Check(t, err)
-
-	assert.Check(t, is.Equal(expectedAccessKeyID, creds.AccessKeyID))
-	assert.Check(t, is.Equal(expectedSecretAccessKey, creds.SecretAccessKey))
-}
diff --git a/components/engine/daemon/logger/awslogs/cwlogsiface_mock_test.go b/components/engine/daemon/logger/awslogs/cwlogsiface_mock_test.go
deleted file mode 100644
index 155e602..0000000
--- a/components/engine/daemon/logger/awslogs/cwlogsiface_mock_test.go
+++ /dev/null
@@ -1,119 +0,0 @@
-package awslogs // import "github.com/docker/docker/daemon/logger/awslogs"
-
-import (
-	"fmt"
-
-	"github.com/aws/aws-sdk-go/service/cloudwatchlogs"
-)
-
-type mockcwlogsclient struct {
-	createLogGroupArgument  chan *cloudwatchlogs.CreateLogGroupInput
-	createLogGroupResult    chan *createLogGroupResult
-	createLogStreamArgument chan *cloudwatchlogs.CreateLogStreamInput
-	createLogStreamResult   chan *createLogStreamResult
-	putLogEventsArgument    chan *cloudwatchlogs.PutLogEventsInput
-	putLogEventsResult      chan *putLogEventsResult
-}
-
-type createLogGroupResult struct {
-	successResult *cloudwatchlogs.CreateLogGroupOutput
-	errorResult   error
-}
-
-type createLogStreamResult struct {
-	successResult *cloudwatchlogs.CreateLogStreamOutput
-	errorResult   error
-}
-
-type putLogEventsResult struct {
-	successResult *cloudwatchlogs.PutLogEventsOutput
-	errorResult   error
-}
-
-func newMockClient() *mockcwlogsclient {
-	return &mockcwlogsclient{
-		createLogGroupArgument:  make(chan *cloudwatchlogs.CreateLogGroupInput, 1),
-		createLogGroupResult:    make(chan *createLogGroupResult, 1),
-		createLogStreamArgument: make(chan *cloudwatchlogs.CreateLogStreamInput, 1),
-		createLogStreamResult:   make(chan *createLogStreamResult, 1),
-		putLogEventsArgument:    make(chan *cloudwatchlogs.PutLogEventsInput, 1),
-		putLogEventsResult:      make(chan *putLogEventsResult, 1),
-	}
-}
-
-func newMockClientBuffered(buflen int) *mockcwlogsclient {
-	return &mockcwlogsclient{
-		createLogStreamArgument: make(chan *cloudwatchlogs.CreateLogStreamInput, buflen),
-		createLogStreamResult:   make(chan *createLogStreamResult, buflen),
-		putLogEventsArgument:    make(chan *cloudwatchlogs.PutLogEventsInput, buflen),
-		putLogEventsResult:      make(chan *putLogEventsResult, buflen),
-	}
-}
-
-func (m *mockcwlogsclient) CreateLogGroup(input *cloudwatchlogs.CreateLogGroupInput) (*cloudwatchlogs.CreateLogGroupOutput, error) {
-	m.createLogGroupArgument <- input
-	output := <-m.createLogGroupResult
-	return output.successResult, output.errorResult
-}
-
-func (m *mockcwlogsclient) CreateLogStream(input *cloudwatchlogs.CreateLogStreamInput) (*cloudwatchlogs.CreateLogStreamOutput, error) {
-	m.createLogStreamArgument <- input
-	output := <-m.createLogStreamResult
-	return output.successResult, output.errorResult
-}
-
-func (m *mockcwlogsclient) PutLogEvents(input *cloudwatchlogs.PutLogEventsInput) (*cloudwatchlogs.PutLogEventsOutput, error) {
-	events := make([]*cloudwatchlogs.InputLogEvent, len(input.LogEvents))
-	copy(events, input.LogEvents)
-	m.putLogEventsArgument <- &cloudwatchlogs.PutLogEventsInput{
-		LogEvents:     events,
-		SequenceToken: input.SequenceToken,
-		LogGroupName:  input.LogGroupName,
-		LogStreamName: input.LogStreamName,
-	}
-
-	// Intended mock output
-	output := <-m.putLogEventsResult
-
-	// Checked enforced limits in mock
-	totalBytes := 0
-	for _, evt := range events {
-		if evt.Message == nil {
-			continue
-		}
-		eventBytes := len([]byte(*evt.Message))
-		if eventBytes > maximumBytesPerEvent {
-			// exceeded per event message size limits
-			return nil, fmt.Errorf("maximum bytes per event exceeded: Event too large %d, max allowed: %d", eventBytes, maximumBytesPerEvent)
-		}
-		// total event bytes including overhead
-		totalBytes += eventBytes + perEventBytes
-	}
-
-	if totalBytes > maximumBytesPerPut {
-		// exceeded per put maximum size limit
-		return nil, fmt.Errorf("maximum bytes per put exceeded: Upload too large %d, max allowed: %d", totalBytes, maximumBytesPerPut)
-	}
-
-	return output.successResult, output.errorResult
-}
-
-type mockmetadataclient struct {
-	regionResult chan *regionResult
-}
-
-type regionResult struct {
-	successResult string
-	errorResult   error
-}
-
-func newMockMetadataClient() *mockmetadataclient {
-	return &mockmetadataclient{
-		regionResult: make(chan *regionResult, 1),
-	}
-}
-
-func (m *mockmetadataclient) Region() (string, error) {
-	output := <-m.regionResult
-	return output.successResult, output.errorResult
-}
diff --git a/components/engine/daemon/logger/copier_test.go b/components/engine/daemon/logger/copier_test.go
deleted file mode 100644
index d09450b..0000000
--- a/components/engine/daemon/logger/copier_test.go
+++ /dev/null
@@ -1,484 +0,0 @@
-package logger // import "github.com/docker/docker/daemon/logger"
-
-import (
-	"bytes"
-	"encoding/json"
-	"fmt"
-	"io"
-	"os"
-	"strings"
-	"sync"
-	"testing"
-	"time"
-)
-
-type TestLoggerJSON struct {
-	*json.Encoder
-	mu    sync.Mutex
-	delay time.Duration
-}
-
-func (l *TestLoggerJSON) Log(m *Message) error {
-	if l.delay > 0 {
-		time.Sleep(l.delay)
-	}
-	l.mu.Lock()
-	defer l.mu.Unlock()
-	return l.Encode(m)
-}
-
-func (l *TestLoggerJSON) Close() error { return nil }
-
-func (l *TestLoggerJSON) Name() string { return "json" }
-
-type TestSizedLoggerJSON struct {
-	*json.Encoder
-	mu sync.Mutex
-}
-
-func (l *TestSizedLoggerJSON) Log(m *Message) error {
-	l.mu.Lock()
-	defer l.mu.Unlock()
-	return l.Encode(m)
-}
-
-func (*TestSizedLoggerJSON) Close() error { return nil }
-
-func (*TestSizedLoggerJSON) Name() string { return "sized-json" }
-
-func (*TestSizedLoggerJSON) BufSize() int {
-	return 32 * 1024
-}
-
-func TestCopier(t *testing.T) {
-	stdoutLine := "Line that thinks that it is log line from docker stdout"
-	stderrLine := "Line that thinks that it is log line from docker stderr"
-	stdoutTrailingLine := "stdout trailing line"
-	stderrTrailingLine := "stderr trailing line"
-
-	var stdout bytes.Buffer
-	var stderr bytes.Buffer
-	for i := 0; i < 30; i++ {
-		if _, err := stdout.WriteString(stdoutLine + "\n"); err != nil {
-			t.Fatal(err)
-		}
-		if _, err := stderr.WriteString(stderrLine + "\n"); err != nil {
-			t.Fatal(err)
-		}
-	}
-
-	// Test remaining lines without line-endings
-	if _, err := stdout.WriteString(stdoutTrailingLine); err != nil {
-		t.Fatal(err)
-	}
-	if _, err := stderr.WriteString(stderrTrailingLine); err != nil {
-		t.Fatal(err)
-	}
-
-	var jsonBuf bytes.Buffer
-
-	jsonLog := &TestLoggerJSON{Encoder: json.NewEncoder(&jsonBuf)}
-
-	c := NewCopier(
-		map[string]io.Reader{
-			"stdout": &stdout,
-			"stderr": &stderr,
-		},
-		jsonLog)
-	c.Run()
-	wait := make(chan struct{})
-	go func() {
-		c.Wait()
-		close(wait)
-	}()
-	select {
-	case <-time.After(1 * time.Second):
-		t.Fatal("Copier failed to do its work in 1 second")
-	case <-wait:
-	}
-	dec := json.NewDecoder(&jsonBuf)
-	for {
-		var msg Message
-		if err := dec.Decode(&msg); err != nil {
-			if err == io.EOF {
-				break
-			}
-			t.Fatal(err)
-		}
-		if msg.Source != "stdout" && msg.Source != "stderr" {
-			t.Fatalf("Wrong Source: %q, should be %q or %q", msg.Source, "stdout", "stderr")
-		}
-		if msg.Source == "stdout" {
-			if string(msg.Line) != stdoutLine && string(msg.Line) != stdoutTrailingLine {
-				t.Fatalf("Wrong Line: %q, expected %q or %q", msg.Line, stdoutLine, stdoutTrailingLine)
-			}
-		}
-		if msg.Source == "stderr" {
-			if string(msg.Line) != stderrLine && string(msg.Line) != stderrTrailingLine {
-				t.Fatalf("Wrong Line: %q, expected %q or %q", msg.Line, stderrLine, stderrTrailingLine)
-			}
-		}
-	}
-}
-
-// TestCopierLongLines tests long lines without line breaks
-func TestCopierLongLines(t *testing.T) {
-	// Long lines (should be split at "defaultBufSize")
-	stdoutLongLine := strings.Repeat("a", defaultBufSize)
-	stderrLongLine := strings.Repeat("b", defaultBufSize)
-	stdoutTrailingLine := "stdout trailing line"
-	stderrTrailingLine := "stderr trailing line"
-
-	var stdout bytes.Buffer
-	var stderr bytes.Buffer
-
-	for i := 0; i < 3; i++ {
-		if _, err := stdout.WriteString(stdoutLongLine); err != nil {
-			t.Fatal(err)
-		}
-		if _, err := stderr.WriteString(stderrLongLine); err != nil {
-			t.Fatal(err)
-		}
-	}
-
-	if _, err := stdout.WriteString(stdoutTrailingLine); err != nil {
-		t.Fatal(err)
-	}
-	if _, err := stderr.WriteString(stderrTrailingLine); err != nil {
-		t.Fatal(err)
-	}
-
-	var jsonBuf bytes.Buffer
-
-	jsonLog := &TestLoggerJSON{Encoder: json.NewEncoder(&jsonBuf)}
-
-	c := NewCopier(
-		map[string]io.Reader{
-			"stdout": &stdout,
-			"stderr": &stderr,
-		},
-		jsonLog)
-	c.Run()
-	wait := make(chan struct{})
-	go func() {
-		c.Wait()
-		close(wait)
-	}()
-	select {
-	case <-time.After(1 * time.Second):
-		t.Fatal("Copier failed to do its work in 1 second")
-	case <-wait:
-	}
-	dec := json.NewDecoder(&jsonBuf)
-	for {
-		var msg Message
-		if err := dec.Decode(&msg); err != nil {
-			if err == io.EOF {
-				break
-			}
-			t.Fatal(err)
-		}
-		if msg.Source != "stdout" && msg.Source != "stderr" {
-			t.Fatalf("Wrong Source: %q, should be %q or %q", msg.Source, "stdout", "stderr")
-		}
-		if msg.Source == "stdout" {
-			if string(msg.Line) != stdoutLongLine && string(msg.Line) != stdoutTrailingLine {
-				t.Fatalf("Wrong Line: %q, expected 'stdoutLongLine' or 'stdoutTrailingLine'", msg.Line)
-			}
-		}
-		if msg.Source == "stderr" {
-			if string(msg.Line) != stderrLongLine && string(msg.Line) != stderrTrailingLine {
-				t.Fatalf("Wrong Line: %q, expected 'stderrLongLine' or 'stderrTrailingLine'", msg.Line)
-			}
-		}
-	}
-}
-
-func TestCopierSlow(t *testing.T) {
-	stdoutLine := "Line that thinks that it is log line from docker stdout"
-	var stdout bytes.Buffer
-	for i := 0; i < 30; i++ {
-		if _, err := stdout.WriteString(stdoutLine + "\n"); err != nil {
-			t.Fatal(err)
-		}
-	}
-
-	var jsonBuf bytes.Buffer
-	//encoder := &encodeCloser{Encoder: json.NewEncoder(&jsonBuf)}
-	jsonLog := &TestLoggerJSON{Encoder: json.NewEncoder(&jsonBuf), delay: 100 * time.Millisecond}
-
-	c := NewCopier(map[string]io.Reader{"stdout": &stdout}, jsonLog)
-	c.Run()
-	wait := make(chan struct{})
-	go func() {
-		c.Wait()
-		close(wait)
-	}()
-	<-time.After(150 * time.Millisecond)
-	c.Close()
-	select {
-	case <-time.After(200 * time.Millisecond):
-		t.Fatal("failed to exit in time after the copier is closed")
-	case <-wait:
-	}
-}
-
-func TestCopierWithSized(t *testing.T) {
-	var jsonBuf bytes.Buffer
-	expectedMsgs := 2
-	sizedLogger := &TestSizedLoggerJSON{Encoder: json.NewEncoder(&jsonBuf)}
-	logbuf := bytes.NewBufferString(strings.Repeat(".", sizedLogger.BufSize()*expectedMsgs))
-	c := NewCopier(map[string]io.Reader{"stdout": logbuf}, sizedLogger)
-
-	c.Run()
-	// Wait for Copier to finish writing to the buffered logger.
-	c.Wait()
-	c.Close()
-
-	recvdMsgs := 0
-	dec := json.NewDecoder(&jsonBuf)
-	for {
-		var msg Message
-		if err := dec.Decode(&msg); err != nil {
-			if err == io.EOF {
-				break
-			}
-			t.Fatal(err)
-		}
-		if msg.Source != "stdout" {
-			t.Fatalf("Wrong Source: %q, should be %q", msg.Source, "stdout")
-		}
-		if len(msg.Line) != sizedLogger.BufSize() {
-			t.Fatalf("Line was not of expected max length %d, was %d", sizedLogger.BufSize(), len(msg.Line))
-		}
-		recvdMsgs++
-	}
-	if recvdMsgs != expectedMsgs {
-		t.Fatalf("expected to receive %d messages, actually received %d", expectedMsgs, recvdMsgs)
-	}
-}
-
-func checkIdentical(t *testing.T, msg Message, expectedID string, expectedTS time.Time) {
-	if msg.PLogMetaData.ID != expectedID {
-		t.Fatalf("IDs are not he same across partials. Expected: %s Received: %s",
-			expectedID, msg.PLogMetaData.ID)
-	}
-	if msg.Timestamp != expectedTS {
-		t.Fatalf("Timestamps are not the same across partials. Expected: %v Received: %v",
-			expectedTS.Format(time.UnixDate), msg.Timestamp.Format(time.UnixDate))
-	}
-}
-
-// Have long lines and make sure that it comes out with PartialMetaData
-func TestCopierWithPartial(t *testing.T) {
-	stdoutLongLine := strings.Repeat("a", defaultBufSize)
-	stderrLongLine := strings.Repeat("b", defaultBufSize)
-	stdoutTrailingLine := "stdout trailing line"
-	stderrTrailingLine := "stderr trailing line"
-	normalStr := "This is an impartial message :)"
-
-	var stdout bytes.Buffer
-	var stderr bytes.Buffer
-	var normalMsg bytes.Buffer
-
-	for i := 0; i < 3; i++ {
-		if _, err := stdout.WriteString(stdoutLongLine); err != nil {
-			t.Fatal(err)
-		}
-		if _, err := stderr.WriteString(stderrLongLine); err != nil {
-			t.Fatal(err)
-		}
-	}
-
-	if _, err := stdout.WriteString(stdoutTrailingLine + "\n"); err != nil {
-		t.Fatal(err)
-	}
-	if _, err := stderr.WriteString(stderrTrailingLine + "\n"); err != nil {
-		t.Fatal(err)
-	}
-	if _, err := normalMsg.WriteString(normalStr + "\n"); err != nil {
-		t.Fatal(err)
-	}
-
-	var jsonBuf bytes.Buffer
-
-	jsonLog := &TestLoggerJSON{Encoder: json.NewEncoder(&jsonBuf)}
-
-	c := NewCopier(
-		map[string]io.Reader{
-			"stdout": &stdout,
-			"normal": &normalMsg,
-			"stderr": &stderr,
-		},
-		jsonLog)
-	c.Run()
-	wait := make(chan struct{})
-	go func() {
-		c.Wait()
-		close(wait)
-	}()
-	select {
-	case <-time.After(1 * time.Second):
-		t.Fatal("Copier failed to do its work in 1 second")
-	case <-wait:
-	}
-
-	dec := json.NewDecoder(&jsonBuf)
-	expectedMsgs := 9
-	recvMsgs := 0
-	var expectedPartID1, expectedPartID2 string
-	var expectedTS1, expectedTS2 time.Time
-
-	for {
-		var msg Message
-
-		if err := dec.Decode(&msg); err != nil {
-			if err == io.EOF {
-				break
-			}
-			t.Fatal(err)
-		}
-		if msg.Source != "stdout" && msg.Source != "stderr" && msg.Source != "normal" {
-			t.Fatalf("Wrong Source: %q, should be %q or %q or %q", msg.Source, "stdout", "stderr", "normal")
-		}
-
-		if msg.Source == "stdout" {
-			if string(msg.Line) != stdoutLongLine && string(msg.Line) != stdoutTrailingLine {
-				t.Fatalf("Wrong Line: %q, expected 'stdoutLongLine' or 'stdoutTrailingLine'", msg.Line)
-			}
-
-			if msg.PLogMetaData.ID == "" {
-				t.Fatalf("Expected partial metadata. Got nothing")
-			}
-
-			if msg.PLogMetaData.Ordinal == 1 {
-				expectedPartID1 = msg.PLogMetaData.ID
-				expectedTS1 = msg.Timestamp
-			} else {
-				checkIdentical(t, msg, expectedPartID1, expectedTS1)
-			}
-			if msg.PLogMetaData.Ordinal == 4 && !msg.PLogMetaData.Last {
-				t.Fatalf("Last is not set for last chunk")
-			}
-		}
-
-		if msg.Source == "stderr" {
-			if string(msg.Line) != stderrLongLine && string(msg.Line) != stderrTrailingLine {
-				t.Fatalf("Wrong Line: %q, expected 'stderrLongLine' or 'stderrTrailingLine'", msg.Line)
-			}
-
-			if msg.PLogMetaData.ID == "" {
-				t.Fatalf("Expected partial metadata. Got nothing")
-			}
-
-			if msg.PLogMetaData.Ordinal == 1 {
-				expectedPartID2 = msg.PLogMetaData.ID
-				expectedTS2 = msg.Timestamp
-			} else {
-				checkIdentical(t, msg, expectedPartID2, expectedTS2)
-			}
-			if msg.PLogMetaData.Ordinal == 4 && !msg.PLogMetaData.Last {
-				t.Fatalf("Last is not set for last chunk")
-			}
-		}
-
-		if msg.Source == "normal" && msg.PLogMetaData != nil {
-			t.Fatalf("Normal messages should not have PartialLogMetaData")
-		}
-		recvMsgs++
-	}
-
-	if expectedMsgs != recvMsgs {
-		t.Fatalf("Expected msgs: %d Recv msgs: %d", expectedMsgs, recvMsgs)
-	}
-}
-
-type BenchmarkLoggerDummy struct {
-}
-
-func (l *BenchmarkLoggerDummy) Log(m *Message) error { PutMessage(m); return nil }
-
-func (l *BenchmarkLoggerDummy) Close() error { return nil }
-
-func (l *BenchmarkLoggerDummy) Name() string { return "dummy" }
-
-func BenchmarkCopier64(b *testing.B) {
-	benchmarkCopier(b, 1<<6)
-}
-func BenchmarkCopier128(b *testing.B) {
-	benchmarkCopier(b, 1<<7)
-}
-func BenchmarkCopier256(b *testing.B) {
-	benchmarkCopier(b, 1<<8)
-}
-func BenchmarkCopier512(b *testing.B) {
-	benchmarkCopier(b, 1<<9)
-}
-func BenchmarkCopier1K(b *testing.B) {
-	benchmarkCopier(b, 1<<10)
-}
-func BenchmarkCopier2K(b *testing.B) {
-	benchmarkCopier(b, 1<<11)
-}
-func BenchmarkCopier4K(b *testing.B) {
-	benchmarkCopier(b, 1<<12)
-}
-func BenchmarkCopier8K(b *testing.B) {
-	benchmarkCopier(b, 1<<13)
-}
-func BenchmarkCopier16K(b *testing.B) {
-	benchmarkCopier(b, 1<<14)
-}
-func BenchmarkCopier32K(b *testing.B) {
-	benchmarkCopier(b, 1<<15)
-}
-func BenchmarkCopier64K(b *testing.B) {
-	benchmarkCopier(b, 1<<16)
-}
-func BenchmarkCopier128K(b *testing.B) {
-	benchmarkCopier(b, 1<<17)
-}
-func BenchmarkCopier256K(b *testing.B) {
-	benchmarkCopier(b, 1<<18)
-}
-
-func piped(b *testing.B, iterations int, delay time.Duration, buf []byte) io.Reader {
-	r, w, err := os.Pipe()
-	if err != nil {
-		b.Fatal(err)
-		return nil
-	}
-	go func() {
-		for i := 0; i < iterations; i++ {
-			time.Sleep(delay)
-			if n, err := w.Write(buf); err != nil || n != len(buf) {
-				if err != nil {
-					b.Fatal(err)
-				}
-				b.Fatal(fmt.Errorf("short write"))
-			}
-		}
-		w.Close()
-	}()
-	return r
-}
-
-func benchmarkCopier(b *testing.B, length int) {
-	b.StopTimer()
-	buf := []byte{'A'}
-	for len(buf) < length {
-		buf = append(buf, buf...)
-	}
-	buf = append(buf[:length-1], []byte{'\n'}...)
-	b.StartTimer()
-	for i := 0; i < b.N; i++ {
-		c := NewCopier(
-			map[string]io.Reader{
-				"buffer": piped(b, 10, time.Nanosecond, buf),
-			},
-			&BenchmarkLoggerDummy{})
-		c.Run()
-		c.Wait()
-		c.Close()
-	}
-}
diff --git a/components/engine/daemon/logger/etwlogs/etwlogs_windows.go b/components/engine/daemon/logger/etwlogs/etwlogs_windows.go
deleted file mode 100644
index 78d3477..0000000
--- a/components/engine/daemon/logger/etwlogs/etwlogs_windows.go
+++ /dev/null
@@ -1,168 +0,0 @@
-// Package etwlogs provides a log driver for forwarding container logs
-// as ETW events.(ETW stands for Event Tracing for Windows)
-// A client can then create an ETW listener to listen for events that are sent
-// by the ETW provider that we register, using the provider's GUID "a3693192-9ed6-46d2-a981-f8226c8363bd".
-// Here is an example of how to do this using the logman utility:
-// 1. logman start -ets DockerContainerLogs -p {a3693192-9ed6-46d2-a981-f8226c8363bd} 0 0 -o trace.etl
-// 2. Run container(s) and generate log messages
-// 3. logman stop -ets DockerContainerLogs
-// 4. You can then convert the etl log file to XML using: tracerpt -y trace.etl
-//
-// Each container log message generates an ETW event that also contains:
-// the container name and ID, the timestamp, and the stream type.
-package etwlogs // import "github.com/docker/docker/daemon/logger/etwlogs"
-
-import (
-	"errors"
-	"fmt"
-	"sync"
-	"unsafe"
-
-	"github.com/docker/docker/daemon/logger"
-	"github.com/sirupsen/logrus"
-	"golang.org/x/sys/windows"
-)
-
-type etwLogs struct {
-	containerName string
-	imageName     string
-	containerID   string
-	imageID       string
-}
-
-const (
-	name             = "etwlogs"
-	win32CallSuccess = 0
-)
-
-var (
-	modAdvapi32          = windows.NewLazySystemDLL("Advapi32.dll")
-	procEventRegister    = modAdvapi32.NewProc("EventRegister")
-	procEventWriteString = modAdvapi32.NewProc("EventWriteString")
-	procEventUnregister  = modAdvapi32.NewProc("EventUnregister")
-)
-var providerHandle windows.Handle
-var refCount int
-var mu sync.Mutex
-
-func init() {
-	providerHandle = windows.InvalidHandle
-	if err := logger.RegisterLogDriver(name, New); err != nil {
-		logrus.Fatal(err)
-	}
-}
-
-// New creates a new etwLogs logger for the given container and registers the EWT provider.
-func New(info logger.Info) (logger.Logger, error) {
-	if err := registerETWProvider(); err != nil {
-		return nil, err
-	}
-	logrus.Debugf("logging driver etwLogs configured for container: %s.", info.ContainerID)
-
-	return &etwLogs{
-		containerName: info.Name(),
-		imageName:     info.ContainerImageName,
-		containerID:   info.ContainerID,
-		imageID:       info.ContainerImageID,
-	}, nil
-}
-
-// Log logs the message to the ETW stream.
-func (etwLogger *etwLogs) Log(msg *logger.Message) error {
-	if providerHandle == windows.InvalidHandle {
-		// This should never be hit, if it is, it indicates a programming error.
-		errorMessage := "ETWLogs cannot log the message, because the event provider has not been registered."
-		logrus.Error(errorMessage)
-		return errors.New(errorMessage)
-	}
-	m := createLogMessage(etwLogger, msg)
-	logger.PutMessage(msg)
-	return callEventWriteString(m)
-}
-
-// Close closes the logger by unregistering the ETW provider.
-func (etwLogger *etwLogs) Close() error {
-	unregisterETWProvider()
-	return nil
-}
-
-func (etwLogger *etwLogs) Name() string {
-	return name
-}
-
-func createLogMessage(etwLogger *etwLogs, msg *logger.Message) string {
-	return fmt.Sprintf("container_name: %s, image_name: %s, container_id: %s, image_id: %s, source: %s, log: %s",
-		etwLogger.containerName,
-		etwLogger.imageName,
-		etwLogger.containerID,
-		etwLogger.imageID,
-		msg.Source,
-		msg.Line)
-}
-
-func registerETWProvider() error {
-	mu.Lock()
-	defer mu.Unlock()
-	if refCount == 0 {
-		var err error
-		if err = callEventRegister(); err != nil {
-			return err
-		}
-	}
-
-	refCount++
-	return nil
-}
-
-func unregisterETWProvider() {
-	mu.Lock()
-	defer mu.Unlock()
-	if refCount == 1 {
-		if callEventUnregister() {
-			refCount--
-			providerHandle = windows.InvalidHandle
-		}
-		// Not returning an error if EventUnregister fails, because etwLogs will continue to work
-	} else {
-		refCount--
-	}
-}
-
-func callEventRegister() error {
-	// The provider's GUID is {a3693192-9ed6-46d2-a981-f8226c8363bd}
-	guid := windows.GUID{
-		Data1: 0xa3693192,
-		Data2: 0x9ed6,
-		Data3: 0x46d2,
-		Data4: [8]byte{0xa9, 0x81, 0xf8, 0x22, 0x6c, 0x83, 0x63, 0xbd},
-	}
-
-	ret, _, _ := procEventRegister.Call(uintptr(unsafe.Pointer(&guid)), 0, 0, uintptr(unsafe.Pointer(&providerHandle)))
-	if ret != win32CallSuccess {
-		errorMessage := fmt.Sprintf("Failed to register ETW provider. Error: %d", ret)
-		logrus.Error(errorMessage)
-		return errors.New(errorMessage)
-	}
-	return nil
-}
-
-func callEventWriteString(message string) error {
-	utf16message, err := windows.UTF16FromString(message)
-
-	if err != nil {
-		return err
-	}
-
-	ret, _, _ := procEventWriteString.Call(uintptr(providerHandle), 0, 0, uintptr(unsafe.Pointer(&utf16message[0])))
-	if ret != win32CallSuccess {
-		errorMessage := fmt.Sprintf("ETWLogs provider failed to log message. Error: %d", ret)
-		logrus.Error(errorMessage)
-		return errors.New(errorMessage)
-	}
-	return nil
-}
-
-func callEventUnregister() bool {
-	ret, _, _ := procEventUnregister.Call(uintptr(providerHandle))
-	return ret == win32CallSuccess
-}
diff --git a/components/engine/daemon/logger/fluentd/fluentd.go b/components/engine/daemon/logger/fluentd/fluentd.go
deleted file mode 100644
index cf7f3e9..0000000
--- a/components/engine/daemon/logger/fluentd/fluentd.go
+++ /dev/null
@@ -1,266 +0,0 @@
-// Package fluentd provides the log driver for forwarding server logs
-// to fluentd endpoints.
-package fluentd // import "github.com/docker/docker/daemon/logger/fluentd"
-
-import (
-	"fmt"
-	"math"
-	"net"
-	"net/url"
-	"strconv"
-	"strings"
-	"time"
-
-	"github.com/docker/docker/daemon/logger"
-	"github.com/docker/docker/daemon/logger/loggerutils"
-	"github.com/docker/docker/pkg/urlutil"
-	"github.com/docker/go-units"
-	"github.com/fluent/fluent-logger-golang/fluent"
-	"github.com/pkg/errors"
-	"github.com/sirupsen/logrus"
-)
-
-type fluentd struct {
-	tag           string
-	containerID   string
-	containerName string
-	writer        *fluent.Fluent
-	extra         map[string]string
-}
-
-type location struct {
-	protocol string
-	host     string
-	port     int
-	path     string
-}
-
-const (
-	name = "fluentd"
-
-	defaultProtocol    = "tcp"
-	defaultHost        = "127.0.0.1"
-	defaultPort        = 24224
-	defaultBufferLimit = 1024 * 1024
-
-	// logger tries to reconnect 2**32 - 1 times
-	// failed (and panic) after 204 years [ 1.5 ** (2**32 - 1) - 1 seconds]
-	defaultRetryWait  = 1000
-	defaultMaxRetries = math.MaxInt32
-
-	addressKey            = "fluentd-address"
-	bufferLimitKey        = "fluentd-buffer-limit"
-	retryWaitKey          = "fluentd-retry-wait"
-	maxRetriesKey         = "fluentd-max-retries"
-	asyncConnectKey       = "fluentd-async-connect"
-	subSecondPrecisionKey = "fluentd-sub-second-precision"
-)
-
-func init() {
-	if err := logger.RegisterLogDriver(name, New); err != nil {
-		logrus.Fatal(err)
-	}
-	if err := logger.RegisterLogOptValidator(name, ValidateLogOpt); err != nil {
-		logrus.Fatal(err)
-	}
-}
-
-// New creates a fluentd logger using the configuration passed in on
-// the context. The supported context configuration variable is
-// fluentd-address.
-func New(info logger.Info) (logger.Logger, error) {
-	loc, err := parseAddress(info.Config[addressKey])
-	if err != nil {
-		return nil, err
-	}
-
-	tag, err := loggerutils.ParseLogTag(info, loggerutils.DefaultTemplate)
-	if err != nil {
-		return nil, err
-	}
-
-	extra, err := info.ExtraAttributes(nil)
-	if err != nil {
-		return nil, err
-	}
-
-	bufferLimit := defaultBufferLimit
-	if info.Config[bufferLimitKey] != "" {
-		bl64, err := units.RAMInBytes(info.Config[bufferLimitKey])
-		if err != nil {
-			return nil, err
-		}
-		bufferLimit = int(bl64)
-	}
-
-	retryWait := defaultRetryWait
-	if info.Config[retryWaitKey] != "" {
-		rwd, err := time.ParseDuration(info.Config[retryWaitKey])
-		if err != nil {
-			return nil, err
-		}
-		retryWait = int(rwd.Seconds() * 1000)
-	}
-
-	maxRetries := defaultMaxRetries
-	if info.Config[maxRetriesKey] != "" {
-		mr64, err := strconv.ParseUint(info.Config[maxRetriesKey], 10, strconv.IntSize)
-		if err != nil {
-			return nil, err
-		}
-		maxRetries = int(mr64)
-	}
-
-	asyncConnect := false
-	if info.Config[asyncConnectKey] != "" {
-		if asyncConnect, err = strconv.ParseBool(info.Config[asyncConnectKey]); err != nil {
-			return nil, err
-		}
-	}
-
-	subSecondPrecision := false
-	if info.Config[subSecondPrecisionKey] != "" {
-		if subSecondPrecision, err = strconv.ParseBool(info.Config[subSecondPrecisionKey]); err != nil {
-			return nil, err
-		}
-	}
-
-	fluentConfig := fluent.Config{
-		FluentPort:         loc.port,
-		FluentHost:         loc.host,
-		FluentNetwork:      loc.protocol,
-		FluentSocketPath:   loc.path,
-		BufferLimit:        bufferLimit,
-		RetryWait:          retryWait,
-		MaxRetry:           maxRetries,
-		Async:              asyncConnect,
-		SubSecondPrecision: subSecondPrecision,
-	}
-
-	logrus.WithField("container", info.ContainerID).WithField("config", fluentConfig).
-		Debug("logging driver fluentd configured")
-
-	log, err := fluent.New(fluentConfig)
-	if err != nil {
-		return nil, err
-	}
-	return &fluentd{
-		tag:           tag,
-		containerID:   info.ContainerID,
-		containerName: info.ContainerName,
-		writer:        log,
-		extra:         extra,
-	}, nil
-}
-
-func (f *fluentd) Log(msg *logger.Message) error {
-	data := map[string]string{
-		"container_id":   f.containerID,
-		"container_name": f.containerName,
-		"source":         msg.Source,
-		"log":            string(msg.Line),
-	}
-	for k, v := range f.extra {
-		data[k] = v
-	}
-	if msg.PLogMetaData != nil {
-		data["partial_message"] = "true"
-		data["partial_id"] = msg.PLogMetaData.ID
-		data["partial_ordinal"] = strconv.Itoa(msg.PLogMetaData.Ordinal)
-		data["partial_last"] = strconv.FormatBool(msg.PLogMetaData.Last)
-	}
-
-	ts := msg.Timestamp
-	logger.PutMessage(msg)
-	// fluent-logger-golang buffers logs from failures and disconnections,
-	// and these are transferred again automatically.
-	return f.writer.PostWithTime(f.tag, ts, data)
-}
-
-func (f *fluentd) Close() error {
-	return f.writer.Close()
-}
-
-func (f *fluentd) Name() string {
-	return name
-}
-
-// ValidateLogOpt looks for fluentd specific log option fluentd-address.
-func ValidateLogOpt(cfg map[string]string) error {
-	for key := range cfg {
-		switch key {
-		case "env":
-		case "env-regex":
-		case "labels":
-		case "tag":
-		case addressKey:
-		case bufferLimitKey:
-		case retryWaitKey:
-		case maxRetriesKey:
-		case asyncConnectKey:
-		case subSecondPrecisionKey:
-			// Accepted
-		default:
-			return fmt.Errorf("unknown log opt '%s' for fluentd log driver", key)
-		}
-	}
-
-	_, err := parseAddress(cfg[addressKey])
-	return err
-}
-
-func parseAddress(address string) (*location, error) {
-	if address == "" {
-		return &location{
-			protocol: defaultProtocol,
-			host:     defaultHost,
-			port:     defaultPort,
-			path:     "",
-		}, nil
-	}
-
-	protocol := defaultProtocol
-	givenAddress := address
-	if urlutil.IsTransportURL(address) {
-		url, err := url.Parse(address)
-		if err != nil {
-			return nil, errors.Wrapf(err, "invalid fluentd-address %s", givenAddress)
-		}
-		// unix and unixgram socket
-		if url.Scheme == "unix" || url.Scheme == "unixgram" {
-			return &location{
-				protocol: url.Scheme,
-				host:     "",
-				port:     0,
-				path:     url.Path,
-			}, nil
-		}
-		// tcp|udp
-		protocol = url.Scheme
-		address = url.Host
-	}
-
-	host, port, err := net.SplitHostPort(address)
-	if err != nil {
-		if !strings.Contains(err.Error(), "missing port in address") {
-			return nil, errors.Wrapf(err, "invalid fluentd-address %s", givenAddress)
-		}
-		return &location{
-			protocol: protocol,
-			host:     host,
-			port:     defaultPort,
-			path:     "",
-		}, nil
-	}
-
-	portnum, err := strconv.Atoi(port)
-	if err != nil {
-		return nil, errors.Wrapf(err, "invalid fluentd-address %s", givenAddress)
-	}
-	return &location{
-		protocol: protocol,
-		host:     host,
-		port:     portnum,
-		path:     "",
-	}, nil
-}
diff --git a/components/engine/daemon/logger/gcplogs/gcplogging.go b/components/engine/daemon/logger/gcplogs/gcplogging.go
deleted file mode 100644
index 1699f67..0000000
--- a/components/engine/daemon/logger/gcplogs/gcplogging.go
+++ /dev/null
@@ -1,244 +0,0 @@
-package gcplogs // import "github.com/docker/docker/daemon/logger/gcplogs"
-
-import (
-	"context"
-	"fmt"
-	"sync"
-	"sync/atomic"
-	"time"
-
-	"github.com/docker/docker/daemon/logger"
-
-	"cloud.google.com/go/compute/metadata"
-	"cloud.google.com/go/logging"
-	"github.com/sirupsen/logrus"
-	mrpb "google.golang.org/genproto/googleapis/api/monitoredres"
-)
-
-const (
-	name = "gcplogs"
-
-	projectOptKey  = "gcp-project"
-	logLabelsKey   = "labels"
-	logEnvKey      = "env"
-	logEnvRegexKey = "env-regex"
-	logCmdKey      = "gcp-log-cmd"
-	logZoneKey     = "gcp-meta-zone"
-	logNameKey     = "gcp-meta-name"
-	logIDKey       = "gcp-meta-id"
-)
-
-var (
-	// The number of logs the gcplogs driver has dropped.
-	droppedLogs uint64
-
-	onGCE bool
-
-	// instance metadata populated from the metadata server if available
-	projectID    string
-	zone         string
-	instanceName string
-	instanceID   string
-)
-
-func init() {
-
-	if err := logger.RegisterLogDriver(name, New); err != nil {
-		logrus.Fatal(err)
-	}
-
-	if err := logger.RegisterLogOptValidator(name, ValidateLogOpts); err != nil {
-		logrus.Fatal(err)
-	}
-}
-
-type gcplogs struct {
-	logger    *logging.Logger
-	instance  *instanceInfo
-	container *containerInfo
-}
-
-type dockerLogEntry struct {
-	Instance  *instanceInfo  `json:"instance,omitempty"`
-	Container *containerInfo `json:"container,omitempty"`
-	Message   string         `json:"message,omitempty"`
-}
-
-type instanceInfo struct {
-	Zone string `json:"zone,omitempty"`
-	Name string `json:"name,omitempty"`
-	ID   string `json:"id,omitempty"`
-}
-
-type containerInfo struct {
-	Name      string            `json:"name,omitempty"`
-	ID        string            `json:"id,omitempty"`
-	ImageName string            `json:"imageName,omitempty"`
-	ImageID   string            `json:"imageId,omitempty"`
-	Created   time.Time         `json:"created,omitempty"`
-	Command   string            `json:"command,omitempty"`
-	Metadata  map[string]string `json:"metadata,omitempty"`
-}
-
-var initGCPOnce sync.Once
-
-func initGCP() {
-	initGCPOnce.Do(func() {
-		onGCE = metadata.OnGCE()
-		if onGCE {
-			// These will fail on instances if the metadata service is
-			// down or the client is compiled with an API version that
-			// has been removed. Since these are not vital, let's ignore
-			// them and make their fields in the dockerLogEntry ,omitempty
-			projectID, _ = metadata.ProjectID()
-			zone, _ = metadata.Zone()
-			instanceName, _ = metadata.InstanceName()
-			instanceID, _ = metadata.InstanceID()
-		}
-	})
-}
-
-// New creates a new logger that logs to Google Cloud Logging using the application
-// default credentials.
-//
-// See https://developers.google.com/identity/protocols/application-default-credentials
-func New(info logger.Info) (logger.Logger, error) {
-	initGCP()
-
-	var project string
-	if projectID != "" {
-		project = projectID
-	}
-	if projectID, found := info.Config[projectOptKey]; found {
-		project = projectID
-	}
-	if project == "" {
-		return nil, fmt.Errorf("No project was specified and couldn't read project from the metadata server. Please specify a project")
-	}
-
-	// Issue #29344: gcplogs segfaults (static binary)
-	// If HOME is not set, logging.NewClient() will call os/user.Current() via oauth2/google.
-	// However, in static binary, os/user.Current() leads to segfault due to a glibc issue that won't be fixed
-	// in a short term. (golang/go#13470, https://sourceware.org/bugzilla/show_bug.cgi?id=19341)
-	// So we forcibly set HOME so as to avoid call to os/user/Current()
-	if err := ensureHomeIfIAmStatic(); err != nil {
-		return nil, err
-	}
-
-	c, err := logging.NewClient(context.Background(), project)
-	if err != nil {
-		return nil, err
-	}
-	var instanceResource *instanceInfo
-	if onGCE {
-		instanceResource = &instanceInfo{
-			Zone: zone,
-			Name: instanceName,
-			ID:   instanceID,
-		}
-	} else if info.Config[logZoneKey] != "" || info.Config[logNameKey] != "" || info.Config[logIDKey] != "" {
-		instanceResource = &instanceInfo{
-			Zone: info.Config[logZoneKey],
-			Name: info.Config[logNameKey],
-			ID:   info.Config[logIDKey],
-		}
-	}
-
-	options := []logging.LoggerOption{}
-	if instanceResource != nil {
-		vmMrpb := logging.CommonResource(
-			&mrpb.MonitoredResource{
-				Type: "gce_instance",
-				Labels: map[string]string{
-					"instance_id": instanceResource.ID,
-					"zone":        instanceResource.Zone,
-				},
-			},
-		)
-		options = []logging.LoggerOption{vmMrpb}
-	}
-	lg := c.Logger("gcplogs-docker-driver", options...)
-
-	if err := c.Ping(context.Background()); err != nil {
-		return nil, fmt.Errorf("unable to connect or authenticate with Google Cloud Logging: %v", err)
-	}
-
-	extraAttributes, err := info.ExtraAttributes(nil)
-	if err != nil {
-		return nil, err
-	}
-
-	l := &gcplogs{
-		logger: lg,
-		container: &containerInfo{
-			Name:      info.ContainerName,
-			ID:        info.ContainerID,
-			ImageName: info.ContainerImageName,
-			ImageID:   info.ContainerImageID,
-			Created:   info.ContainerCreated,
-			Metadata:  extraAttributes,
-		},
-	}
-
-	if info.Config[logCmdKey] == "true" {
-		l.container.Command = info.Command()
-	}
-
-	if instanceResource != nil {
-		l.instance = instanceResource
-	}
-
-	// The logger "overflows" at a rate of 10,000 logs per second and this
-	// overflow func is called. We want to surface the error to the user
-	// without overly spamming /var/log/docker.log so we log the first time
-	// we overflow and every 1000th time after.
-	c.OnError = func(err error) {
-		if err == logging.ErrOverflow {
-			if i := atomic.AddUint64(&droppedLogs, 1); i%1000 == 1 {
-				logrus.Errorf("gcplogs driver has dropped %v logs", i)
-			}
-		} else {
-			logrus.Error(err)
-		}
-	}
-
-	return l, nil
-}
-
-// ValidateLogOpts validates the opts passed to the gcplogs driver. Currently, the gcplogs
-// driver doesn't take any arguments.
-func ValidateLogOpts(cfg map[string]string) error {
-	for k := range cfg {
-		switch k {
-		case projectOptKey, logLabelsKey, logEnvKey, logEnvRegexKey, logCmdKey, logZoneKey, logNameKey, logIDKey:
-		default:
-			return fmt.Errorf("%q is not a valid option for the gcplogs driver", k)
-		}
-	}
-	return nil
-}
-
-func (l *gcplogs) Log(m *logger.Message) error {
-	message := string(m.Line)
-	ts := m.Timestamp
-	logger.PutMessage(m)
-
-	l.logger.Log(logging.Entry{
-		Timestamp: ts,
-		Payload: &dockerLogEntry{
-			Instance:  l.instance,
-			Container: l.container,
-			Message:   message,
-		},
-	})
-	return nil
-}
-
-func (l *gcplogs) Close() error {
-	l.logger.Flush()
-	return nil
-}
-
-func (l *gcplogs) Name() string {
-	return name
-}
diff --git a/components/engine/daemon/logger/gcplogs/gcplogging_linux.go b/components/engine/daemon/logger/gcplogs/gcplogging_linux.go
deleted file mode 100644
index 27f8ef3..0000000
--- a/components/engine/daemon/logger/gcplogs/gcplogging_linux.go
+++ /dev/null
@@ -1,29 +0,0 @@
-package gcplogs // import "github.com/docker/docker/daemon/logger/gcplogs"
-
-import (
-	"os"
-
-	"github.com/docker/docker/dockerversion"
-	"github.com/docker/docker/pkg/homedir"
-	"github.com/sirupsen/logrus"
-)
-
-// ensureHomeIfIAmStatic ensure $HOME to be set if dockerversion.IAmStatic is "true".
-// See issue #29344: gcplogs segfaults (static binary)
-// If HOME is not set, logging.NewClient() will call os/user.Current() via oauth2/google.
-// However, in static binary, os/user.Current() leads to segfault due to a glibc issue that won't be fixed
-// in a short term. (golang/go#13470, https://sourceware.org/bugzilla/show_bug.cgi?id=19341)
-// So we forcibly set HOME so as to avoid call to os/user/Current()
-func ensureHomeIfIAmStatic() error {
-	// Note: dockerversion.IAmStatic and homedir.GetStatic() is only available for linux.
-	// So we need to use them in this gcplogging_linux.go rather than in gcplogging.go
-	if dockerversion.IAmStatic == "true" && os.Getenv("HOME") == "" {
-		home, err := homedir.GetStatic()
-		if err != nil {
-			return err
-		}
-		logrus.Warnf("gcplogs requires HOME to be set for static daemon binary. Forcibly setting HOME to %s.", home)
-		os.Setenv("HOME", home)
-	}
-	return nil
-}
diff --git a/components/engine/daemon/logger/gcplogs/gcplogging_others.go b/components/engine/daemon/logger/gcplogs/gcplogging_others.go
deleted file mode 100644
index 10a2cdc..0000000
--- a/components/engine/daemon/logger/gcplogs/gcplogging_others.go
+++ /dev/null
@@ -1,7 +0,0 @@
-// +build !linux
-
-package gcplogs // import "github.com/docker/docker/daemon/logger/gcplogs"
-
-func ensureHomeIfIAmStatic() error {
-	return nil
-}
diff --git a/components/engine/daemon/logger/gelf/gelf.go b/components/engine/daemon/logger/gelf/gelf.go
deleted file mode 100644
index 57a82da..0000000
--- a/components/engine/daemon/logger/gelf/gelf.go
+++ /dev/null
@@ -1,272 +0,0 @@
-// Package gelf provides the log driver for forwarding server logs to
-// endpoints that support the Graylog Extended Log Format.
-package gelf // import "github.com/docker/docker/daemon/logger/gelf"
-
-import (
-	"compress/flate"
-	"encoding/json"
-	"fmt"
-	"net"
-	"net/url"
-	"strconv"
-	"time"
-
-	"github.com/Graylog2/go-gelf/gelf"
-	"github.com/docker/docker/daemon/logger"
-	"github.com/docker/docker/daemon/logger/loggerutils"
-	"github.com/docker/docker/pkg/urlutil"
-	"github.com/sirupsen/logrus"
-)
-
-const name = "gelf"
-
-type gelfLogger struct {
-	writer   gelf.Writer
-	info     logger.Info
-	hostname string
-	rawExtra json.RawMessage
-}
-
-func init() {
-	if err := logger.RegisterLogDriver(name, New); err != nil {
-		logrus.Fatal(err)
-	}
-	if err := logger.RegisterLogOptValidator(name, ValidateLogOpt); err != nil {
-		logrus.Fatal(err)
-	}
-}
-
-// New creates a gelf logger using the configuration passed in on the
-// context. The supported context configuration variable is gelf-address.
-func New(info logger.Info) (logger.Logger, error) {
-	// parse gelf address
-	address, err := parseAddress(info.Config["gelf-address"])
-	if err != nil {
-		return nil, err
-	}
-
-	// collect extra data for GELF message
-	hostname, err := info.Hostname()
-	if err != nil {
-		return nil, fmt.Errorf("gelf: cannot access hostname to set source field")
-	}
-
-	// parse log tag
-	tag, err := loggerutils.ParseLogTag(info, loggerutils.DefaultTemplate)
-	if err != nil {
-		return nil, err
-	}
-
-	extra := map[string]interface{}{
-		"_container_id":   info.ContainerID,
-		"_container_name": info.Name(),
-		"_image_id":       info.ContainerImageID,
-		"_image_name":     info.ContainerImageName,
-		"_command":        info.Command(),
-		"_tag":            tag,
-		"_created":        info.ContainerCreated,
-	}
-
-	extraAttrs, err := info.ExtraAttributes(func(key string) string {
-		if key[0] == '_' {
-			return key
-		}
-		return "_" + key
-	})
-
-	if err != nil {
-		return nil, err
-	}
-
-	for k, v := range extraAttrs {
-		extra[k] = v
-	}
-
-	rawExtra, err := json.Marshal(extra)
-	if err != nil {
-		return nil, err
-	}
-
-	var gelfWriter gelf.Writer
-	if address.Scheme == "udp" {
-		gelfWriter, err = newGELFUDPWriter(address.Host, info)
-		if err != nil {
-			return nil, err
-		}
-	} else if address.Scheme == "tcp" {
-		gelfWriter, err = newGELFTCPWriter(address.Host, info)
-		if err != nil {
-			return nil, err
-		}
-	}
-
-	return &gelfLogger{
-		writer:   gelfWriter,
-		info:     info,
-		hostname: hostname,
-		rawExtra: rawExtra,
-	}, nil
-}
-
-// create new TCP gelfWriter
-func newGELFTCPWriter(address string, info logger.Info) (gelf.Writer, error) {
-	gelfWriter, err := gelf.NewTCPWriter(address)
-	if err != nil {
-		return nil, fmt.Errorf("gelf: cannot connect to GELF endpoint: %s %v", address, err)
-	}
-
-	if v, ok := info.Config["gelf-tcp-max-reconnect"]; ok {
-		i, err := strconv.Atoi(v)
-		if err != nil || i < 0 {
-			return nil, fmt.Errorf("gelf-tcp-max-reconnect must be a positive integer")
-		}
-		gelfWriter.MaxReconnect = i
-	}
-
-	if v, ok := info.Config["gelf-tcp-reconnect-delay"]; ok {
-		i, err := strconv.Atoi(v)
-		if err != nil || i < 0 {
-			return nil, fmt.Errorf("gelf-tcp-reconnect-delay must be a positive integer")
-		}
-		gelfWriter.ReconnectDelay = time.Duration(i)
-	}
-
-	return gelfWriter, nil
-}
-
-// create new UDP gelfWriter
-func newGELFUDPWriter(address string, info logger.Info) (gelf.Writer, error) {
-	gelfWriter, err := gelf.NewUDPWriter(address)
-	if err != nil {
-		return nil, fmt.Errorf("gelf: cannot connect to GELF endpoint: %s %v", address, err)
-	}
-
-	if v, ok := info.Config["gelf-compression-type"]; ok {
-		switch v {
-		case "gzip":
-			gelfWriter.CompressionType = gelf.CompressGzip
-		case "zlib":
-			gelfWriter.CompressionType = gelf.CompressZlib
-		case "none":
-			gelfWriter.CompressionType = gelf.CompressNone
-		default:
-			return nil, fmt.Errorf("gelf: invalid compression type %q", v)
-		}
-	}
-
-	if v, ok := info.Config["gelf-compression-level"]; ok {
-		val, err := strconv.Atoi(v)
-		if err != nil {
-			return nil, fmt.Errorf("gelf: invalid compression level %s, err %v", v, err)
-		}
-		gelfWriter.CompressionLevel = val
-	}
-
-	return gelfWriter, nil
-}
-
-func (s *gelfLogger) Log(msg *logger.Message) error {
-	if len(msg.Line) == 0 {
-		return nil
-	}
-
-	level := gelf.LOG_INFO
-	if msg.Source == "stderr" {
-		level = gelf.LOG_ERR
-	}
-
-	m := gelf.Message{
-		Version:  "1.1",
-		Host:     s.hostname,
-		Short:    string(msg.Line),
-		TimeUnix: float64(msg.Timestamp.UnixNano()/int64(time.Millisecond)) / 1000.0,
-		Level:    int32(level),
-		RawExtra: s.rawExtra,
-	}
-	logger.PutMessage(msg)
-
-	if err := s.writer.WriteMessage(&m); err != nil {
-		return fmt.Errorf("gelf: cannot send GELF message: %v", err)
-	}
-	return nil
-}
-
-func (s *gelfLogger) Close() error {
-	return s.writer.Close()
-}
-
-func (s *gelfLogger) Name() string {
-	return name
-}
-
-// ValidateLogOpt looks for gelf specific log option gelf-address.
-func ValidateLogOpt(cfg map[string]string) error {
-	address, err := parseAddress(cfg["gelf-address"])
-	if err != nil {
-		return err
-	}
-
-	for key, val := range cfg {
-		switch key {
-		case "gelf-address":
-		case "tag":
-		case "labels":
-		case "env":
-		case "env-regex":
-		case "gelf-compression-level":
-			if address.Scheme != "udp" {
-				return fmt.Errorf("compression is only supported on UDP")
-			}
-			i, err := strconv.Atoi(val)
-			if err != nil || i < flate.DefaultCompression || i > flate.BestCompression {
-				return fmt.Errorf("unknown value %q for log opt %q for gelf log driver", val, key)
-			}
-		case "gelf-compression-type":
-			if address.Scheme != "udp" {
-				return fmt.Errorf("compression is only supported on UDP")
-			}
-			switch val {
-			case "gzip", "zlib", "none":
-			default:
-				return fmt.Errorf("unknown value %q for log opt %q for gelf log driver", val, key)
-			}
-		case "gelf-tcp-max-reconnect", "gelf-tcp-reconnect-delay":
-			if address.Scheme != "tcp" {
-				return fmt.Errorf("%q is only valid for TCP", key)
-			}
-			i, err := strconv.Atoi(val)
-			if err != nil || i < 0 {
-				return fmt.Errorf("%q must be a positive integer", key)
-			}
-		default:
-			return fmt.Errorf("unknown log opt %q for gelf log driver", key)
-		}
-	}
-
-	return nil
-}
-
-func parseAddress(address string) (*url.URL, error) {
-	if address == "" {
-		return nil, fmt.Errorf("gelf-address is a required parameter")
-	}
-	if !urlutil.IsTransportURL(address) {
-		return nil, fmt.Errorf("gelf-address should be in form proto://address, got %v", address)
-	}
-	url, err := url.Parse(address)
-	if err != nil {
-		return nil, err
-	}
-
-	// we support only udp
-	if url.Scheme != "udp" && url.Scheme != "tcp" {
-		return nil, fmt.Errorf("gelf: endpoint needs to be TCP or UDP")
-	}
-
-	// get host and port
-	if _, _, err = net.SplitHostPort(url.Host); err != nil {
-		return nil, fmt.Errorf("gelf: please provide gelf-address as proto://host:port")
-	}
-
-	return url, nil
-}
diff --git a/components/engine/daemon/logger/gelf/gelf_test.go b/components/engine/daemon/logger/gelf/gelf_test.go
deleted file mode 100644
index 3610bc6..0000000
--- a/components/engine/daemon/logger/gelf/gelf_test.go
+++ /dev/null
@@ -1,260 +0,0 @@
-// +build linux
-
-package gelf // import "github.com/docker/docker/daemon/logger/gelf"
-
-import (
-	"net"
-	"testing"
-
-	"github.com/docker/docker/daemon/logger"
-)
-
-// Validate parseAddress
-func TestParseAddress(t *testing.T) {
-	url, err := parseAddress("udp://127.0.0.1:12201")
-	if err != nil {
-		t.Fatal(err)
-	}
-	if url.String() != "udp://127.0.0.1:12201" {
-		t.Fatalf("Expected address udp://127.0.0.1:12201, got %s", url.String())
-	}
-
-	_, err = parseAddress("127.0.0.1:12201")
-	if err == nil {
-		t.Fatal("Expected error requiring protocol")
-	}
-
-	_, err = parseAddress("http://127.0.0.1:12201")
-	if err == nil {
-		t.Fatal("Expected error restricting protocol")
-	}
-}
-
-// Validate TCP options
-func TestTCPValidateLogOpt(t *testing.T) {
-	err := ValidateLogOpt(map[string]string{
-		"gelf-address": "tcp://127.0.0.1:12201",
-	})
-	if err != nil {
-		t.Fatal("Expected TCP to be supported")
-	}
-
-	err = ValidateLogOpt(map[string]string{
-		"gelf-address":           "tcp://127.0.0.1:12201",
-		"gelf-compression-level": "9",
-	})
-	if err == nil {
-		t.Fatal("Expected TCP to reject compression level")
-	}
-
-	err = ValidateLogOpt(map[string]string{
-		"gelf-address":          "tcp://127.0.0.1:12201",
-		"gelf-compression-type": "gzip",
-	})
-	if err == nil {
-		t.Fatal("Expected TCP to reject compression type")
-	}
-
-	err = ValidateLogOpt(map[string]string{
-		"gelf-address":             "tcp://127.0.0.1:12201",
-		"gelf-tcp-max-reconnect":   "5",
-		"gelf-tcp-reconnect-delay": "10",
-	})
-	if err != nil {
-		t.Fatal("Expected TCP reconnect to be a valid parameters")
-	}
-
-	err = ValidateLogOpt(map[string]string{
-		"gelf-address":             "tcp://127.0.0.1:12201",
-		"gelf-tcp-max-reconnect":   "-1",
-		"gelf-tcp-reconnect-delay": "-3",
-	})
-	if err == nil {
-		t.Fatal("Expected negative TCP reconnect to be rejected")
-	}
-
-	err = ValidateLogOpt(map[string]string{
-		"gelf-address":             "tcp://127.0.0.1:12201",
-		"gelf-tcp-max-reconnect":   "invalid",
-		"gelf-tcp-reconnect-delay": "invalid",
-	})
-	if err == nil {
-		t.Fatal("Expected TCP reconnect to be required to be an int")
-	}
-
-	err = ValidateLogOpt(map[string]string{
-		"gelf-address":             "udp://127.0.0.1:12201",
-		"gelf-tcp-max-reconnect":   "1",
-		"gelf-tcp-reconnect-delay": "3",
-	})
-	if err == nil {
-		t.Fatal("Expected TCP reconnect to be invalid for UDP")
-	}
-}
-
-// Validate UDP options
-func TestUDPValidateLogOpt(t *testing.T) {
-	err := ValidateLogOpt(map[string]string{
-		"gelf-address":           "udp://127.0.0.1:12201",
-		"tag":                    "testtag",
-		"labels":                 "testlabel",
-		"env":                    "testenv",
-		"env-regex":              "testenv-regex",
-		"gelf-compression-level": "9",
-		"gelf-compression-type":  "gzip",
-	})
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	err = ValidateLogOpt(map[string]string{
-		"gelf-address":           "udp://127.0.0.1:12201",
-		"gelf-compression-level": "ultra",
-		"gelf-compression-type":  "zlib",
-	})
-	if err == nil {
-		t.Fatal("Expected compression level error")
-	}
-
-	err = ValidateLogOpt(map[string]string{
-		"gelf-address":          "udp://127.0.0.1:12201",
-		"gelf-compression-type": "rar",
-	})
-	if err == nil {
-		t.Fatal("Expected compression type error")
-	}
-
-	err = ValidateLogOpt(map[string]string{
-		"invalid": "invalid",
-	})
-	if err == nil {
-		t.Fatal("Expected unknown option error")
-	}
-
-	err = ValidateLogOpt(map[string]string{})
-	if err == nil {
-		t.Fatal("Expected required parameter error")
-	}
-}
-
-// Validate newGELFTCPWriter
-func TestNewGELFTCPWriter(t *testing.T) {
-	address := "127.0.0.1:0"
-	tcpAddr, err := net.ResolveTCPAddr("tcp", address)
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	listener, err := net.ListenTCP("tcp", tcpAddr)
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	url := "tcp://" + listener.Addr().String()
-	info := logger.Info{
-		Config: map[string]string{
-			"gelf-address":             url,
-			"gelf-tcp-max-reconnect":   "0",
-			"gelf-tcp-reconnect-delay": "0",
-			"tag":                      "{{.ID}}",
-		},
-		ContainerID: "12345678901234567890",
-	}
-
-	writer, err := newGELFTCPWriter(listener.Addr().String(), info)
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	err = writer.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	err = listener.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-}
-
-// Validate newGELFUDPWriter
-func TestNewGELFUDPWriter(t *testing.T) {
-	address := "127.0.0.1:0"
-	info := logger.Info{
-		Config: map[string]string{
-			"gelf-address":           "udp://127.0.0.1:0",
-			"gelf-compression-level": "5",
-			"gelf-compression-type":  "gzip",
-		},
-	}
-
-	writer, err := newGELFUDPWriter(address, info)
-	if err != nil {
-		t.Fatal(err)
-	}
-	writer.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-}
-
-// Validate New for TCP
-func TestNewTCP(t *testing.T) {
-	address := "127.0.0.1:0"
-	tcpAddr, err := net.ResolveTCPAddr("tcp", address)
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	listener, err := net.ListenTCP("tcp", tcpAddr)
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	url := "tcp://" + listener.Addr().String()
-	info := logger.Info{
-		Config: map[string]string{
-			"gelf-address":             url,
-			"gelf-tcp-max-reconnect":   "0",
-			"gelf-tcp-reconnect-delay": "0",
-		},
-		ContainerID: "12345678901234567890",
-	}
-
-	logger, err := New(info)
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	err = logger.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	err = listener.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-}
-
-// Validate New for UDP
-func TestNewUDP(t *testing.T) {
-	info := logger.Info{
-		Config: map[string]string{
-			"gelf-address":           "udp://127.0.0.1:0",
-			"gelf-compression-level": "5",
-			"gelf-compression-type":  "gzip",
-		},
-		ContainerID: "12345678901234567890",
-	}
-
-	logger, err := New(info)
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	err = logger.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-}
diff --git a/components/engine/daemon/logger/journald/journald.go b/components/engine/daemon/logger/journald/journald.go
deleted file mode 100644
index 40bdd42..0000000
--- a/components/engine/daemon/logger/journald/journald.go
+++ /dev/null
@@ -1,123 +0,0 @@
-// +build linux
-
-// Package journald provides the log driver for forwarding server logs
-// to endpoints that receive the systemd format.
-package journald // import "github.com/docker/docker/daemon/logger/journald"
-
-import (
-	"fmt"
-	"sync"
-	"unicode"
-
-	"github.com/coreos/go-systemd/journal"
-	"github.com/docker/docker/daemon/logger"
-	"github.com/docker/docker/daemon/logger/loggerutils"
-	"github.com/sirupsen/logrus"
-)
-
-const name = "journald"
-
-type journald struct {
-	mu      sync.Mutex
-	vars    map[string]string // additional variables and values to send to the journal along with the log message
-	readers map[*logger.LogWatcher]struct{}
-}
-
-func init() {
-	if err := logger.RegisterLogDriver(name, New); err != nil {
-		logrus.Fatal(err)
-	}
-	if err := logger.RegisterLogOptValidator(name, validateLogOpt); err != nil {
-		logrus.Fatal(err)
-	}
-}
-
-// sanitizeKeyMode returns the sanitized string so that it could be used in journald.
-// In journald log, there are special requirements for fields.
-// Fields must be composed of uppercase letters, numbers, and underscores, but must
-// not start with an underscore.
-func sanitizeKeyMod(s string) string {
-	n := ""
-	for _, v := range s {
-		if 'a' <= v && v <= 'z' {
-			v = unicode.ToUpper(v)
-		} else if ('Z' < v || v < 'A') && ('9' < v || v < '0') {
-			v = '_'
-		}
-		// If (n == "" && v == '_'), then we will skip as this is the beginning with '_'
-		if !(n == "" && v == '_') {
-			n += string(v)
-		}
-	}
-	return n
-}
-
-// New creates a journald logger using the configuration passed in on
-// the context.
-func New(info logger.Info) (logger.Logger, error) {
-	if !journal.Enabled() {
-		return nil, fmt.Errorf("journald is not enabled on this host")
-	}
-
-	// parse log tag
-	tag, err := loggerutils.ParseLogTag(info, loggerutils.DefaultTemplate)
-	if err != nil {
-		return nil, err
-	}
-
-	vars := map[string]string{
-		"CONTAINER_ID":      info.ContainerID[:12],
-		"CONTAINER_ID_FULL": info.ContainerID,
-		"CONTAINER_NAME":    info.Name(),
-		"CONTAINER_TAG":     tag,
-		"IMAGE_NAME":        info.ImageName(),
-		"SYSLOG_IDENTIFIER": tag,
-	}
-	extraAttrs, err := info.ExtraAttributes(sanitizeKeyMod)
-	if err != nil {
-		return nil, err
-	}
-	for k, v := range extraAttrs {
-		vars[k] = v
-	}
-	return &journald{vars: vars, readers: make(map[*logger.LogWatcher]struct{})}, nil
-}
-
-// We don't actually accept any options, but we have to supply a callback for
-// the factory to pass the (probably empty) configuration map to.
-func validateLogOpt(cfg map[string]string) error {
-	for key := range cfg {
-		switch key {
-		case "labels":
-		case "env":
-		case "env-regex":
-		case "tag":
-		default:
-			return fmt.Errorf("unknown log opt '%s' for journald log driver", key)
-		}
-	}
-	return nil
-}
-
-func (s *journald) Log(msg *logger.Message) error {
-	vars := map[string]string{}
-	for k, v := range s.vars {
-		vars[k] = v
-	}
-	if msg.PLogMetaData != nil && !msg.PLogMetaData.Last {
-		vars["CONTAINER_PARTIAL_MESSAGE"] = "true"
-	}
-
-	line := string(msg.Line)
-	source := msg.Source
-	logger.PutMessage(msg)
-
-	if source == "stderr" {
-		return journal.Send(line, journal.PriErr, vars)
-	}
-	return journal.Send(line, journal.PriInfo, vars)
-}
-
-func (s *journald) Name() string {
-	return name
-}
diff --git a/components/engine/daemon/logger/journald/journald_test.go b/components/engine/daemon/logger/journald/journald_test.go
deleted file mode 100644
index bd7bf7a..0000000
--- a/components/engine/daemon/logger/journald/journald_test.go
+++ /dev/null
@@ -1,23 +0,0 @@
-// +build linux
-
-package journald // import "github.com/docker/docker/daemon/logger/journald"
-
-import (
-	"testing"
-)
-
-func TestSanitizeKeyMod(t *testing.T) {
-	entries := map[string]string{
-		"io.kubernetes.pod.name":      "IO_KUBERNETES_POD_NAME",
-		"io?.kubernetes.pod.name":     "IO__KUBERNETES_POD_NAME",
-		"?io.kubernetes.pod.name":     "IO_KUBERNETES_POD_NAME",
-		"io123.kubernetes.pod.name":   "IO123_KUBERNETES_POD_NAME",
-		"_io123.kubernetes.pod.name":  "IO123_KUBERNETES_POD_NAME",
-		"__io123_kubernetes.pod.name": "IO123_KUBERNETES_POD_NAME",
-	}
-	for k, v := range entries {
-		if sanitizeKeyMod(k) != v {
-			t.Fatalf("Failed to sanitize %s, got %s, expected %s", k, sanitizeKeyMod(k), v)
-		}
-	}
-}
diff --git a/components/engine/daemon/logger/journald/journald_unsupported.go b/components/engine/daemon/logger/journald/journald_unsupported.go
deleted file mode 100644
index 7899fc1..0000000
--- a/components/engine/daemon/logger/journald/journald_unsupported.go
+++ /dev/null
@@ -1,6 +0,0 @@
-// +build !linux
-
-package journald // import "github.com/docker/docker/daemon/logger/journald"
-
-type journald struct {
-}
diff --git a/components/engine/daemon/logger/journald/read.go b/components/engine/daemon/logger/journald/read.go
deleted file mode 100644
index 7b22198..0000000
--- a/components/engine/daemon/logger/journald/read.go
+++ /dev/null
@@ -1,387 +0,0 @@
-// +build linux,cgo,!static_build,journald
-
-package journald // import "github.com/docker/docker/daemon/logger/journald"
-
-// #include <sys/types.h>
-// #include <sys/poll.h>
-// #include <systemd/sd-journal.h>
-// #include <errno.h>
-// #include <stdio.h>
-// #include <stdlib.h>
-// #include <string.h>
-// #include <time.h>
-// #include <unistd.h>
-//
-//static int get_message(sd_journal *j, const char **msg, size_t *length, int *partial)
-//{
-//	int rc;
-//	size_t plength;
-//	*msg = NULL;
-//	*length = 0;
-//	plength = strlen("CONTAINER_PARTIAL_MESSAGE=true");
-//	rc = sd_journal_get_data(j, "CONTAINER_PARTIAL_MESSAGE", (const void **) msg, length);
-//	*partial = ((rc == 0) && (*length == plength) && (memcmp(*msg, "CONTAINER_PARTIAL_MESSAGE=true", plength) == 0));
-//	rc = sd_journal_get_data(j, "MESSAGE", (const void **) msg, length);
-//	if (rc == 0) {
-//		if (*length > 8) {
-//			(*msg) += 8;
-//			*length -= 8;
-//		} else {
-//			*msg = NULL;
-//			*length = 0;
-//			rc = -ENOENT;
-//		}
-//	}
-//	return rc;
-//}
-//static int get_priority(sd_journal *j, int *priority)
-//{
-//	const void *data;
-//	size_t i, length;
-//	int rc;
-//	*priority = -1;
-//	rc = sd_journal_get_data(j, "PRIORITY", &data, &length);
-//	if (rc == 0) {
-//		if ((length > 9) && (strncmp(data, "PRIORITY=", 9) == 0)) {
-//			*priority = 0;
-//			for (i = 9; i < length; i++) {
-//				*priority = *priority * 10 + ((const char *)data)[i] - '0';
-//			}
-//			if (length > 9) {
-//				rc = 0;
-//			}
-//		}
-//	}
-//	return rc;
-//}
-//static int is_attribute_field(const char *msg, size_t length)
-//{
-//	static const struct known_field {
-//		const char *name;
-//		size_t length;
-//	} fields[] = {
-//		{"MESSAGE", sizeof("MESSAGE") - 1},
-//		{"MESSAGE_ID", sizeof("MESSAGE_ID") - 1},
-//		{"PRIORITY", sizeof("PRIORITY") - 1},
-//		{"CODE_FILE", sizeof("CODE_FILE") - 1},
-//		{"CODE_LINE", sizeof("CODE_LINE") - 1},
-//		{"CODE_FUNC", sizeof("CODE_FUNC") - 1},
-//		{"ERRNO", sizeof("ERRNO") - 1},
-//		{"SYSLOG_FACILITY", sizeof("SYSLOG_FACILITY") - 1},
-//		{"SYSLOG_IDENTIFIER", sizeof("SYSLOG_IDENTIFIER") - 1},
-//		{"SYSLOG_PID", sizeof("SYSLOG_PID") - 1},
-//		{"CONTAINER_NAME", sizeof("CONTAINER_NAME") - 1},
-//		{"CONTAINER_ID", sizeof("CONTAINER_ID") - 1},
-//		{"CONTAINER_ID_FULL", sizeof("CONTAINER_ID_FULL") - 1},
-//		{"CONTAINER_TAG", sizeof("CONTAINER_TAG") - 1},
-//	};
-//	unsigned int i;
-//	void *p;
-//	if ((length < 1) || (msg[0] == '_') || ((p = memchr(msg, '=', length)) == NULL)) {
-//		return -1;
-//	}
-//	length = ((const char *) p) - msg;
-//	for (i = 0; i < sizeof(fields) / sizeof(fields[0]); i++) {
-//		if ((fields[i].length == length) && (memcmp(fields[i].name, msg, length) == 0)) {
-//			return -1;
-//		}
-//	}
-//	return 0;
-//}
-//static int get_attribute_field(sd_journal *j, const char **msg, size_t *length)
-//{
-//	int rc;
-//	*msg = NULL;
-//	*length = 0;
-//	while ((rc = sd_journal_enumerate_data(j, (const void **) msg, length)) > 0) {
-//		if (is_attribute_field(*msg, *length) == 0) {
-//			break;
-//		}
-//		rc = -ENOENT;
-//	}
-//	return rc;
-//}
-import "C"
-
-import (
-	"errors"
-	"strings"
-	"time"
-	"unsafe"
-
-	"github.com/coreos/go-systemd/journal"
-	"github.com/docker/docker/api/types/backend"
-	"github.com/docker/docker/daemon/logger"
-	"github.com/sirupsen/logrus"
-)
-
-func (s *journald) Close() error {
-	s.mu.Lock()
-	for r := range s.readers {
-		r.ProducerGone()
-		delete(s.readers, r)
-	}
-	s.mu.Unlock()
-	return nil
-}
-
-// convert error code returned from a sd_journal_* function
-// (which returns -errno) to a string
-func CErr(ret C.int) string {
-	return C.GoString(C.strerror(C.int(-ret)))
-}
-
-func (s *journald) drainJournal(logWatcher *logger.LogWatcher, j *C.sd_journal, oldCursor *C.char, untilUnixMicro uint64) (*C.char, bool, int) {
-	var (
-		msg, data, cursor *C.char
-		length            C.size_t
-		stamp             C.uint64_t
-		priority, partial C.int
-		done              bool
-		shown             int
-	)
-
-	// Walk the journal from here forward until we run out of new entries
-	// or we reach the until value (if provided).
-drain:
-	for {
-		// Try not to send a given entry twice.
-		if oldCursor != nil {
-			for C.sd_journal_test_cursor(j, oldCursor) > 0 {
-				if C.sd_journal_next(j) <= 0 {
-					break drain
-				}
-			}
-		}
-		// Read and send the logged message, if there is one to read.
-		i := C.get_message(j, &msg, &length, &partial)
-		if i != -C.ENOENT && i != -C.EADDRNOTAVAIL {
-			// Read the entry's timestamp.
-			if C.sd_journal_get_realtime_usec(j, &stamp) != 0 {
-				break
-			}
-			// Break if the timestamp exceeds any provided until flag.
-			if untilUnixMicro != 0 && untilUnixMicro < uint64(stamp) {
-				done = true
-				break
-			}
-
-			// Set up the time and text of the entry.
-			timestamp := time.Unix(int64(stamp)/1000000, (int64(stamp)%1000000)*1000)
-			line := C.GoBytes(unsafe.Pointer(msg), C.int(length))
-			if partial == 0 {
-				line = append(line, "\n"...)
-			}
-			// Recover the stream name by mapping
-			// from the journal priority back to
-			// the stream that we would have
-			// assigned that value.
-			source := ""
-			if C.get_priority(j, &priority) == 0 {
-				if priority == C.int(journal.PriErr) {
-					source = "stderr"
-				} else if priority == C.int(journal.PriInfo) {
-					source = "stdout"
-				}
-			}
-			// Retrieve the values of any variables we're adding to the journal.
-			var attrs []backend.LogAttr
-			C.sd_journal_restart_data(j)
-			for C.get_attribute_field(j, &data, &length) > C.int(0) {
-				kv := strings.SplitN(C.GoStringN(data, C.int(length)), "=", 2)
-				attrs = append(attrs, backend.LogAttr{Key: kv[0], Value: kv[1]})
-			}
-
-			// Send the log message, unless the consumer is gone
-			select {
-			case <-logWatcher.WatchConsumerGone():
-				done = true // we won't be able to write anything anymore
-				break drain
-			case logWatcher.Msg <- &logger.Message{
-				Line:      line,
-				Source:    source,
-				Timestamp: timestamp.In(time.UTC),
-				Attrs:     attrs,
-			}:
-				shown++
-			}
-			// Call sd_journal_process() periodically during the processing loop
-			// to close any opened file descriptors for rotated (deleted) journal files.
-			if shown%1024 == 0 {
-				if ret := C.sd_journal_process(j); ret < 0 {
-					// log a warning but ignore it for now
-					logrus.WithField("container", s.vars["CONTAINER_ID_FULL"]).
-						WithField("error", CErr(ret)).
-						Warn("journald: error processing journal")
-				}
-			}
-		}
-		// If we're at the end of the journal, we're done (for now).
-		if C.sd_journal_next(j) <= 0 {
-			break
-		}
-	}
-
-	// free(NULL) is safe
-	C.free(unsafe.Pointer(oldCursor))
-	if C.sd_journal_get_cursor(j, &cursor) != 0 {
-		// ensure that we won't be freeing an address that's invalid
-		cursor = nil
-	}
-	return cursor, done, shown
-}
-
-func (s *journald) followJournal(logWatcher *logger.LogWatcher, j *C.sd_journal, cursor *C.char, untilUnixMicro uint64) *C.char {
-	s.mu.Lock()
-	s.readers[logWatcher] = struct{}{}
-	s.mu.Unlock()
-
-	waitTimeout := C.uint64_t(250000) // 0.25s
-
-	for {
-		status := C.sd_journal_wait(j, waitTimeout)
-		if status < 0 {
-			logWatcher.Err <- errors.New("error waiting for journal: " + CErr(status))
-			goto cleanup
-		}
-		select {
-		case <-logWatcher.WatchConsumerGone():
-			goto cleanup // won't be able to write anything anymore
-		case <-logWatcher.WatchProducerGone():
-			// container is gone, drain journal
-		default:
-			// container is still alive
-			if status == C.SD_JOURNAL_NOP {
-				// no new data -- keep waiting
-				continue
-			}
-		}
-		newCursor, done, recv := s.drainJournal(logWatcher, j, cursor, untilUnixMicro)
-		cursor = newCursor
-		if done || (status == C.SD_JOURNAL_NOP && recv == 0) {
-			break
-		}
-	}
-
-cleanup:
-	s.mu.Lock()
-	delete(s.readers, logWatcher)
-	s.mu.Unlock()
-	close(logWatcher.Msg)
-	return cursor
-}
-
-func (s *journald) readLogs(logWatcher *logger.LogWatcher, config logger.ReadConfig) {
-	var (
-		j              *C.sd_journal
-		cmatch, cursor *C.char
-		stamp          C.uint64_t
-		sinceUnixMicro uint64
-		untilUnixMicro uint64
-	)
-
-	// Get a handle to the journal.
-	if rc := C.sd_journal_open(&j, C.int(0)); rc != 0 {
-		logWatcher.Err <- errors.New("error opening journal: " + CErr(rc))
-		close(logWatcher.Msg)
-		return
-	}
-	if config.Follow {
-		// Initialize library inotify watches early
-		if rc := C.sd_journal_get_fd(j); rc < 0 {
-			logWatcher.Err <- errors.New("error getting journald fd: " + CErr(rc))
-			close(logWatcher.Msg)
-			return
-		}
-	}
-	// If we end up following the log, we can set the journal context
-	// pointer and the channel pointer to nil so that we won't close them
-	// here, potentially while the goroutine that uses them is still
-	// running.  Otherwise, close them when we return from this function.
-	following := false
-	defer func() {
-		if !following {
-			close(logWatcher.Msg)
-		}
-		C.sd_journal_close(j)
-	}()
-	// Remove limits on the size of data items that we'll retrieve.
-	if rc := C.sd_journal_set_data_threshold(j, C.size_t(0)); rc != 0 {
-		logWatcher.Err <- errors.New("error setting journal data threshold: " + CErr(rc))
-		return
-	}
-	// Add a match to have the library do the searching for us.
-	cmatch = C.CString("CONTAINER_ID_FULL=" + s.vars["CONTAINER_ID_FULL"])
-	defer C.free(unsafe.Pointer(cmatch))
-	if rc := C.sd_journal_add_match(j, unsafe.Pointer(cmatch), C.strlen(cmatch)); rc != 0 {
-		logWatcher.Err <- errors.New("error setting journal match: " + CErr(rc))
-		return
-	}
-	// If we have a cutoff time, convert it to Unix time once.
-	if !config.Since.IsZero() {
-		nano := config.Since.UnixNano()
-		sinceUnixMicro = uint64(nano / 1000)
-	}
-	// If we have an until value, convert it too
-	if !config.Until.IsZero() {
-		nano := config.Until.UnixNano()
-		untilUnixMicro = uint64(nano / 1000)
-	}
-	if config.Tail >= 0 {
-		// If until time provided, start from there.
-		// Otherwise start at the end of the journal.
-		if untilUnixMicro != 0 {
-			if rc := C.sd_journal_seek_realtime_usec(j, C.uint64_t(untilUnixMicro)); rc != 0 {
-				logWatcher.Err <- errors.New("error seeking provided until value: " + CErr(rc))
-				return
-			}
-		} else if rc := C.sd_journal_seek_tail(j); rc != 0 {
-			logWatcher.Err <- errors.New("error seeking to end of journal: " + CErr(rc))
-			return
-		}
-		// (Try to) skip backwards by the requested number of lines...
-		if C.sd_journal_previous_skip(j, C.uint64_t(config.Tail)) >= 0 {
-			// ...but not before "since"
-			if sinceUnixMicro != 0 &&
-				C.sd_journal_get_realtime_usec(j, &stamp) == 0 &&
-				uint64(stamp) < sinceUnixMicro {
-				C.sd_journal_seek_realtime_usec(j, C.uint64_t(sinceUnixMicro))
-			}
-		}
-	} else {
-		// Start at the beginning of the journal.
-		if rc := C.sd_journal_seek_head(j); rc != 0 {
-			logWatcher.Err <- errors.New("error seeking to start of journal: " + CErr(rc))
-			return
-		}
-		// If we have a cutoff date, fast-forward to it.
-		if sinceUnixMicro != 0 {
-			if rc := C.sd_journal_seek_realtime_usec(j, C.uint64_t(sinceUnixMicro)); rc != 0 {
-				logWatcher.Err <- errors.New("error seeking to start time in journal: " + CErr(rc))
-				return
-			}
-		}
-		if rc := C.sd_journal_next(j); rc < 0 {
-			logWatcher.Err <- errors.New("error skipping to next journal entry: " + CErr(rc))
-			return
-		}
-	}
-	if config.Tail != 0 { // special case for --tail 0
-		cursor, _, _ = s.drainJournal(logWatcher, j, nil, untilUnixMicro)
-	}
-	if config.Follow {
-		cursor = s.followJournal(logWatcher, j, cursor, untilUnixMicro)
-		// Let followJournal handle freeing the journal context
-		// object and closing the channel.
-		following = true
-	}
-
-	C.free(unsafe.Pointer(cursor))
-	return
-}
-
-func (s *journald) ReadLogs(config logger.ReadConfig) *logger.LogWatcher {
-	logWatcher := logger.NewLogWatcher()
-	go s.readLogs(logWatcher, config)
-	return logWatcher
-}
diff --git a/components/engine/daemon/logger/journald/read_native.go b/components/engine/daemon/logger/journald/read_native.go
deleted file mode 100644
index ab68cf4..0000000
--- a/components/engine/daemon/logger/journald/read_native.go
+++ /dev/null
@@ -1,6 +0,0 @@
-// +build linux,cgo,!static_build,journald,!journald_compat
-
-package journald // import "github.com/docker/docker/daemon/logger/journald"
-
-// #cgo pkg-config: libsystemd
-import "C"
diff --git a/components/engine/daemon/logger/journald/read_native_compat.go b/components/engine/daemon/logger/journald/read_native_compat.go
deleted file mode 100644
index 4806e13..0000000
--- a/components/engine/daemon/logger/journald/read_native_compat.go
+++ /dev/null
@@ -1,6 +0,0 @@
-// +build linux,cgo,!static_build,journald,journald_compat
-
-package journald // import "github.com/docker/docker/daemon/logger/journald"
-
-// #cgo pkg-config: libsystemd-journal
-import "C"
diff --git a/components/engine/daemon/logger/journald/read_unsupported.go b/components/engine/daemon/logger/journald/read_unsupported.go
deleted file mode 100644
index a66b666..0000000
--- a/components/engine/daemon/logger/journald/read_unsupported.go
+++ /dev/null
@@ -1,7 +0,0 @@
-// +build !linux !cgo static_build !journald
-
-package journald // import "github.com/docker/docker/daemon/logger/journald"
-
-func (s *journald) Close() error {
-	return nil
-}
diff --git a/components/engine/daemon/logger/jsonfilelog/jsonfilelog.go b/components/engine/daemon/logger/jsonfilelog/jsonfilelog.go
deleted file mode 100644
index bbb8eeb..0000000
--- a/components/engine/daemon/logger/jsonfilelog/jsonfilelog.go
+++ /dev/null
@@ -1,186 +0,0 @@
-// Package jsonfilelog provides the default Logger implementation for
-// Docker logging. This logger logs to files on the host server in the
-// JSON format.
-package jsonfilelog // import "github.com/docker/docker/daemon/logger/jsonfilelog"
-
-import (
-	"bytes"
-	"encoding/json"
-	"fmt"
-	"strconv"
-	"sync"
-
-	"github.com/docker/docker/daemon/logger"
-	"github.com/docker/docker/daemon/logger/jsonfilelog/jsonlog"
-	"github.com/docker/docker/daemon/logger/loggerutils"
-	"github.com/docker/go-units"
-	"github.com/pkg/errors"
-	"github.com/sirupsen/logrus"
-)
-
-// Name is the name of the file that the jsonlogger logs to.
-const Name = "json-file"
-
-// JSONFileLogger is Logger implementation for default Docker logging.
-type JSONFileLogger struct {
-	mu      sync.Mutex
-	closed  bool
-	writer  *loggerutils.LogFile
-	readers map[*logger.LogWatcher]struct{} // stores the active log followers
-	tag     string                          // tag values requested by the user to log
-}
-
-func init() {
-	if err := logger.RegisterLogDriver(Name, New); err != nil {
-		logrus.Fatal(err)
-	}
-	if err := logger.RegisterLogOptValidator(Name, ValidateLogOpt); err != nil {
-		logrus.Fatal(err)
-	}
-}
-
-// New creates new JSONFileLogger which writes to filename passed in
-// on given context.
-func New(info logger.Info) (logger.Logger, error) {
-	var capval int64 = -1
-	if capacity, ok := info.Config["max-size"]; ok {
-		var err error
-		capval, err = units.FromHumanSize(capacity)
-		if err != nil {
-			return nil, err
-		}
-		if capval <= 0 {
-			return nil, fmt.Errorf("max-size must be a positive number")
-		}
-	}
-	var maxFiles = 1
-	if maxFileString, ok := info.Config["max-file"]; ok {
-		var err error
-		maxFiles, err = strconv.Atoi(maxFileString)
-		if err != nil {
-			return nil, err
-		}
-		if maxFiles < 1 {
-			return nil, fmt.Errorf("max-file cannot be less than 1")
-		}
-	}
-
-	var compress bool
-	if compressString, ok := info.Config["compress"]; ok {
-		var err error
-		compress, err = strconv.ParseBool(compressString)
-		if err != nil {
-			return nil, err
-		}
-		if compress && (maxFiles == 1 || capval == -1) {
-			return nil, fmt.Errorf("compress cannot be true when max-file is less than 2 or max-size is not set")
-		}
-	}
-
-	attrs, err := info.ExtraAttributes(nil)
-	if err != nil {
-		return nil, err
-	}
-
-	// no default template. only use a tag if the user asked for it
-	tag, err := loggerutils.ParseLogTag(info, "")
-	if err != nil {
-		return nil, err
-	}
-	if tag != "" {
-		attrs["tag"] = tag
-	}
-
-	var extra []byte
-	if len(attrs) > 0 {
-		var err error
-		extra, err = json.Marshal(attrs)
-		if err != nil {
-			return nil, err
-		}
-	}
-
-	buf := bytes.NewBuffer(nil)
-	marshalFunc := func(msg *logger.Message) ([]byte, error) {
-		if err := marshalMessage(msg, extra, buf); err != nil {
-			return nil, err
-		}
-		b := buf.Bytes()
-		buf.Reset()
-		return b, nil
-	}
-
-	writer, err := loggerutils.NewLogFile(info.LogPath, capval, maxFiles, compress, marshalFunc, decodeFunc, 0640, getTailReader)
-	if err != nil {
-		return nil, err
-	}
-
-	return &JSONFileLogger{
-		writer:  writer,
-		readers: make(map[*logger.LogWatcher]struct{}),
-		tag:     tag,
-	}, nil
-}
-
-// Log converts logger.Message to jsonlog.JSONLog and serializes it to file.
-func (l *JSONFileLogger) Log(msg *logger.Message) error {
-	l.mu.Lock()
-	err := l.writer.WriteLogEntry(msg)
-	l.mu.Unlock()
-	return err
-}
-
-func marshalMessage(msg *logger.Message, extra json.RawMessage, buf *bytes.Buffer) error {
-	logLine := msg.Line
-	if msg.PLogMetaData == nil || (msg.PLogMetaData != nil && msg.PLogMetaData.Last) {
-		logLine = append(msg.Line, '\n')
-	}
-	err := (&jsonlog.JSONLogs{
-		Log:      logLine,
-		Stream:   msg.Source,
-		Created:  msg.Timestamp,
-		RawAttrs: extra,
-	}).MarshalJSONBuf(buf)
-	if err != nil {
-		return errors.Wrap(err, "error writing log message to buffer")
-	}
-	err = buf.WriteByte('\n')
-	return errors.Wrap(err, "error finalizing log buffer")
-}
-
-// ValidateLogOpt looks for json specific log options max-file & max-size.
-func ValidateLogOpt(cfg map[string]string) error {
-	for key := range cfg {
-		switch key {
-		case "max-file":
-		case "max-size":
-		case "compress":
-		case "labels":
-		case "env":
-		case "env-regex":
-		case "tag":
-		default:
-			return fmt.Errorf("unknown log opt '%s' for json-file log driver", key)
-		}
-	}
-	return nil
-}
-
-// Close closes underlying file and signals all the readers
-// that the logs producer is gone.
-func (l *JSONFileLogger) Close() error {
-	l.mu.Lock()
-	l.closed = true
-	err := l.writer.Close()
-	for r := range l.readers {
-		r.ProducerGone()
-		delete(l.readers, r)
-	}
-	l.mu.Unlock()
-	return err
-}
-
-// Name returns name of this logger.
-func (l *JSONFileLogger) Name() string {
-	return Name
-}
diff --git a/components/engine/daemon/logger/jsonfilelog/jsonfilelog_test.go b/components/engine/daemon/logger/jsonfilelog/jsonfilelog_test.go
deleted file mode 100644
index 8e66e64..0000000
--- a/components/engine/daemon/logger/jsonfilelog/jsonfilelog_test.go
+++ /dev/null
@@ -1,319 +0,0 @@
-package jsonfilelog // import "github.com/docker/docker/daemon/logger/jsonfilelog"
-
-import (
-	"bytes"
-	"compress/gzip"
-	"encoding/json"
-	"fmt"
-	"io/ioutil"
-	"os"
-	"path/filepath"
-	"reflect"
-	"strconv"
-	"testing"
-	"time"
-
-	"github.com/docker/docker/daemon/logger"
-	"github.com/docker/docker/daemon/logger/jsonfilelog/jsonlog"
-	"gotest.tools/assert"
-	is "gotest.tools/assert/cmp"
-	"gotest.tools/fs"
-)
-
-func TestJSONFileLogger(t *testing.T) {
-	cid := "a7317399f3f857173c6179d44823594f8294678dea9999662e5c625b5a1c7657"
-	tmp, err := ioutil.TempDir("", "docker-logger-")
-	if err != nil {
-		t.Fatal(err)
-	}
-	defer os.RemoveAll(tmp)
-	filename := filepath.Join(tmp, "container.log")
-	l, err := New(logger.Info{
-		ContainerID: cid,
-		LogPath:     filename,
-	})
-	if err != nil {
-		t.Fatal(err)
-	}
-	defer l.Close()
-
-	if err := l.Log(&logger.Message{Line: []byte("line1"), Source: "src1"}); err != nil {
-		t.Fatal(err)
-	}
-	if err := l.Log(&logger.Message{Line: []byte("line2"), Source: "src2"}); err != nil {
-		t.Fatal(err)
-	}
-	if err := l.Log(&logger.Message{Line: []byte("line3"), Source: "src3"}); err != nil {
-		t.Fatal(err)
-	}
-	res, err := ioutil.ReadFile(filename)
-	if err != nil {
-		t.Fatal(err)
-	}
-	expected := `{"log":"line1\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line2\n","stream":"src2","time":"0001-01-01T00:00:00Z"}
-{"log":"line3\n","stream":"src3","time":"0001-01-01T00:00:00Z"}
-`
-
-	if string(res) != expected {
-		t.Fatalf("Wrong log content: %q, expected %q", res, expected)
-	}
-}
-
-func TestJSONFileLoggerWithTags(t *testing.T) {
-	cid := "a7317399f3f857173c6179d44823594f8294678dea9999662e5c625b5a1c7657"
-	cname := "test-container"
-	tmp, err := ioutil.TempDir("", "docker-logger-")
-
-	assert.NilError(t, err)
-
-	defer os.RemoveAll(tmp)
-	filename := filepath.Join(tmp, "container.log")
-	l, err := New(logger.Info{
-		Config: map[string]string{
-			"tag": "{{.ID}}/{{.Name}}", // first 12 characters of ContainerID and full ContainerName
-		},
-		ContainerID:   cid,
-		ContainerName: cname,
-		LogPath:       filename,
-	})
-
-	assert.NilError(t, err)
-	defer l.Close()
-
-	err = l.Log(&logger.Message{Line: []byte("line1"), Source: "src1"})
-	assert.NilError(t, err)
-
-	err = l.Log(&logger.Message{Line: []byte("line2"), Source: "src2"})
-	assert.NilError(t, err)
-
-	err = l.Log(&logger.Message{Line: []byte("line3"), Source: "src3"})
-	assert.NilError(t, err)
-
-	res, err := ioutil.ReadFile(filename)
-	assert.NilError(t, err)
-
-	expected := `{"log":"line1\n","stream":"src1","attrs":{"tag":"a7317399f3f8/test-container"},"time":"0001-01-01T00:00:00Z"}
-{"log":"line2\n","stream":"src2","attrs":{"tag":"a7317399f3f8/test-container"},"time":"0001-01-01T00:00:00Z"}
-{"log":"line3\n","stream":"src3","attrs":{"tag":"a7317399f3f8/test-container"},"time":"0001-01-01T00:00:00Z"}
-`
-	assert.Check(t, is.Equal(expected, string(res)))
-}
-
-func BenchmarkJSONFileLoggerLog(b *testing.B) {
-	tmp := fs.NewDir(b, "bench-jsonfilelog")
-	defer tmp.Remove()
-
-	jsonlogger, err := New(logger.Info{
-		ContainerID: "a7317399f3f857173c6179d44823594f8294678dea9999662e5c625b5a1c7657",
-		LogPath:     tmp.Join("container.log"),
-		Config: map[string]string{
-			"labels":   "first,second",
-			"max-file": "10",
-			"compress": "true",
-			"max-size": "20m",
-		},
-		ContainerLabels: map[string]string{
-			"first":  "label_value",
-			"second": "label_foo",
-		},
-	})
-	assert.NilError(b, err)
-	defer jsonlogger.Close()
-
-	t := time.Now().UTC()
-	for _, data := range [][]byte{
-		[]byte(""),
-		[]byte("a short string"),
-		bytes.Repeat([]byte("a long string"), 100),
-		bytes.Repeat([]byte("a really long string"), 10000),
-	} {
-		b.Run(fmt.Sprintf("%d", len(data)), func(b *testing.B) {
-			testMsg := &logger.Message{
-				Line:      data,
-				Source:    "stderr",
-				Timestamp: t,
-			}
-
-			buf := bytes.NewBuffer(nil)
-			assert.NilError(b, marshalMessage(testMsg, nil, buf))
-			b.SetBytes(int64(buf.Len()))
-			b.ResetTimer()
-			for i := 0; i < b.N; i++ {
-				msg := logger.NewMessage()
-				msg.Line = testMsg.Line
-				msg.Timestamp = testMsg.Timestamp
-				msg.Source = testMsg.Source
-				if err := jsonlogger.Log(msg); err != nil {
-					b.Fatal(err)
-				}
-			}
-		})
-	}
-}
-
-func TestJSONFileLoggerWithOpts(t *testing.T) {
-	cid := "a7317399f3f857173c6179d44823594f8294678dea9999662e5c625b5a1c7657"
-	tmp, err := ioutil.TempDir("", "docker-logger-")
-	if err != nil {
-		t.Fatal(err)
-	}
-	defer os.RemoveAll(tmp)
-	filename := filepath.Join(tmp, "container.log")
-	config := map[string]string{"max-file": "3", "max-size": "1k", "compress": "true"}
-	l, err := New(logger.Info{
-		ContainerID: cid,
-		LogPath:     filename,
-		Config:      config,
-	})
-	if err != nil {
-		t.Fatal(err)
-	}
-	defer l.Close()
-	for i := 0; i < 36; i++ {
-		if err := l.Log(&logger.Message{Line: []byte("line" + strconv.Itoa(i)), Source: "src1"}); err != nil {
-			t.Fatal(err)
-		}
-	}
-
-	res, err := ioutil.ReadFile(filename)
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	penUlt, err := ioutil.ReadFile(filename + ".1")
-	if err != nil {
-		if !os.IsNotExist(err) {
-			t.Fatal(err)
-		}
-
-		file, err := os.Open(filename + ".1.gz")
-		defer file.Close()
-		if err != nil {
-			t.Fatal(err)
-		}
-		zipReader, err := gzip.NewReader(file)
-		defer zipReader.Close()
-		if err != nil {
-			t.Fatal(err)
-		}
-		penUlt, err = ioutil.ReadAll(zipReader)
-		if err != nil {
-			t.Fatal(err)
-		}
-	}
-
-	file, err := os.Open(filename + ".2.gz")
-	defer file.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-	zipReader, err := gzip.NewReader(file)
-	defer zipReader.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-	antepenult, err := ioutil.ReadAll(zipReader)
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	expectedAntepenultimate := `{"log":"line0\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line1\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line2\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line3\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line4\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line5\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line6\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line7\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line8\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line9\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line10\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line11\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line12\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line13\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line14\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line15\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-`
-	expectedPenultimate := `{"log":"line16\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line17\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line18\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line19\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line20\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line21\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line22\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line23\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line24\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line25\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line26\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line27\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line28\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line29\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line30\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line31\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-`
-	expected := `{"log":"line32\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line33\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line34\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-{"log":"line35\n","stream":"src1","time":"0001-01-01T00:00:00Z"}
-`
-
-	if string(res) != expected {
-		t.Fatalf("Wrong log content: %q, expected %q", res, expected)
-	}
-	if string(penUlt) != expectedPenultimate {
-		t.Fatalf("Wrong log content: %q, expected %q", penUlt, expectedPenultimate)
-	}
-	if string(antepenult) != expectedAntepenultimate {
-		t.Fatalf("Wrong log content: %q, expected %q", antepenult, expectedAntepenultimate)
-	}
-}
-
-func TestJSONFileLoggerWithLabelsEnv(t *testing.T) {
-	cid := "a7317399f3f857173c6179d44823594f8294678dea9999662e5c625b5a1c7657"
-	tmp, err := ioutil.TempDir("", "docker-logger-")
-	if err != nil {
-		t.Fatal(err)
-	}
-	defer os.RemoveAll(tmp)
-	filename := filepath.Join(tmp, "container.log")
-	config := map[string]string{"labels": "rack,dc", "env": "environ,debug,ssl", "env-regex": "^dc"}
-	l, err := New(logger.Info{
-		ContainerID:     cid,
-		LogPath:         filename,
-		Config:          config,
-		ContainerLabels: map[string]string{"rack": "101", "dc": "lhr"},
-		ContainerEnv:    []string{"environ=production", "debug=false", "port=10001", "ssl=true", "dc_region=west"},
-	})
-	if err != nil {
-		t.Fatal(err)
-	}
-	defer l.Close()
-	if err := l.Log(&logger.Message{Line: []byte("line"), Source: "src1"}); err != nil {
-		t.Fatal(err)
-	}
-	res, err := ioutil.ReadFile(filename)
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	var jsonLog jsonlog.JSONLogs
-	if err := json.Unmarshal(res, &jsonLog); err != nil {
-		t.Fatal(err)
-	}
-	extra := make(map[string]string)
-	if err := json.Unmarshal(jsonLog.RawAttrs, &extra); err != nil {
-		t.Fatal(err)
-	}
-	expected := map[string]string{
-		"rack":      "101",
-		"dc":        "lhr",
-		"environ":   "production",
-		"debug":     "false",
-		"ssl":       "true",
-		"dc_region": "west",
-	}
-	if !reflect.DeepEqual(extra, expected) {
-		t.Fatalf("Wrong log attrs: %q, expected %q", extra, expected)
-	}
-}
diff --git a/components/engine/daemon/logger/jsonfilelog/jsonlog/jsonlog.go b/components/engine/daemon/logger/jsonfilelog/jsonlog/jsonlog.go
deleted file mode 100644
index 74be8e7..0000000
--- a/components/engine/daemon/logger/jsonfilelog/jsonlog/jsonlog.go
+++ /dev/null
@@ -1,25 +0,0 @@
-package jsonlog // import "github.com/docker/docker/daemon/logger/jsonfilelog/jsonlog"
-
-import (
-	"time"
-)
-
-// JSONLog is a log message, typically a single entry from a given log stream.
-type JSONLog struct {
-	// Log is the log message
-	Log string `json:"log,omitempty"`
-	// Stream is the log source
-	Stream string `json:"stream,omitempty"`
-	// Created is the created timestamp of log
-	Created time.Time `json:"time"`
-	// Attrs is the list of extra attributes provided by the user
-	Attrs map[string]string `json:"attrs,omitempty"`
-}
-
-// Reset all fields to their zero value.
-func (jl *JSONLog) Reset() {
-	jl.Log = ""
-	jl.Stream = ""
-	jl.Created = time.Time{}
-	jl.Attrs = make(map[string]string)
-}
diff --git a/components/engine/daemon/logger/jsonfilelog/jsonlog/jsonlogbytes.go b/components/engine/daemon/logger/jsonfilelog/jsonlog/jsonlogbytes.go
deleted file mode 100644
index 577c718..0000000
--- a/components/engine/daemon/logger/jsonfilelog/jsonlog/jsonlogbytes.go
+++ /dev/null
@@ -1,125 +0,0 @@
-package jsonlog // import "github.com/docker/docker/daemon/logger/jsonfilelog/jsonlog"
-
-import (
-	"bytes"
-	"encoding/json"
-	"time"
-	"unicode/utf8"
-)
-
-// JSONLogs marshals encoded JSONLog objects
-type JSONLogs struct {
-	Log     []byte    `json:"log,omitempty"`
-	Stream  string    `json:"stream,omitempty"`
-	Created time.Time `json:"time"`
-
-	// json-encoded bytes
-	RawAttrs json.RawMessage `json:"attrs,omitempty"`
-}
-
-// MarshalJSONBuf is an optimized JSON marshaller that avoids reflection
-// and unnecessary allocation.
-func (mj *JSONLogs) MarshalJSONBuf(buf *bytes.Buffer) error {
-	var first = true
-
-	buf.WriteString(`{`)
-	if len(mj.Log) != 0 {
-		first = false
-		buf.WriteString(`"log":`)
-		ffjsonWriteJSONBytesAsString(buf, mj.Log)
-	}
-	if len(mj.Stream) != 0 {
-		if first {
-			first = false
-		} else {
-			buf.WriteString(`,`)
-		}
-		buf.WriteString(`"stream":`)
-		ffjsonWriteJSONBytesAsString(buf, []byte(mj.Stream))
-	}
-	if len(mj.RawAttrs) > 0 {
-		if first {
-			first = false
-		} else {
-			buf.WriteString(`,`)
-		}
-		buf.WriteString(`"attrs":`)
-		buf.Write(mj.RawAttrs)
-	}
-	if !first {
-		buf.WriteString(`,`)
-	}
-
-	created, err := fastTimeMarshalJSON(mj.Created)
-	if err != nil {
-		return err
-	}
-
-	buf.WriteString(`"time":`)
-	buf.WriteString(created)
-	buf.WriteString(`}`)
-	return nil
-}
-
-func ffjsonWriteJSONBytesAsString(buf *bytes.Buffer, s []byte) {
-	const hex = "0123456789abcdef"
-
-	buf.WriteByte('"')
-	start := 0
-	for i := 0; i < len(s); {
-		if b := s[i]; b < utf8.RuneSelf {
-			if 0x20 <= b && b != '\\' && b != '"' && b != '<' && b != '>' && b != '&' {
-				i++
-				continue
-			}
-			if start < i {
-				buf.Write(s[start:i])
-			}
-			switch b {
-			case '\\', '"':
-				buf.WriteByte('\\')
-				buf.WriteByte(b)
-			case '\n':
-				buf.WriteByte('\\')
-				buf.WriteByte('n')
-			case '\r':
-				buf.WriteByte('\\')
-				buf.WriteByte('r')
-			default:
-
-				buf.WriteString(`\u00`)
-				buf.WriteByte(hex[b>>4])
-				buf.WriteByte(hex[b&0xF])
-			}
-			i++
-			start = i
-			continue
-		}
-		c, size := utf8.DecodeRune(s[i:])
-		if c == utf8.RuneError && size == 1 {
-			if start < i {
-				buf.Write(s[start:i])
-			}
-			buf.WriteString(`\ufffd`)
-			i += size
-			start = i
-			continue
-		}
-
-		if c == '\u2028' || c == '\u2029' {
-			if start < i {
-				buf.Write(s[start:i])
-			}
-			buf.WriteString(`\u202`)
-			buf.WriteByte(hex[c&0xF])
-			i += size
-			start = i
-			continue
-		}
-		i += size
-	}
-	if start < len(s) {
-		buf.Write(s[start:])
-	}
-	buf.WriteByte('"')
-}
diff --git a/components/engine/daemon/logger/jsonfilelog/jsonlog/jsonlogbytes_test.go b/components/engine/daemon/logger/jsonfilelog/jsonlog/jsonlogbytes_test.go
deleted file mode 100644
index d268db4..0000000
--- a/components/engine/daemon/logger/jsonfilelog/jsonlog/jsonlogbytes_test.go
+++ /dev/null
@@ -1,51 +0,0 @@
-package jsonlog // import "github.com/docker/docker/daemon/logger/jsonfilelog/jsonlog"
-
-import (
-	"bytes"
-	"encoding/json"
-	"fmt"
-	"regexp"
-	"testing"
-	"time"
-
-	"gotest.tools/assert"
-)
-
-func TestJSONLogsMarshalJSONBuf(t *testing.T) {
-	logs := map[*JSONLogs]string{
-		{Log: []byte(`"A log line with \\"`)}:                  `^{\"log\":\"\\\"A log line with \\\\\\\\\\\"\",\"time\":`,
-		{Log: []byte("A log line")}:                            `^{\"log\":\"A log line\",\"time\":`,
-		{Log: []byte("A log line with \r")}:                    `^{\"log\":\"A log line with \\r\",\"time\":`,
-		{Log: []byte("A log line with & < >")}:                 `^{\"log\":\"A log line with \\u0026 \\u003c \\u003e\",\"time\":`,
-		{Log: []byte("A log line with utf8 :    ")}:        `^{\"log\":\"A log line with utf8 :    \",\"time\":`,
-		{Stream: "stdout"}:                                     `^{\"stream\":\"stdout\",\"time\":`,
-		{Stream: "stdout", Log: []byte("A log line")}:          `^{\"log\":\"A log line\",\"stream\":\"stdout\",\"time\":`,
-		{Created: time.Date(2017, 9, 1, 1, 1, 1, 1, time.UTC)}: `^{\"time\":"2017-09-01T01:01:01.000000001Z"}$`,
-
-		{}: `^{\"time\":"0001-01-01T00:00:00Z"}$`,
-		// These ones are a little weird
-		{Log: []byte("\u2028 \u2029")}: `^{\"log\":\"\\u2028 \\u2029\",\"time\":`,
-		{Log: []byte{0xaF}}:            `^{\"log\":\"\\ufffd\",\"time\":`,
-		{Log: []byte{0x7F}}:            `^{\"log\":\"\x7f\",\"time\":`,
-		// with raw attributes
-		{Log: []byte("A log line"), RawAttrs: []byte(`{"hello":"world","value":1234}`)}: `^{\"log\":\"A log line\",\"attrs\":{\"hello\":\"world\",\"value\":1234},\"time\":`,
-		// with Tag set
-		{Log: []byte("A log line with tag"), RawAttrs: []byte(`{"hello":"world","value":1234}`)}: `^{\"log\":\"A log line with tag\",\"attrs\":{\"hello\":\"world\",\"value\":1234},\"time\":`,
-	}
-	for jsonLog, expression := range logs {
-		var buf bytes.Buffer
-		err := jsonLog.MarshalJSONBuf(&buf)
-		assert.NilError(t, err)
-
-		assert.Assert(t, regexP(buf.String(), expression))
-		assert.NilError(t, json.Unmarshal(buf.Bytes(), &map[string]interface{}{}))
-	}
-}
-
-func regexP(value string, pattern string) func() (bool, string) {
-	return func() (bool, string) {
-		re := regexp.MustCompile(pattern)
-		msg := fmt.Sprintf("%q did not match pattern %q", value, pattern)
-		return re.MatchString(value), msg
-	}
-}
diff --git a/components/engine/daemon/logger/jsonfilelog/jsonlog/time_marshalling.go b/components/engine/daemon/logger/jsonfilelog/jsonlog/time_marshalling.go
deleted file mode 100644
index 1822ea5..0000000
--- a/components/engine/daemon/logger/jsonfilelog/jsonlog/time_marshalling.go
+++ /dev/null
@@ -1,20 +0,0 @@
-package jsonlog // import "github.com/docker/docker/daemon/logger/jsonfilelog/jsonlog"
-
-import (
-	"time"
-
-	"github.com/pkg/errors"
-)
-
-const jsonFormat = `"` + time.RFC3339Nano + `"`
-
-// fastTimeMarshalJSON avoids one of the extra allocations that
-// time.MarshalJSON is making.
-func fastTimeMarshalJSON(t time.Time) (string, error) {
-	if y := t.Year(); y < 0 || y >= 10000 {
-		// RFC 3339 is clear that years are 4 digits exactly.
-		// See golang.org/issue/4556#c15 for more discussion.
-		return "", errors.New("time.MarshalJSON: year outside of range [0,9999]")
-	}
-	return t.Format(jsonFormat), nil
-}
diff --git a/components/engine/daemon/logger/jsonfilelog/jsonlog/time_marshalling_test.go b/components/engine/daemon/logger/jsonfilelog/jsonlog/time_marshalling_test.go
deleted file mode 100644
index b3959b0..0000000
--- a/components/engine/daemon/logger/jsonfilelog/jsonlog/time_marshalling_test.go
+++ /dev/null
@@ -1,34 +0,0 @@
-package jsonlog // import "github.com/docker/docker/daemon/logger/jsonfilelog/jsonlog"
-
-import (
-	"testing"
-	"time"
-
-	"gotest.tools/assert"
-	is "gotest.tools/assert/cmp"
-)
-
-func TestFastTimeMarshalJSONWithInvalidYear(t *testing.T) {
-	aTime := time.Date(-1, 1, 1, 0, 0, 0, 0, time.Local)
-	_, err := fastTimeMarshalJSON(aTime)
-	assert.Check(t, is.ErrorContains(err, "year outside of range"))
-
-	anotherTime := time.Date(10000, 1, 1, 0, 0, 0, 0, time.Local)
-	_, err = fastTimeMarshalJSON(anotherTime)
-	assert.Check(t, is.ErrorContains(err, "year outside of range"))
-}
-
-func TestFastTimeMarshalJSON(t *testing.T) {
-	aTime := time.Date(2015, 5, 29, 11, 1, 2, 3, time.UTC)
-	json, err := fastTimeMarshalJSON(aTime)
-	assert.NilError(t, err)
-	assert.Check(t, is.Equal("\"2015-05-29T11:01:02.000000003Z\"", json))
-
-	location, err := time.LoadLocation("Europe/Paris")
-	assert.NilError(t, err)
-
-	aTime = time.Date(2015, 5, 29, 11, 1, 2, 3, location)
-	json, err = fastTimeMarshalJSON(aTime)
-	assert.NilError(t, err)
-	assert.Check(t, is.Equal("\"2015-05-29T11:01:02.000000003+02:00\"", json))
-}
diff --git a/components/engine/daemon/logger/jsonfilelog/read.go b/components/engine/daemon/logger/jsonfilelog/read.go
deleted file mode 100644
index 12f676b..0000000
--- a/components/engine/daemon/logger/jsonfilelog/read.go
+++ /dev/null
@@ -1,97 +0,0 @@
-package jsonfilelog // import "github.com/docker/docker/daemon/logger/jsonfilelog"
-
-import (
-	"context"
-	"encoding/json"
-	"io"
-
-	"github.com/docker/docker/api/types/backend"
-	"github.com/docker/docker/daemon/logger"
-	"github.com/docker/docker/daemon/logger/jsonfilelog/jsonlog"
-	"github.com/docker/docker/daemon/logger/loggerutils"
-	"github.com/docker/docker/pkg/tailfile"
-	"github.com/sirupsen/logrus"
-)
-
-const maxJSONDecodeRetry = 20000
-
-// ReadLogs implements the logger's LogReader interface for the logs
-// created by this driver.
-func (l *JSONFileLogger) ReadLogs(config logger.ReadConfig) *logger.LogWatcher {
-	logWatcher := logger.NewLogWatcher()
-
-	go l.readLogs(logWatcher, config)
-	return logWatcher
-}
-
-func (l *JSONFileLogger) readLogs(watcher *logger.LogWatcher, config logger.ReadConfig) {
-	defer close(watcher.Msg)
-
-	l.mu.Lock()
-	l.readers[watcher] = struct{}{}
-	l.mu.Unlock()
-
-	l.writer.ReadLogs(config, watcher)
-
-	l.mu.Lock()
-	delete(l.readers, watcher)
-	l.mu.Unlock()
-}
-
-func decodeLogLine(dec *json.Decoder, l *jsonlog.JSONLog) (*logger.Message, error) {
-	l.Reset()
-	if err := dec.Decode(l); err != nil {
-		return nil, err
-	}
-
-	var attrs []backend.LogAttr
-	if len(l.Attrs) != 0 {
-		attrs = make([]backend.LogAttr, 0, len(l.Attrs))
-		for k, v := range l.Attrs {
-			attrs = append(attrs, backend.LogAttr{Key: k, Value: v})
-		}
-	}
-	msg := &logger.Message{
-		Source:    l.Stream,
-		Timestamp: l.Created,
-		Line:      []byte(l.Log),
-		Attrs:     attrs,
-	}
-	return msg, nil
-}
-
-// decodeFunc is used to create a decoder for the log file reader
-func decodeFunc(rdr io.Reader) func() (*logger.Message, error) {
-	l := &jsonlog.JSONLog{}
-	dec := json.NewDecoder(rdr)
-	return func() (msg *logger.Message, err error) {
-		for retries := 0; retries < maxJSONDecodeRetry; retries++ {
-			msg, err = decodeLogLine(dec, l)
-			if err == nil || err == io.EOF {
-				break
-			}
-
-			logrus.WithError(err).WithField("retries", retries).Warn("got error while decoding json")
-			// try again, could be due to a an incomplete json object as we read
-			if _, ok := err.(*json.SyntaxError); ok {
-				dec = json.NewDecoder(rdr)
-				continue
-			}
-
-			// io.ErrUnexpectedEOF is returned from json.Decoder when there is
-			// remaining data in the parser's buffer while an io.EOF occurs.
-			// If the json logger writes a partial json log entry to the disk
-			// while at the same time the decoder tries to decode it, the race condition happens.
-			if err == io.ErrUnexpectedEOF {
-				reader := io.MultiReader(dec.Buffered(), rdr)
-				dec = json.NewDecoder(reader)
-				continue
-			}
-		}
-		return msg, err
-	}
-}
-
-func getTailReader(ctx context.Context, r loggerutils.SizeReaderAt, req int) (io.Reader, int, error) {
-	return tailfile.NewTailReader(ctx, r, req)
-}
diff --git a/components/engine/daemon/logger/jsonfilelog/read_test.go b/components/engine/daemon/logger/jsonfilelog/read_test.go
deleted file mode 100644
index 0206ecb..0000000
--- a/components/engine/daemon/logger/jsonfilelog/read_test.go
+++ /dev/null
@@ -1,93 +0,0 @@
-package jsonfilelog // import "github.com/docker/docker/daemon/logger/jsonfilelog"
-
-import (
-	"bytes"
-	"io"
-	"testing"
-	"time"
-
-	"github.com/docker/docker/daemon/logger"
-	"gotest.tools/assert"
-	"gotest.tools/fs"
-)
-
-func BenchmarkJSONFileLoggerReadLogs(b *testing.B) {
-	tmp := fs.NewDir(b, "bench-jsonfilelog")
-	defer tmp.Remove()
-
-	jsonlogger, err := New(logger.Info{
-		ContainerID: "a7317399f3f857173c6179d44823594f8294678dea9999662e5c625b5a1c7657",
-		LogPath:     tmp.Join("container.log"),
-		Config: map[string]string{
-			"labels": "first,second",
-		},
-		ContainerLabels: map[string]string{
-			"first":  "label_value",
-			"second": "label_foo",
-		},
-	})
-	assert.NilError(b, err)
-	defer jsonlogger.Close()
-
-	msg := &logger.Message{
-		Line:      []byte("Line that thinks that it is log line from docker\n"),
-		Source:    "stderr",
-		Timestamp: time.Now().UTC(),
-	}
-
-	buf := bytes.NewBuffer(nil)
-	assert.NilError(b, marshalMessage(msg, nil, buf))
-	b.SetBytes(int64(buf.Len()))
-
-	b.ResetTimer()
-
-	chError := make(chan error, b.N+1)
-	go func() {
-		for i := 0; i < b.N; i++ {
-			chError <- jsonlogger.Log(msg)
-		}
-		chError <- jsonlogger.Close()
-	}()
-
-	lw := jsonlogger.(*JSONFileLogger).ReadLogs(logger.ReadConfig{Follow: true})
-	for {
-		select {
-		case <-lw.Msg:
-		case <-lw.WatchProducerGone():
-			return
-		case err := <-chError:
-			if err != nil {
-				b.Fatal(err)
-			}
-		}
-	}
-}
-
-func TestEncodeDecode(t *testing.T) {
-	t.Parallel()
-
-	m1 := &logger.Message{Line: []byte("hello 1"), Timestamp: time.Now(), Source: "stdout"}
-	m2 := &logger.Message{Line: []byte("hello 2"), Timestamp: time.Now(), Source: "stdout"}
-	m3 := &logger.Message{Line: []byte("hello 3"), Timestamp: time.Now(), Source: "stdout"}
-
-	buf := bytes.NewBuffer(nil)
-	assert.Assert(t, marshalMessage(m1, nil, buf))
-	assert.Assert(t, marshalMessage(m2, nil, buf))
-	assert.Assert(t, marshalMessage(m3, nil, buf))
-
-	decode := decodeFunc(buf)
-	msg, err := decode()
-	assert.NilError(t, err)
-	assert.Assert(t, string(msg.Line) == "hello 1\n", string(msg.Line))
-
-	msg, err = decode()
-	assert.NilError(t, err)
-	assert.Assert(t, string(msg.Line) == "hello 2\n")
-
-	msg, err = decode()
-	assert.NilError(t, err)
-	assert.Assert(t, string(msg.Line) == "hello 3\n")
-
-	_, err = decode()
-	assert.Assert(t, err == io.EOF)
-}
diff --git a/components/engine/daemon/logger/local/local.go b/components/engine/daemon/logger/local/local.go
index ba4aa09..a076dfd 100644
--- a/components/engine/daemon/logger/local/local.go
+++ b/components/engine/daemon/logger/local/local.go
@@ -27,7 +27,7 @@ const (
 
 	defaultMaxFileSize  int64 = 20 * 1024 * 1024
 	defaultMaxFileCount       = 5
-	defaultCompressLogs       = true
+	defaultCompressLogs       = false
 )
 
 // LogOptKeys are the keys names used for log opts passed in to initialize the driver.
diff --git a/components/engine/daemon/logger/splunk/splunk.go b/components/engine/daemon/logger/splunk/splunk.go
deleted file mode 100644
index 8756ffa..0000000
--- a/components/engine/daemon/logger/splunk/splunk.go
+++ /dev/null
@@ -1,649 +0,0 @@
-// Package splunk provides the log driver for forwarding server logs to
-// Splunk HTTP Event Collector endpoint.
-package splunk // import "github.com/docker/docker/daemon/logger/splunk"
-
-import (
-	"bytes"
-	"compress/gzip"
-	"context"
-	"crypto/tls"
-	"crypto/x509"
-	"encoding/json"
-	"fmt"
-	"io"
-	"io/ioutil"
-	"net/http"
-	"net/url"
-	"os"
-	"strconv"
-	"strings"
-	"sync"
-	"time"
-
-	"github.com/docker/docker/daemon/logger"
-	"github.com/docker/docker/daemon/logger/loggerutils"
-	"github.com/docker/docker/pkg/pools"
-	"github.com/docker/docker/pkg/urlutil"
-	"github.com/sirupsen/logrus"
-)
-
-const (
-	driverName                    = "splunk"
-	splunkURLKey                  = "splunk-url"
-	splunkTokenKey                = "splunk-token"
-	splunkSourceKey               = "splunk-source"
-	splunkSourceTypeKey           = "splunk-sourcetype"
-	splunkIndexKey                = "splunk-index"
-	splunkCAPathKey               = "splunk-capath"
-	splunkCANameKey               = "splunk-caname"
-	splunkInsecureSkipVerifyKey   = "splunk-insecureskipverify"
-	splunkFormatKey               = "splunk-format"
-	splunkVerifyConnectionKey     = "splunk-verify-connection"
-	splunkGzipCompressionKey      = "splunk-gzip"
-	splunkGzipCompressionLevelKey = "splunk-gzip-level"
-	envKey                        = "env"
-	envRegexKey                   = "env-regex"
-	labelsKey                     = "labels"
-	tagKey                        = "tag"
-)
-
-const (
-	// How often do we send messages (if we are not reaching batch size)
-	defaultPostMessagesFrequency = 5 * time.Second
-	// How big can be batch of messages
-	defaultPostMessagesBatchSize = 1000
-	// Maximum number of messages we can store in buffer
-	defaultBufferMaximum = 10 * defaultPostMessagesBatchSize
-	// Number of messages allowed to be queued in the channel
-	defaultStreamChannelSize = 4 * defaultPostMessagesBatchSize
-	// maxResponseSize is the max amount that will be read from an http response
-	maxResponseSize = 1024
-)
-
-const (
-	envVarPostMessagesFrequency = "SPLUNK_LOGGING_DRIVER_POST_MESSAGES_FREQUENCY"
-	envVarPostMessagesBatchSize = "SPLUNK_LOGGING_DRIVER_POST_MESSAGES_BATCH_SIZE"
-	envVarBufferMaximum         = "SPLUNK_LOGGING_DRIVER_BUFFER_MAX"
-	envVarStreamChannelSize     = "SPLUNK_LOGGING_DRIVER_CHANNEL_SIZE"
-)
-
-var batchSendTimeout = 30 * time.Second
-
-type splunkLoggerInterface interface {
-	logger.Logger
-	worker()
-}
-
-type splunkLogger struct {
-	client    *http.Client
-	transport *http.Transport
-
-	url         string
-	auth        string
-	nullMessage *splunkMessage
-
-	// http compression
-	gzipCompression      bool
-	gzipCompressionLevel int
-
-	// Advanced options
-	postMessagesFrequency time.Duration
-	postMessagesBatchSize int
-	bufferMaximum         int
-
-	// For synchronization between background worker and logger.
-	// We use channel to send messages to worker go routine.
-	// All other variables for blocking Close call before we flush all messages to HEC
-	stream     chan *splunkMessage
-	lock       sync.RWMutex
-	closed     bool
-	closedCond *sync.Cond
-}
-
-type splunkLoggerInline struct {
-	*splunkLogger
-
-	nullEvent *splunkMessageEvent
-}
-
-type splunkLoggerJSON struct {
-	*splunkLoggerInline
-}
-
-type splunkLoggerRaw struct {
-	*splunkLogger
-
-	prefix []byte
-}
-
-type splunkMessage struct {
-	Event      interface{} `json:"event"`
-	Time       string      `json:"time"`
-	Host       string      `json:"host"`
-	Source     string      `json:"source,omitempty"`
-	SourceType string      `json:"sourcetype,omitempty"`
-	Index      string      `json:"index,omitempty"`
-}
-
-type splunkMessageEvent struct {
-	Line   interface{}       `json:"line"`
-	Source string            `json:"source"`
-	Tag    string            `json:"tag,omitempty"`
-	Attrs  map[string]string `json:"attrs,omitempty"`
-}
-
-const (
-	splunkFormatRaw    = "raw"
-	splunkFormatJSON   = "json"
-	splunkFormatInline = "inline"
-)
-
-func init() {
-	if err := logger.RegisterLogDriver(driverName, New); err != nil {
-		logrus.Fatal(err)
-	}
-	if err := logger.RegisterLogOptValidator(driverName, ValidateLogOpt); err != nil {
-		logrus.Fatal(err)
-	}
-}
-
-// New creates splunk logger driver using configuration passed in context
-func New(info logger.Info) (logger.Logger, error) {
-	hostname, err := info.Hostname()
-	if err != nil {
-		return nil, fmt.Errorf("%s: cannot access hostname to set source field", driverName)
-	}
-
-	// Parse and validate Splunk URL
-	splunkURL, err := parseURL(info)
-	if err != nil {
-		return nil, err
-	}
-
-	// Splunk Token is required parameter
-	splunkToken, ok := info.Config[splunkTokenKey]
-	if !ok {
-		return nil, fmt.Errorf("%s: %s is expected", driverName, splunkTokenKey)
-	}
-
-	tlsConfig := &tls.Config{}
-
-	// Splunk is using autogenerated certificates by default,
-	// allow users to trust them with skipping verification
-	if insecureSkipVerifyStr, ok := info.Config[splunkInsecureSkipVerifyKey]; ok {
-		insecureSkipVerify, err := strconv.ParseBool(insecureSkipVerifyStr)
-		if err != nil {
-			return nil, err
-		}
-		tlsConfig.InsecureSkipVerify = insecureSkipVerify
-	}
-
-	// If path to the root certificate is provided - load it
-	if caPath, ok := info.Config[splunkCAPathKey]; ok {
-		caCert, err := ioutil.ReadFile(caPath)
-		if err != nil {
-			return nil, err
-		}
-		caPool := x509.NewCertPool()
-		caPool.AppendCertsFromPEM(caCert)
-		tlsConfig.RootCAs = caPool
-	}
-
-	if caName, ok := info.Config[splunkCANameKey]; ok {
-		tlsConfig.ServerName = caName
-	}
-
-	gzipCompression := false
-	if gzipCompressionStr, ok := info.Config[splunkGzipCompressionKey]; ok {
-		gzipCompression, err = strconv.ParseBool(gzipCompressionStr)
-		if err != nil {
-			return nil, err
-		}
-	}
-
-	gzipCompressionLevel := gzip.DefaultCompression
-	if gzipCompressionLevelStr, ok := info.Config[splunkGzipCompressionLevelKey]; ok {
-		var err error
-		gzipCompressionLevel64, err := strconv.ParseInt(gzipCompressionLevelStr, 10, 32)
-		if err != nil {
-			return nil, err
-		}
-		gzipCompressionLevel = int(gzipCompressionLevel64)
-		if gzipCompressionLevel < gzip.DefaultCompression || gzipCompressionLevel > gzip.BestCompression {
-			err := fmt.Errorf("not supported level '%s' for %s (supported values between %d and %d)",
-				gzipCompressionLevelStr, splunkGzipCompressionLevelKey, gzip.DefaultCompression, gzip.BestCompression)
-			return nil, err
-		}
-	}
-
-	transport := &http.Transport{
-		TLSClientConfig: tlsConfig,
-		Proxy:           http.ProxyFromEnvironment,
-	}
-	client := &http.Client{
-		Transport: transport,
-	}
-
-	source := info.Config[splunkSourceKey]
-	sourceType := info.Config[splunkSourceTypeKey]
-	index := info.Config[splunkIndexKey]
-
-	var nullMessage = &splunkMessage{
-		Host:       hostname,
-		Source:     source,
-		SourceType: sourceType,
-		Index:      index,
-	}
-
-	// Allow user to remove tag from the messages by setting tag to empty string
-	tag := ""
-	if tagTemplate, ok := info.Config[tagKey]; !ok || tagTemplate != "" {
-		tag, err = loggerutils.ParseLogTag(info, loggerutils.DefaultTemplate)
-		if err != nil {
-			return nil, err
-		}
-	}
-
-	attrs, err := info.ExtraAttributes(nil)
-	if err != nil {
-		return nil, err
-	}
-
-	var (
-		postMessagesFrequency = getAdvancedOptionDuration(envVarPostMessagesFrequency, defaultPostMessagesFrequency)
-		postMessagesBatchSize = getAdvancedOptionInt(envVarPostMessagesBatchSize, defaultPostMessagesBatchSize)
-		bufferMaximum         = getAdvancedOptionInt(envVarBufferMaximum, defaultBufferMaximum)
-		streamChannelSize     = getAdvancedOptionInt(envVarStreamChannelSize, defaultStreamChannelSize)
-	)
-
-	logger := &splunkLogger{
-		client:                client,
-		transport:             transport,
-		url:                   splunkURL.String(),
-		auth:                  "Splunk " + splunkToken,
-		nullMessage:           nullMessage,
-		gzipCompression:       gzipCompression,
-		gzipCompressionLevel:  gzipCompressionLevel,
-		stream:                make(chan *splunkMessage, streamChannelSize),
-		postMessagesFrequency: postMessagesFrequency,
-		postMessagesBatchSize: postMessagesBatchSize,
-		bufferMaximum:         bufferMaximum,
-	}
-
-	// By default we verify connection, but we allow use to skip that
-	verifyConnection := true
-	if verifyConnectionStr, ok := info.Config[splunkVerifyConnectionKey]; ok {
-		var err error
-		verifyConnection, err = strconv.ParseBool(verifyConnectionStr)
-		if err != nil {
-			return nil, err
-		}
-	}
-	if verifyConnection {
-		err = verifySplunkConnection(logger)
-		if err != nil {
-			return nil, err
-		}
-	}
-
-	var splunkFormat string
-	if splunkFormatParsed, ok := info.Config[splunkFormatKey]; ok {
-		switch splunkFormatParsed {
-		case splunkFormatInline:
-		case splunkFormatJSON:
-		case splunkFormatRaw:
-		default:
-			return nil, fmt.Errorf("Unknown format specified %s, supported formats are inline, json and raw", splunkFormat)
-		}
-		splunkFormat = splunkFormatParsed
-	} else {
-		splunkFormat = splunkFormatInline
-	}
-
-	var loggerWrapper splunkLoggerInterface
-
-	switch splunkFormat {
-	case splunkFormatInline:
-		nullEvent := &splunkMessageEvent{
-			Tag:   tag,
-			Attrs: attrs,
-		}
-
-		loggerWrapper = &splunkLoggerInline{logger, nullEvent}
-	case splunkFormatJSON:
-		nullEvent := &splunkMessageEvent{
-			Tag:   tag,
-			Attrs: attrs,
-		}
-
-		loggerWrapper = &splunkLoggerJSON{&splunkLoggerInline{logger, nullEvent}}
-	case splunkFormatRaw:
-		var prefix bytes.Buffer
-		if tag != "" {
-			prefix.WriteString(tag)
-			prefix.WriteString(" ")
-		}
-		for key, value := range attrs {
-			prefix.WriteString(key)
-			prefix.WriteString("=")
-			prefix.WriteString(value)
-			prefix.WriteString(" ")
-		}
-
-		loggerWrapper = &splunkLoggerRaw{logger, prefix.Bytes()}
-	default:
-		return nil, fmt.Errorf("Unexpected format %s", splunkFormat)
-	}
-
-	go loggerWrapper.worker()
-
-	return loggerWrapper, nil
-}
-
-func (l *splunkLoggerInline) Log(msg *logger.Message) error {
-	message := l.createSplunkMessage(msg)
-
-	event := *l.nullEvent
-	event.Line = string(msg.Line)
-	event.Source = msg.Source
-
-	message.Event = &event
-	logger.PutMessage(msg)
-	return l.queueMessageAsync(message)
-}
-
-func (l *splunkLoggerJSON) Log(msg *logger.Message) error {
-	message := l.createSplunkMessage(msg)
-	event := *l.nullEvent
-
-	var rawJSONMessage json.RawMessage
-	if err := json.Unmarshal(msg.Line, &rawJSONMessage); err == nil {
-		event.Line = &rawJSONMessage
-	} else {
-		event.Line = string(msg.Line)
-	}
-
-	event.Source = msg.Source
-
-	message.Event = &event
-	logger.PutMessage(msg)
-	return l.queueMessageAsync(message)
-}
-
-func (l *splunkLoggerRaw) Log(msg *logger.Message) error {
-	// empty or whitespace-only messages are not accepted by HEC
-	if strings.TrimSpace(string(msg.Line)) == "" {
-		return nil
-	}
-
-	message := l.createSplunkMessage(msg)
-
-	message.Event = string(append(l.prefix, msg.Line...))
-	logger.PutMessage(msg)
-	return l.queueMessageAsync(message)
-}
-
-func (l *splunkLogger) queueMessageAsync(message *splunkMessage) error {
-	l.lock.RLock()
-	defer l.lock.RUnlock()
-	if l.closedCond != nil {
-		return fmt.Errorf("%s: driver is closed", driverName)
-	}
-	l.stream <- message
-	return nil
-}
-
-func (l *splunkLogger) worker() {
-	timer := time.NewTicker(l.postMessagesFrequency)
-	var messages []*splunkMessage
-	for {
-		select {
-		case message, open := <-l.stream:
-			if !open {
-				l.postMessages(messages, true)
-				l.lock.Lock()
-				defer l.lock.Unlock()
-				l.transport.CloseIdleConnections()
-				l.closed = true
-				l.closedCond.Signal()
-				return
-			}
-			messages = append(messages, message)
-			// Only sending when we get exactly to the batch size,
-			// This also helps not to fire postMessages on every new message,
-			// when previous try failed.
-			if len(messages)%l.postMessagesBatchSize == 0 {
-				messages = l.postMessages(messages, false)
-			}
-		case <-timer.C:
-			messages = l.postMessages(messages, false)
-		}
-	}
-}
-
-func (l *splunkLogger) postMessages(messages []*splunkMessage, lastChance bool) []*splunkMessage {
-	messagesLen := len(messages)
-
-	ctx, cancel := context.WithTimeout(context.Background(), batchSendTimeout)
-	defer cancel()
-
-	for i := 0; i < messagesLen; i += l.postMessagesBatchSize {
-		upperBound := i + l.postMessagesBatchSize
-		if upperBound > messagesLen {
-			upperBound = messagesLen
-		}
-
-		if err := l.tryPostMessages(ctx, messages[i:upperBound]); err != nil {
-			logrus.WithError(err).WithField("module", "logger/splunk").Warn("Error while sending logs")
-			if messagesLen-i >= l.bufferMaximum || lastChance {
-				// If this is last chance - print them all to the daemon log
-				if lastChance {
-					upperBound = messagesLen
-				}
-				// Not all sent, but buffer has got to its maximum, let's log all messages
-				// we could not send and return buffer minus one batch size
-				for j := i; j < upperBound; j++ {
-					if jsonEvent, err := json.Marshal(messages[j]); err != nil {
-						logrus.Error(err)
-					} else {
-						logrus.Error(fmt.Errorf("Failed to send a message '%s'", string(jsonEvent)))
-					}
-				}
-				return messages[upperBound:messagesLen]
-			}
-			// Not all sent, returning buffer from where we have not sent messages
-			return messages[i:messagesLen]
-		}
-	}
-	// All sent, return empty buffer
-	return messages[:0]
-}
-
-func (l *splunkLogger) tryPostMessages(ctx context.Context, messages []*splunkMessage) error {
-	if len(messages) == 0 {
-		return nil
-	}
-	var buffer bytes.Buffer
-	var writer io.Writer
-	var gzipWriter *gzip.Writer
-	var err error
-	// If gzip compression is enabled - create gzip writer with specified compression
-	// level. If gzip compression is disabled, use standard buffer as a writer
-	if l.gzipCompression {
-		gzipWriter, err = gzip.NewWriterLevel(&buffer, l.gzipCompressionLevel)
-		if err != nil {
-			return err
-		}
-		writer = gzipWriter
-	} else {
-		writer = &buffer
-	}
-	for _, message := range messages {
-		jsonEvent, err := json.Marshal(message)
-		if err != nil {
-			return err
-		}
-		if _, err := writer.Write(jsonEvent); err != nil {
-			return err
-		}
-	}
-	// If gzip compression is enabled, tell it, that we are done
-	if l.gzipCompression {
-		err = gzipWriter.Close()
-		if err != nil {
-			return err
-		}
-	}
-	req, err := http.NewRequest("POST", l.url, bytes.NewBuffer(buffer.Bytes()))
-	if err != nil {
-		return err
-	}
-	req = req.WithContext(ctx)
-	req.Header.Set("Authorization", l.auth)
-	// Tell if we are sending gzip compressed body
-	if l.gzipCompression {
-		req.Header.Set("Content-Encoding", "gzip")
-	}
-	resp, err := l.client.Do(req)
-	if err != nil {
-		return err
-	}
-	defer func() {
-		pools.Copy(ioutil.Discard, resp.Body)
-		resp.Body.Close()
-	}()
-	if resp.StatusCode != http.StatusOK {
-		rdr := io.LimitReader(resp.Body, maxResponseSize)
-		body, err := ioutil.ReadAll(rdr)
-		if err != nil {
-			return err
-		}
-		return fmt.Errorf("%s: failed to send event - %s - %s", driverName, resp.Status, string(body))
-	}
-	return nil
-}
-
-func (l *splunkLogger) Close() error {
-	l.lock.Lock()
-	defer l.lock.Unlock()
-	if l.closedCond == nil {
-		l.closedCond = sync.NewCond(&l.lock)
-		close(l.stream)
-		for !l.closed {
-			l.closedCond.Wait()
-		}
-	}
-	return nil
-}
-
-func (l *splunkLogger) Name() string {
-	return driverName
-}
-
-func (l *splunkLogger) createSplunkMessage(msg *logger.Message) *splunkMessage {
-	message := *l.nullMessage
-	message.Time = fmt.Sprintf("%f", float64(msg.Timestamp.UnixNano())/float64(time.Second))
-	return &message
-}
-
-// ValidateLogOpt looks for all supported by splunk driver options
-func ValidateLogOpt(cfg map[string]string) error {
-	for key := range cfg {
-		switch key {
-		case splunkURLKey:
-		case splunkTokenKey:
-		case splunkSourceKey:
-		case splunkSourceTypeKey:
-		case splunkIndexKey:
-		case splunkCAPathKey:
-		case splunkCANameKey:
-		case splunkInsecureSkipVerifyKey:
-		case splunkFormatKey:
-		case splunkVerifyConnectionKey:
-		case splunkGzipCompressionKey:
-		case splunkGzipCompressionLevelKey:
-		case envKey:
-		case envRegexKey:
-		case labelsKey:
-		case tagKey:
-		default:
-			return fmt.Errorf("unknown log opt '%s' for %s log driver", key, driverName)
-		}
-	}
-	return nil
-}
-
-func parseURL(info logger.Info) (*url.URL, error) {
-	splunkURLStr, ok := info.Config[splunkURLKey]
-	if !ok {
-		return nil, fmt.Errorf("%s: %s is expected", driverName, splunkURLKey)
-	}
-
-	splunkURL, err := url.Parse(splunkURLStr)
-	if err != nil {
-		return nil, fmt.Errorf("%s: failed to parse %s as url value in %s", driverName, splunkURLStr, splunkURLKey)
-	}
-
-	if !urlutil.IsURL(splunkURLStr) ||
-		!splunkURL.IsAbs() ||
-		(splunkURL.Path != "" && splunkURL.Path != "/") ||
-		splunkURL.RawQuery != "" ||
-		splunkURL.Fragment != "" {
-		return nil, fmt.Errorf("%s: expected format scheme://dns_name_or_ip:port for %s", driverName, splunkURLKey)
-	}
-
-	splunkURL.Path = "/services/collector/event/1.0"
-
-	return splunkURL, nil
-}
-
-func verifySplunkConnection(l *splunkLogger) error {
-	req, err := http.NewRequest(http.MethodOptions, l.url, nil)
-	if err != nil {
-		return err
-	}
-	resp, err := l.client.Do(req)
-	if err != nil {
-		return err
-	}
-	defer func() {
-		pools.Copy(ioutil.Discard, resp.Body)
-		resp.Body.Close()
-	}()
-
-	if resp.StatusCode != http.StatusOK {
-		rdr := io.LimitReader(resp.Body, maxResponseSize)
-		body, err := ioutil.ReadAll(rdr)
-		if err != nil {
-			return err
-		}
-		return fmt.Errorf("%s: failed to verify connection - %s - %s", driverName, resp.Status, string(body))
-	}
-	return nil
-}
-
-func getAdvancedOptionDuration(envName string, defaultValue time.Duration) time.Duration {
-	valueStr := os.Getenv(envName)
-	if valueStr == "" {
-		return defaultValue
-	}
-	parsedValue, err := time.ParseDuration(valueStr)
-	if err != nil {
-		logrus.Error(fmt.Sprintf("Failed to parse value of %s as duration. Using default %v. %v", envName, defaultValue, err))
-		return defaultValue
-	}
-	return parsedValue
-}
-
-func getAdvancedOptionInt(envName string, defaultValue int) int {
-	valueStr := os.Getenv(envName)
-	if valueStr == "" {
-		return defaultValue
-	}
-	parsedValue, err := strconv.ParseInt(valueStr, 10, 32)
-	if err != nil {
-		logrus.Error(fmt.Sprintf("Failed to parse value of %s as integer. Using default %d. %v", envName, defaultValue, err))
-		return defaultValue
-	}
-	return int(parsedValue)
-}
diff --git a/components/engine/daemon/logger/splunk/splunk_test.go b/components/engine/daemon/logger/splunk/splunk_test.go
deleted file mode 100644
index db1e905..0000000
--- a/components/engine/daemon/logger/splunk/splunk_test.go
+++ /dev/null
@@ -1,1394 +0,0 @@
-package splunk // import "github.com/docker/docker/daemon/logger/splunk"
-
-import (
-	"compress/gzip"
-	"context"
-	"fmt"
-	"net/http"
-	"os"
-	"runtime"
-	"testing"
-	"time"
-
-	"github.com/docker/docker/daemon/logger"
-	"gotest.tools/assert"
-	"gotest.tools/env"
-)
-
-// Validate options
-func TestValidateLogOpt(t *testing.T) {
-	err := ValidateLogOpt(map[string]string{
-		splunkURLKey:                  "http://127.0.0.1",
-		splunkTokenKey:                "2160C7EF-2CE9-4307-A180-F852B99CF417",
-		splunkSourceKey:               "mysource",
-		splunkSourceTypeKey:           "mysourcetype",
-		splunkIndexKey:                "myindex",
-		splunkCAPathKey:               "/usr/cert.pem",
-		splunkCANameKey:               "ca_name",
-		splunkInsecureSkipVerifyKey:   "true",
-		splunkFormatKey:               "json",
-		splunkVerifyConnectionKey:     "true",
-		splunkGzipCompressionKey:      "true",
-		splunkGzipCompressionLevelKey: "1",
-		envKey:                        "a",
-		envRegexKey:                   "^foo",
-		labelsKey:                     "b",
-		tagKey:                        "c",
-	})
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	err = ValidateLogOpt(map[string]string{
-		"not-supported-option": "a",
-	})
-	if err == nil {
-		t.Fatal("Expecting error on unsupported options")
-	}
-}
-
-// Driver require user to specify required options
-func TestNewMissedConfig(t *testing.T) {
-	info := logger.Info{
-		Config: map[string]string{},
-	}
-	_, err := New(info)
-	if err == nil {
-		t.Fatal("Logger driver should fail when no required parameters specified")
-	}
-}
-
-// Driver require user to specify splunk-url
-func TestNewMissedUrl(t *testing.T) {
-	info := logger.Info{
-		Config: map[string]string{
-			splunkTokenKey: "4642492F-D8BD-47F1-A005-0C08AE4657DF",
-		},
-	}
-	_, err := New(info)
-	if err.Error() != "splunk: splunk-url is expected" {
-		t.Fatal("Logger driver should fail when no required parameters specified")
-	}
-}
-
-// Driver require user to specify splunk-token
-func TestNewMissedToken(t *testing.T) {
-	info := logger.Info{
-		Config: map[string]string{
-			splunkURLKey: "http://127.0.0.1:8088",
-		},
-	}
-	_, err := New(info)
-	if err.Error() != "splunk: splunk-token is expected" {
-		t.Fatal("Logger driver should fail when no required parameters specified")
-	}
-}
-
-func TestNewWithProxy(t *testing.T) {
-	proxy := "http://proxy.testing:8888"
-	reset := env.Patch(t, "HTTP_PROXY", proxy)
-	defer reset()
-
-	// must not be localhost
-	splunkURL := "http://example.com:12345"
-	logger, err := New(logger.Info{
-		Config: map[string]string{
-			splunkURLKey:              splunkURL,
-			splunkTokenKey:            "token",
-			splunkVerifyConnectionKey: "false",
-		},
-		ContainerID: "containeriid",
-	})
-	assert.NilError(t, err)
-	splunkLogger := logger.(*splunkLoggerInline)
-
-	proxyFunc := splunkLogger.transport.Proxy
-	assert.Assert(t, proxyFunc != nil)
-
-	req, err := http.NewRequest("GET", splunkURL, nil)
-	assert.NilError(t, err)
-
-	proxyURL, err := proxyFunc(req)
-	assert.NilError(t, err)
-	assert.Assert(t, proxyURL != nil)
-	assert.Equal(t, proxy, proxyURL.String())
-}
-
-// Test default settings
-func TestDefault(t *testing.T) {
-	hec := NewHTTPEventCollectorMock(t)
-
-	go hec.Serve()
-
-	info := logger.Info{
-		Config: map[string]string{
-			splunkURLKey:   hec.URL(),
-			splunkTokenKey: hec.token,
-		},
-		ContainerID:        "containeriid",
-		ContainerName:      "container_name",
-		ContainerImageID:   "contaimageid",
-		ContainerImageName: "container_image_name",
-	}
-
-	hostname, err := info.Hostname()
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	loggerDriver, err := New(info)
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	if loggerDriver.Name() != driverName {
-		t.Fatal("Unexpected logger driver name")
-	}
-
-	if !hec.connectionVerified {
-		t.Fatal("By default connection should be verified")
-	}
-
-	splunkLoggerDriver, ok := loggerDriver.(*splunkLoggerInline)
-	if !ok {
-		t.Fatal("Unexpected Splunk Logging Driver type")
-	}
-
-	if splunkLoggerDriver.url != hec.URL()+"/services/collector/event/1.0" ||
-		splunkLoggerDriver.auth != "Splunk "+hec.token ||
-		splunkLoggerDriver.nullMessage.Host != hostname ||
-		splunkLoggerDriver.nullMessage.Source != "" ||
-		splunkLoggerDriver.nullMessage.SourceType != "" ||
-		splunkLoggerDriver.nullMessage.Index != "" ||
-		splunkLoggerDriver.gzipCompression ||
-		splunkLoggerDriver.postMessagesFrequency != defaultPostMessagesFrequency ||
-		splunkLoggerDriver.postMessagesBatchSize != defaultPostMessagesBatchSize ||
-		splunkLoggerDriver.bufferMaximum != defaultBufferMaximum ||
-		cap(splunkLoggerDriver.stream) != defaultStreamChannelSize {
-		t.Fatal("Found not default values setup in Splunk Logging Driver.")
-	}
-
-	message1Time := time.Now()
-	if err := loggerDriver.Log(&logger.Message{Line: []byte("{\"a\":\"b\"}"), Source: "stdout", Timestamp: message1Time}); err != nil {
-		t.Fatal(err)
-	}
-	message2Time := time.Now()
-	if err := loggerDriver.Log(&logger.Message{Line: []byte("notajson"), Source: "stdout", Timestamp: message2Time}); err != nil {
-		t.Fatal(err)
-	}
-
-	err = loggerDriver.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	if len(hec.messages) != 2 {
-		t.Fatal("Expected two messages")
-	}
-
-	if *hec.gzipEnabled {
-		t.Fatal("Gzip should not be used")
-	}
-
-	message1 := hec.messages[0]
-	if message1.Time != fmt.Sprintf("%f", float64(message1Time.UnixNano())/float64(time.Second)) ||
-		message1.Host != hostname ||
-		message1.Source != "" ||
-		message1.SourceType != "" ||
-		message1.Index != "" {
-		t.Fatalf("Unexpected values of message 1 %v", message1)
-	}
-
-	if event, err := message1.EventAsMap(); err != nil {
-		t.Fatal(err)
-	} else {
-		if event["line"] != "{\"a\":\"b\"}" ||
-			event["source"] != "stdout" ||
-			event["tag"] != "containeriid" ||
-			len(event) != 3 {
-			t.Fatalf("Unexpected event in message %v", event)
-		}
-	}
-
-	message2 := hec.messages[1]
-	if message2.Time != fmt.Sprintf("%f", float64(message2Time.UnixNano())/float64(time.Second)) ||
-		message2.Host != hostname ||
-		message2.Source != "" ||
-		message2.SourceType != "" ||
-		message2.Index != "" {
-		t.Fatalf("Unexpected values of message 1 %v", message2)
-	}
-
-	if event, err := message2.EventAsMap(); err != nil {
-		t.Fatal(err)
-	} else {
-		if event["line"] != "notajson" ||
-			event["source"] != "stdout" ||
-			event["tag"] != "containeriid" ||
-			len(event) != 3 {
-			t.Fatalf("Unexpected event in message %v", event)
-		}
-	}
-
-	err = hec.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-}
-
-// Verify inline format with a not default settings for most of options
-func TestInlineFormatWithNonDefaultOptions(t *testing.T) {
-	hec := NewHTTPEventCollectorMock(t)
-
-	go hec.Serve()
-
-	info := logger.Info{
-		Config: map[string]string{
-			splunkURLKey:             hec.URL(),
-			splunkTokenKey:           hec.token,
-			splunkSourceKey:          "mysource",
-			splunkSourceTypeKey:      "mysourcetype",
-			splunkIndexKey:           "myindex",
-			splunkFormatKey:          splunkFormatInline,
-			splunkGzipCompressionKey: "true",
-			tagKey:                   "{{.ImageName}}/{{.Name}}",
-			labelsKey:                "a",
-			envRegexKey:              "^foo",
-		},
-		ContainerID:        "containeriid",
-		ContainerName:      "/container_name",
-		ContainerImageID:   "contaimageid",
-		ContainerImageName: "container_image_name",
-		ContainerLabels: map[string]string{
-			"a": "b",
-		},
-		ContainerEnv: []string{"foo_finder=bar"},
-	}
-
-	hostname, err := info.Hostname()
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	loggerDriver, err := New(info)
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	if !hec.connectionVerified {
-		t.Fatal("By default connection should be verified")
-	}
-
-	splunkLoggerDriver, ok := loggerDriver.(*splunkLoggerInline)
-	if !ok {
-		t.Fatal("Unexpected Splunk Logging Driver type")
-	}
-
-	if splunkLoggerDriver.url != hec.URL()+"/services/collector/event/1.0" ||
-		splunkLoggerDriver.auth != "Splunk "+hec.token ||
-		splunkLoggerDriver.nullMessage.Host != hostname ||
-		splunkLoggerDriver.nullMessage.Source != "mysource" ||
-		splunkLoggerDriver.nullMessage.SourceType != "mysourcetype" ||
-		splunkLoggerDriver.nullMessage.Index != "myindex" ||
-		!splunkLoggerDriver.gzipCompression ||
-		splunkLoggerDriver.gzipCompressionLevel != gzip.DefaultCompression ||
-		splunkLoggerDriver.postMessagesFrequency != defaultPostMessagesFrequency ||
-		splunkLoggerDriver.postMessagesBatchSize != defaultPostMessagesBatchSize ||
-		splunkLoggerDriver.bufferMaximum != defaultBufferMaximum ||
-		cap(splunkLoggerDriver.stream) != defaultStreamChannelSize {
-		t.Fatal("Values do not match configuration.")
-	}
-
-	messageTime := time.Now()
-	if err := loggerDriver.Log(&logger.Message{Line: []byte("1"), Source: "stdout", Timestamp: messageTime}); err != nil {
-		t.Fatal(err)
-	}
-
-	err = loggerDriver.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	if len(hec.messages) != 1 {
-		t.Fatal("Expected one message")
-	}
-
-	if !*hec.gzipEnabled {
-		t.Fatal("Gzip should be used")
-	}
-
-	message := hec.messages[0]
-	if message.Time != fmt.Sprintf("%f", float64(messageTime.UnixNano())/float64(time.Second)) ||
-		message.Host != hostname ||
-		message.Source != "mysource" ||
-		message.SourceType != "mysourcetype" ||
-		message.Index != "myindex" {
-		t.Fatalf("Unexpected values of message %v", message)
-	}
-
-	if event, err := message.EventAsMap(); err != nil {
-		t.Fatal(err)
-	} else {
-		if event["line"] != "1" ||
-			event["source"] != "stdout" ||
-			event["tag"] != "container_image_name/container_name" ||
-			event["attrs"].(map[string]interface{})["a"] != "b" ||
-			event["attrs"].(map[string]interface{})["foo_finder"] != "bar" ||
-			len(event) != 4 {
-			t.Fatalf("Unexpected event in message %v", event)
-		}
-	}
-
-	err = hec.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-}
-
-// Verify JSON format
-func TestJsonFormat(t *testing.T) {
-	hec := NewHTTPEventCollectorMock(t)
-
-	go hec.Serve()
-
-	info := logger.Info{
-		Config: map[string]string{
-			splunkURLKey:                  hec.URL(),
-			splunkTokenKey:                hec.token,
-			splunkFormatKey:               splunkFormatJSON,
-			splunkGzipCompressionKey:      "true",
-			splunkGzipCompressionLevelKey: "1",
-		},
-		ContainerID:        "containeriid",
-		ContainerName:      "/container_name",
-		ContainerImageID:   "contaimageid",
-		ContainerImageName: "container_image_name",
-	}
-
-	hostname, err := info.Hostname()
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	loggerDriver, err := New(info)
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	if !hec.connectionVerified {
-		t.Fatal("By default connection should be verified")
-	}
-
-	splunkLoggerDriver, ok := loggerDriver.(*splunkLoggerJSON)
-	if !ok {
-		t.Fatal("Unexpected Splunk Logging Driver type")
-	}
-
-	if splunkLoggerDriver.url != hec.URL()+"/services/collector/event/1.0" ||
-		splunkLoggerDriver.auth != "Splunk "+hec.token ||
-		splunkLoggerDriver.nullMessage.Host != hostname ||
-		splunkLoggerDriver.nullMessage.Source != "" ||
-		splunkLoggerDriver.nullMessage.SourceType != "" ||
-		splunkLoggerDriver.nullMessage.Index != "" ||
-		!splunkLoggerDriver.gzipCompression ||
-		splunkLoggerDriver.gzipCompressionLevel != gzip.BestSpeed ||
-		splunkLoggerDriver.postMessagesFrequency != defaultPostMessagesFrequency ||
-		splunkLoggerDriver.postMessagesBatchSize != defaultPostMessagesBatchSize ||
-		splunkLoggerDriver.bufferMaximum != defaultBufferMaximum ||
-		cap(splunkLoggerDriver.stream) != defaultStreamChannelSize {
-		t.Fatal("Values do not match configuration.")
-	}
-
-	message1Time := time.Now()
-	if err := loggerDriver.Log(&logger.Message{Line: []byte("{\"a\":\"b\"}"), Source: "stdout", Timestamp: message1Time}); err != nil {
-		t.Fatal(err)
-	}
-	message2Time := time.Now()
-	if err := loggerDriver.Log(&logger.Message{Line: []byte("notjson"), Source: "stdout", Timestamp: message2Time}); err != nil {
-		t.Fatal(err)
-	}
-
-	err = loggerDriver.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	if len(hec.messages) != 2 {
-		t.Fatal("Expected two messages")
-	}
-
-	message1 := hec.messages[0]
-	if message1.Time != fmt.Sprintf("%f", float64(message1Time.UnixNano())/float64(time.Second)) ||
-		message1.Host != hostname ||
-		message1.Source != "" ||
-		message1.SourceType != "" ||
-		message1.Index != "" {
-		t.Fatalf("Unexpected values of message 1 %v", message1)
-	}
-
-	if event, err := message1.EventAsMap(); err != nil {
-		t.Fatal(err)
-	} else {
-		if event["line"].(map[string]interface{})["a"] != "b" ||
-			event["source"] != "stdout" ||
-			event["tag"] != "containeriid" ||
-			len(event) != 3 {
-			t.Fatalf("Unexpected event in message 1 %v", event)
-		}
-	}
-
-	message2 := hec.messages[1]
-	if message2.Time != fmt.Sprintf("%f", float64(message2Time.UnixNano())/float64(time.Second)) ||
-		message2.Host != hostname ||
-		message2.Source != "" ||
-		message2.SourceType != "" ||
-		message2.Index != "" {
-		t.Fatalf("Unexpected values of message 2 %v", message2)
-	}
-
-	// If message cannot be parsed as JSON - it should be sent as a line
-	if event, err := message2.EventAsMap(); err != nil {
-		t.Fatal(err)
-	} else {
-		if event["line"] != "notjson" ||
-			event["source"] != "stdout" ||
-			event["tag"] != "containeriid" ||
-			len(event) != 3 {
-			t.Fatalf("Unexpected event in message 2 %v", event)
-		}
-	}
-
-	err = hec.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-}
-
-// Verify raw format
-func TestRawFormat(t *testing.T) {
-	hec := NewHTTPEventCollectorMock(t)
-
-	go hec.Serve()
-
-	info := logger.Info{
-		Config: map[string]string{
-			splunkURLKey:    hec.URL(),
-			splunkTokenKey:  hec.token,
-			splunkFormatKey: splunkFormatRaw,
-		},
-		ContainerID:        "containeriid",
-		ContainerName:      "/container_name",
-		ContainerImageID:   "contaimageid",
-		ContainerImageName: "container_image_name",
-	}
-
-	hostname, err := info.Hostname()
-	assert.NilError(t, err)
-
-	loggerDriver, err := New(info)
-	assert.NilError(t, err)
-
-	if !hec.connectionVerified {
-		t.Fatal("By default connection should be verified")
-	}
-
-	splunkLoggerDriver, ok := loggerDriver.(*splunkLoggerRaw)
-	if !ok {
-		t.Fatal("Unexpected Splunk Logging Driver type")
-	}
-
-	if splunkLoggerDriver.url != hec.URL()+"/services/collector/event/1.0" ||
-		splunkLoggerDriver.auth != "Splunk "+hec.token ||
-		splunkLoggerDriver.nullMessage.Host != hostname ||
-		splunkLoggerDriver.nullMessage.Source != "" ||
-		splunkLoggerDriver.nullMessage.SourceType != "" ||
-		splunkLoggerDriver.nullMessage.Index != "" ||
-		splunkLoggerDriver.gzipCompression ||
-		splunkLoggerDriver.postMessagesFrequency != defaultPostMessagesFrequency ||
-		splunkLoggerDriver.postMessagesBatchSize != defaultPostMessagesBatchSize ||
-		splunkLoggerDriver.bufferMaximum != defaultBufferMaximum ||
-		cap(splunkLoggerDriver.stream) != defaultStreamChannelSize ||
-		string(splunkLoggerDriver.prefix) != "containeriid " {
-		t.Fatal("Values do not match configuration.")
-	}
-
-	message1Time := time.Now()
-	if err := loggerDriver.Log(&logger.Message{Line: []byte("{\"a\":\"b\"}"), Source: "stdout", Timestamp: message1Time}); err != nil {
-		t.Fatal(err)
-	}
-	message2Time := time.Now()
-	if err := loggerDriver.Log(&logger.Message{Line: []byte("notjson"), Source: "stdout", Timestamp: message2Time}); err != nil {
-		t.Fatal(err)
-	}
-
-	err = loggerDriver.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	if len(hec.messages) != 2 {
-		t.Fatal("Expected two messages")
-	}
-
-	message1 := hec.messages[0]
-	if message1.Time != fmt.Sprintf("%f", float64(message1Time.UnixNano())/float64(time.Second)) ||
-		message1.Host != hostname ||
-		message1.Source != "" ||
-		message1.SourceType != "" ||
-		message1.Index != "" {
-		t.Fatalf("Unexpected values of message 1 %v", message1)
-	}
-
-	if event, err := message1.EventAsString(); err != nil {
-		t.Fatal(err)
-	} else {
-		if event != "containeriid {\"a\":\"b\"}" {
-			t.Fatalf("Unexpected event in message 1 %v", event)
-		}
-	}
-
-	message2 := hec.messages[1]
-	if message2.Time != fmt.Sprintf("%f", float64(message2Time.UnixNano())/float64(time.Second)) ||
-		message2.Host != hostname ||
-		message2.Source != "" ||
-		message2.SourceType != "" ||
-		message2.Index != "" {
-		t.Fatalf("Unexpected values of message 2 %v", message2)
-	}
-
-	if event, err := message2.EventAsString(); err != nil {
-		t.Fatal(err)
-	} else {
-		if event != "containeriid notjson" {
-			t.Fatalf("Unexpected event in message 1 %v", event)
-		}
-	}
-
-	err = hec.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-}
-
-// Verify raw format with labels
-func TestRawFormatWithLabels(t *testing.T) {
-	hec := NewHTTPEventCollectorMock(t)
-
-	go hec.Serve()
-
-	info := logger.Info{
-		Config: map[string]string{
-			splunkURLKey:    hec.URL(),
-			splunkTokenKey:  hec.token,
-			splunkFormatKey: splunkFormatRaw,
-			labelsKey:       "a",
-		},
-		ContainerID:        "containeriid",
-		ContainerName:      "/container_name",
-		ContainerImageID:   "contaimageid",
-		ContainerImageName: "container_image_name",
-		ContainerLabels: map[string]string{
-			"a": "b",
-		},
-	}
-
-	hostname, err := info.Hostname()
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	loggerDriver, err := New(info)
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	if !hec.connectionVerified {
-		t.Fatal("By default connection should be verified")
-	}
-
-	splunkLoggerDriver, ok := loggerDriver.(*splunkLoggerRaw)
-	if !ok {
-		t.Fatal("Unexpected Splunk Logging Driver type")
-	}
-
-	if splunkLoggerDriver.url != hec.URL()+"/services/collector/event/1.0" ||
-		splunkLoggerDriver.auth != "Splunk "+hec.token ||
-		splunkLoggerDriver.nullMessage.Host != hostname ||
-		splunkLoggerDriver.nullMessage.Source != "" ||
-		splunkLoggerDriver.nullMessage.SourceType != "" ||
-		splunkLoggerDriver.nullMessage.Index != "" ||
-		splunkLoggerDriver.gzipCompression ||
-		splunkLoggerDriver.postMessagesFrequency != defaultPostMessagesFrequency ||
-		splunkLoggerDriver.postMessagesBatchSize != defaultPostMessagesBatchSize ||
-		splunkLoggerDriver.bufferMaximum != defaultBufferMaximum ||
-		cap(splunkLoggerDriver.stream) != defaultStreamChannelSize ||
-		string(splunkLoggerDriver.prefix) != "containeriid a=b " {
-		t.Fatal("Values do not match configuration.")
-	}
-
-	message1Time := time.Now()
-	if err := loggerDriver.Log(&logger.Message{Line: []byte("{\"a\":\"b\"}"), Source: "stdout", Timestamp: message1Time}); err != nil {
-		t.Fatal(err)
-	}
-	message2Time := time.Now()
-	if err := loggerDriver.Log(&logger.Message{Line: []byte("notjson"), Source: "stdout", Timestamp: message2Time}); err != nil {
-		t.Fatal(err)
-	}
-
-	err = loggerDriver.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	if len(hec.messages) != 2 {
-		t.Fatal("Expected two messages")
-	}
-
-	message1 := hec.messages[0]
-	if message1.Time != fmt.Sprintf("%f", float64(message1Time.UnixNano())/float64(time.Second)) ||
-		message1.Host != hostname ||
-		message1.Source != "" ||
-		message1.SourceType != "" ||
-		message1.Index != "" {
-		t.Fatalf("Unexpected values of message 1 %v", message1)
-	}
-
-	if event, err := message1.EventAsString(); err != nil {
-		t.Fatal(err)
-	} else {
-		if event != "containeriid a=b {\"a\":\"b\"}" {
-			t.Fatalf("Unexpected event in message 1 %v", event)
-		}
-	}
-
-	message2 := hec.messages[1]
-	if message2.Time != fmt.Sprintf("%f", float64(message2Time.UnixNano())/float64(time.Second)) ||
-		message2.Host != hostname ||
-		message2.Source != "" ||
-		message2.SourceType != "" ||
-		message2.Index != "" {
-		t.Fatalf("Unexpected values of message 2 %v", message2)
-	}
-
-	if event, err := message2.EventAsString(); err != nil {
-		t.Fatal(err)
-	} else {
-		if event != "containeriid a=b notjson" {
-			t.Fatalf("Unexpected event in message 2 %v", event)
-		}
-	}
-
-	err = hec.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-}
-
-// Verify that Splunk Logging Driver can accept tag="" which will allow to send raw messages
-// in the same way we get them in stdout/stderr
-func TestRawFormatWithoutTag(t *testing.T) {
-	hec := NewHTTPEventCollectorMock(t)
-
-	go hec.Serve()
-
-	info := logger.Info{
-		Config: map[string]string{
-			splunkURLKey:    hec.URL(),
-			splunkTokenKey:  hec.token,
-			splunkFormatKey: splunkFormatRaw,
-			tagKey:          "",
-		},
-		ContainerID:        "containeriid",
-		ContainerName:      "/container_name",
-		ContainerImageID:   "contaimageid",
-		ContainerImageName: "container_image_name",
-	}
-
-	hostname, err := info.Hostname()
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	loggerDriver, err := New(info)
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	if !hec.connectionVerified {
-		t.Fatal("By default connection should be verified")
-	}
-
-	splunkLoggerDriver, ok := loggerDriver.(*splunkLoggerRaw)
-	if !ok {
-		t.Fatal("Unexpected Splunk Logging Driver type")
-	}
-
-	if splunkLoggerDriver.url != hec.URL()+"/services/collector/event/1.0" ||
-		splunkLoggerDriver.auth != "Splunk "+hec.token ||
-		splunkLoggerDriver.nullMessage.Host != hostname ||
-		splunkLoggerDriver.nullMessage.Source != "" ||
-		splunkLoggerDriver.nullMessage.SourceType != "" ||
-		splunkLoggerDriver.nullMessage.Index != "" ||
-		splunkLoggerDriver.gzipCompression ||
-		splunkLoggerDriver.postMessagesFrequency != defaultPostMessagesFrequency ||
-		splunkLoggerDriver.postMessagesBatchSize != defaultPostMessagesBatchSize ||
-		splunkLoggerDriver.bufferMaximum != defaultBufferMaximum ||
-		cap(splunkLoggerDriver.stream) != defaultStreamChannelSize ||
-		string(splunkLoggerDriver.prefix) != "" {
-		t.Log(string(splunkLoggerDriver.prefix) + "a")
-		t.Fatal("Values do not match configuration.")
-	}
-
-	message1Time := time.Now()
-	if err := loggerDriver.Log(&logger.Message{Line: []byte("{\"a\":\"b\"}"), Source: "stdout", Timestamp: message1Time}); err != nil {
-		t.Fatal(err)
-	}
-	message2Time := time.Now()
-	if err := loggerDriver.Log(&logger.Message{Line: []byte("notjson"), Source: "stdout", Timestamp: message2Time}); err != nil {
-		t.Fatal(err)
-	}
-	message3Time := time.Now()
-	if err := loggerDriver.Log(&logger.Message{Line: []byte(" "), Source: "stdout", Timestamp: message3Time}); err != nil {
-		t.Fatal(err)
-	}
-
-	err = loggerDriver.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	// message3 would have an empty or whitespace only string in the "event" field
-	// both of which are not acceptable to HEC
-	// thus here we must expect 2 messages, not 3
-	if len(hec.messages) != 2 {
-		t.Fatal("Expected two messages")
-	}
-
-	message1 := hec.messages[0]
-	if message1.Time != fmt.Sprintf("%f", float64(message1Time.UnixNano())/float64(time.Second)) ||
-		message1.Host != hostname ||
-		message1.Source != "" ||
-		message1.SourceType != "" ||
-		message1.Index != "" {
-		t.Fatalf("Unexpected values of message 1 %v", message1)
-	}
-
-	if event, err := message1.EventAsString(); err != nil {
-		t.Fatal(err)
-	} else {
-		if event != "{\"a\":\"b\"}" {
-			t.Fatalf("Unexpected event in message 1 %v", event)
-		}
-	}
-
-	message2 := hec.messages[1]
-	if message2.Time != fmt.Sprintf("%f", float64(message2Time.UnixNano())/float64(time.Second)) ||
-		message2.Host != hostname ||
-		message2.Source != "" ||
-		message2.SourceType != "" ||
-		message2.Index != "" {
-		t.Fatalf("Unexpected values of message 2 %v", message2)
-	}
-
-	if event, err := message2.EventAsString(); err != nil {
-		t.Fatal(err)
-	} else {
-		if event != "notjson" {
-			t.Fatalf("Unexpected event in message 2 %v", event)
-		}
-	}
-
-	err = hec.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-}
-
-// Verify that we will send messages in batches with default batching parameters,
-// but change frequency to be sure that numOfRequests will match expected 17 requests
-func TestBatching(t *testing.T) {
-	if err := os.Setenv(envVarPostMessagesFrequency, "10h"); err != nil {
-		t.Fatal(err)
-	}
-
-	hec := NewHTTPEventCollectorMock(t)
-
-	go hec.Serve()
-
-	info := logger.Info{
-		Config: map[string]string{
-			splunkURLKey:   hec.URL(),
-			splunkTokenKey: hec.token,
-		},
-		ContainerID:        "containeriid",
-		ContainerName:      "/container_name",
-		ContainerImageID:   "contaimageid",
-		ContainerImageName: "container_image_name",
-	}
-
-	loggerDriver, err := New(info)
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	for i := 0; i < defaultStreamChannelSize*4; i++ {
-		if err := loggerDriver.Log(&logger.Message{Line: []byte(fmt.Sprintf("%d", i)), Source: "stdout", Timestamp: time.Now()}); err != nil {
-			t.Fatal(err)
-		}
-	}
-
-	err = loggerDriver.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	if len(hec.messages) != defaultStreamChannelSize*4 {
-		t.Fatal("Not all messages delivered")
-	}
-
-	for i, message := range hec.messages {
-		if event, err := message.EventAsMap(); err != nil {
-			t.Fatal(err)
-		} else {
-			if event["line"] != fmt.Sprintf("%d", i) {
-				t.Fatalf("Unexpected event in message %v", event)
-			}
-		}
-	}
-
-	// 1 to verify connection and 16 batches
-	if hec.numOfRequests != 17 {
-		t.Fatalf("Unexpected number of requests %d", hec.numOfRequests)
-	}
-
-	err = hec.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	if err := os.Setenv(envVarPostMessagesFrequency, ""); err != nil {
-		t.Fatal(err)
-	}
-}
-
-// Verify that test is using time to fire events not rare than specified frequency
-func TestFrequency(t *testing.T) {
-	if err := os.Setenv(envVarPostMessagesFrequency, "5ms"); err != nil {
-		t.Fatal(err)
-	}
-
-	hec := NewHTTPEventCollectorMock(t)
-
-	go hec.Serve()
-
-	info := logger.Info{
-		Config: map[string]string{
-			splunkURLKey:   hec.URL(),
-			splunkTokenKey: hec.token,
-		},
-		ContainerID:        "containeriid",
-		ContainerName:      "/container_name",
-		ContainerImageID:   "contaimageid",
-		ContainerImageName: "container_image_name",
-	}
-
-	loggerDriver, err := New(info)
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	for i := 0; i < 10; i++ {
-		if err := loggerDriver.Log(&logger.Message{Line: []byte(fmt.Sprintf("%d", i)), Source: "stdout", Timestamp: time.Now()}); err != nil {
-			t.Fatal(err)
-		}
-		time.Sleep(15 * time.Millisecond)
-	}
-
-	err = loggerDriver.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	if len(hec.messages) != 10 {
-		t.Fatal("Not all messages delivered")
-	}
-
-	for i, message := range hec.messages {
-		if event, err := message.EventAsMap(); err != nil {
-			t.Fatal(err)
-		} else {
-			if event["line"] != fmt.Sprintf("%d", i) {
-				t.Fatalf("Unexpected event in message %v", event)
-			}
-		}
-	}
-
-	// 1 to verify connection and 10 to verify that we have sent messages with required frequency,
-	// but because frequency is too small (to keep test quick), instead of 11, use 9 if context switches will be slow
-	expectedRequests := 9
-	if runtime.GOOS == "windows" {
-		// sometimes in Windows, this test fails with number of requests showing 8. So be more conservative.
-		expectedRequests = 7
-	}
-	if hec.numOfRequests < expectedRequests {
-		t.Fatalf("Unexpected number of requests %d", hec.numOfRequests)
-	}
-
-	err = hec.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	if err := os.Setenv(envVarPostMessagesFrequency, ""); err != nil {
-		t.Fatal(err)
-	}
-}
-
-// Simulate behavior similar to first version of Splunk Logging Driver, when we were sending one message
-// per request
-func TestOneMessagePerRequest(t *testing.T) {
-	if err := os.Setenv(envVarPostMessagesFrequency, "10h"); err != nil {
-		t.Fatal(err)
-	}
-
-	if err := os.Setenv(envVarPostMessagesBatchSize, "1"); err != nil {
-		t.Fatal(err)
-	}
-
-	if err := os.Setenv(envVarBufferMaximum, "1"); err != nil {
-		t.Fatal(err)
-	}
-
-	if err := os.Setenv(envVarStreamChannelSize, "0"); err != nil {
-		t.Fatal(err)
-	}
-
-	hec := NewHTTPEventCollectorMock(t)
-
-	go hec.Serve()
-
-	info := logger.Info{
-		Config: map[string]string{
-			splunkURLKey:   hec.URL(),
-			splunkTokenKey: hec.token,
-		},
-		ContainerID:        "containeriid",
-		ContainerName:      "/container_name",
-		ContainerImageID:   "contaimageid",
-		ContainerImageName: "container_image_name",
-	}
-
-	loggerDriver, err := New(info)
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	for i := 0; i < 10; i++ {
-		if err := loggerDriver.Log(&logger.Message{Line: []byte(fmt.Sprintf("%d", i)), Source: "stdout", Timestamp: time.Now()}); err != nil {
-			t.Fatal(err)
-		}
-	}
-
-	err = loggerDriver.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	if len(hec.messages) != 10 {
-		t.Fatal("Not all messages delivered")
-	}
-
-	for i, message := range hec.messages {
-		if event, err := message.EventAsMap(); err != nil {
-			t.Fatal(err)
-		} else {
-			if event["line"] != fmt.Sprintf("%d", i) {
-				t.Fatalf("Unexpected event in message %v", event)
-			}
-		}
-	}
-
-	// 1 to verify connection and 10 messages
-	if hec.numOfRequests != 11 {
-		t.Fatalf("Unexpected number of requests %d", hec.numOfRequests)
-	}
-
-	err = hec.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	if err := os.Setenv(envVarPostMessagesFrequency, ""); err != nil {
-		t.Fatal(err)
-	}
-
-	if err := os.Setenv(envVarPostMessagesBatchSize, ""); err != nil {
-		t.Fatal(err)
-	}
-
-	if err := os.Setenv(envVarBufferMaximum, ""); err != nil {
-		t.Fatal(err)
-	}
-
-	if err := os.Setenv(envVarStreamChannelSize, ""); err != nil {
-		t.Fatal(err)
-	}
-}
-
-// Driver should not be created when HEC is unresponsive
-func TestVerify(t *testing.T) {
-	hec := NewHTTPEventCollectorMock(t)
-	hec.simulateServerError = true
-	go hec.Serve()
-
-	info := logger.Info{
-		Config: map[string]string{
-			splunkURLKey:   hec.URL(),
-			splunkTokenKey: hec.token,
-		},
-		ContainerID:        "containeriid",
-		ContainerName:      "/container_name",
-		ContainerImageID:   "contaimageid",
-		ContainerImageName: "container_image_name",
-	}
-
-	_, err := New(info)
-	if err == nil {
-		t.Fatal("Expecting driver to fail, when server is unresponsive")
-	}
-
-	err = hec.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-}
-
-// Verify that user can specify to skip verification that Splunk HEC is working.
-// Also in this test we verify retry logic.
-func TestSkipVerify(t *testing.T) {
-	hec := NewHTTPEventCollectorMock(t)
-	hec.simulateServerError = true
-	go hec.Serve()
-
-	info := logger.Info{
-		Config: map[string]string{
-			splunkURLKey:              hec.URL(),
-			splunkTokenKey:            hec.token,
-			splunkVerifyConnectionKey: "false",
-		},
-		ContainerID:        "containeriid",
-		ContainerName:      "/container_name",
-		ContainerImageID:   "contaimageid",
-		ContainerImageName: "container_image_name",
-	}
-
-	loggerDriver, err := New(info)
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	if hec.connectionVerified {
-		t.Fatal("Connection should not be verified")
-	}
-
-	for i := 0; i < defaultStreamChannelSize*2; i++ {
-		if err := loggerDriver.Log(&logger.Message{Line: []byte(fmt.Sprintf("%d", i)), Source: "stdout", Timestamp: time.Now()}); err != nil {
-			t.Fatal(err)
-		}
-	}
-
-	if len(hec.messages) != 0 {
-		t.Fatal("No messages should be accepted at this point")
-	}
-
-	hec.simulateErr(false)
-
-	for i := defaultStreamChannelSize * 2; i < defaultStreamChannelSize*4; i++ {
-		if err := loggerDriver.Log(&logger.Message{Line: []byte(fmt.Sprintf("%d", i)), Source: "stdout", Timestamp: time.Now()}); err != nil {
-			t.Fatal(err)
-		}
-	}
-
-	err = loggerDriver.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	if len(hec.messages) != defaultStreamChannelSize*4 {
-		t.Fatal("Not all messages delivered")
-	}
-
-	for i, message := range hec.messages {
-		if event, err := message.EventAsMap(); err != nil {
-			t.Fatal(err)
-		} else {
-			if event["line"] != fmt.Sprintf("%d", i) {
-				t.Fatalf("Unexpected event in message %v", event)
-			}
-		}
-	}
-
-	err = hec.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-}
-
-// Verify logic for when we filled whole buffer
-func TestBufferMaximum(t *testing.T) {
-	if err := os.Setenv(envVarPostMessagesBatchSize, "2"); err != nil {
-		t.Fatal(err)
-	}
-
-	if err := os.Setenv(envVarBufferMaximum, "10"); err != nil {
-		t.Fatal(err)
-	}
-
-	if err := os.Setenv(envVarStreamChannelSize, "0"); err != nil {
-		t.Fatal(err)
-	}
-
-	hec := NewHTTPEventCollectorMock(t)
-	hec.simulateErr(true)
-	go hec.Serve()
-
-	info := logger.Info{
-		Config: map[string]string{
-			splunkURLKey:              hec.URL(),
-			splunkTokenKey:            hec.token,
-			splunkVerifyConnectionKey: "false",
-		},
-		ContainerID:        "containeriid",
-		ContainerName:      "/container_name",
-		ContainerImageID:   "contaimageid",
-		ContainerImageName: "container_image_name",
-	}
-
-	loggerDriver, err := New(info)
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	if hec.connectionVerified {
-		t.Fatal("Connection should not be verified")
-	}
-
-	for i := 0; i < 11; i++ {
-		if err := loggerDriver.Log(&logger.Message{Line: []byte(fmt.Sprintf("%d", i)), Source: "stdout", Timestamp: time.Now()}); err != nil {
-			t.Fatal(err)
-		}
-	}
-
-	if len(hec.messages) != 0 {
-		t.Fatal("No messages should be accepted at this point")
-	}
-
-	hec.simulateServerError = false
-
-	err = loggerDriver.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	if len(hec.messages) != 9 {
-		t.Fatalf("Expected # of messages %d, got %d", 9, len(hec.messages))
-	}
-
-	// First 1000 messages are written to daemon log when buffer was full
-	for i, message := range hec.messages {
-		if event, err := message.EventAsMap(); err != nil {
-			t.Fatal(err)
-		} else {
-			if event["line"] != fmt.Sprintf("%d", i+2) {
-				t.Fatalf("Unexpected event in message %v", event)
-			}
-		}
-	}
-
-	err = hec.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	if err := os.Setenv(envVarPostMessagesBatchSize, ""); err != nil {
-		t.Fatal(err)
-	}
-
-	if err := os.Setenv(envVarBufferMaximum, ""); err != nil {
-		t.Fatal(err)
-	}
-
-	if err := os.Setenv(envVarStreamChannelSize, ""); err != nil {
-		t.Fatal(err)
-	}
-}
-
-// Verify that we are not blocking close when HEC is down for the whole time
-func TestServerAlwaysDown(t *testing.T) {
-	if err := os.Setenv(envVarPostMessagesBatchSize, "2"); err != nil {
-		t.Fatal(err)
-	}
-
-	if err := os.Setenv(envVarBufferMaximum, "4"); err != nil {
-		t.Fatal(err)
-	}
-
-	if err := os.Setenv(envVarStreamChannelSize, "0"); err != nil {
-		t.Fatal(err)
-	}
-
-	hec := NewHTTPEventCollectorMock(t)
-	hec.simulateServerError = true
-	go hec.Serve()
-
-	info := logger.Info{
-		Config: map[string]string{
-			splunkURLKey:              hec.URL(),
-			splunkTokenKey:            hec.token,
-			splunkVerifyConnectionKey: "false",
-		},
-		ContainerID:        "containeriid",
-		ContainerName:      "/container_name",
-		ContainerImageID:   "contaimageid",
-		ContainerImageName: "container_image_name",
-	}
-
-	loggerDriver, err := New(info)
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	if hec.connectionVerified {
-		t.Fatal("Connection should not be verified")
-	}
-
-	for i := 0; i < 5; i++ {
-		if err := loggerDriver.Log(&logger.Message{Line: []byte(fmt.Sprintf("%d", i)), Source: "stdout", Timestamp: time.Now()}); err != nil {
-			t.Fatal(err)
-		}
-	}
-
-	err = loggerDriver.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	if len(hec.messages) != 0 {
-		t.Fatal("No messages should be sent")
-	}
-
-	err = hec.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	if err := os.Setenv(envVarPostMessagesBatchSize, ""); err != nil {
-		t.Fatal(err)
-	}
-
-	if err := os.Setenv(envVarBufferMaximum, ""); err != nil {
-		t.Fatal(err)
-	}
-
-	if err := os.Setenv(envVarStreamChannelSize, ""); err != nil {
-		t.Fatal(err)
-	}
-}
-
-// Cannot send messages after we close driver
-func TestCannotSendAfterClose(t *testing.T) {
-	hec := NewHTTPEventCollectorMock(t)
-	go hec.Serve()
-
-	info := logger.Info{
-		Config: map[string]string{
-			splunkURLKey:   hec.URL(),
-			splunkTokenKey: hec.token,
-		},
-		ContainerID:        "containeriid",
-		ContainerName:      "/container_name",
-		ContainerImageID:   "contaimageid",
-		ContainerImageName: "container_image_name",
-	}
-
-	loggerDriver, err := New(info)
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	if err := loggerDriver.Log(&logger.Message{Line: []byte("message1"), Source: "stdout", Timestamp: time.Now()}); err != nil {
-		t.Fatal(err)
-	}
-
-	err = loggerDriver.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	if err := loggerDriver.Log(&logger.Message{Line: []byte("message2"), Source: "stdout", Timestamp: time.Now()}); err == nil {
-		t.Fatal("Driver should not allow to send messages after close")
-	}
-
-	if len(hec.messages) != 1 {
-		t.Fatal("Only one message should be sent")
-	}
-
-	message := hec.messages[0]
-	if event, err := message.EventAsMap(); err != nil {
-		t.Fatal(err)
-	} else {
-		if event["line"] != "message1" {
-			t.Fatalf("Unexpected event in message %v", event)
-		}
-	}
-
-	err = hec.Close()
-	if err != nil {
-		t.Fatal(err)
-	}
-}
-
-func TestDeadlockOnBlockedEndpoint(t *testing.T) {
-	hec := NewHTTPEventCollectorMock(t)
-	go hec.Serve()
-	info := logger.Info{
-		Config: map[string]string{
-			splunkURLKey:   hec.URL(),
-			splunkTokenKey: hec.token,
-		},
-		ContainerID:        "containeriid",
-		ContainerName:      "/container_name",
-		ContainerImageID:   "contaimageid",
-		ContainerImageName: "container_image_name",
-	}
-
-	l, err := New(info)
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	ctx, unblock := context.WithCancel(context.Background())
-	hec.withBlock(ctx)
-	defer unblock()
-
-	batchSendTimeout = 1 * time.Second
-
-	if err := l.Log(&logger.Message{}); err != nil {
-		t.Fatal(err)
-	}
-
-	done := make(chan struct{})
-	go func() {
-		l.Close()
-		close(done)
-	}()
-
-	select {
-	case <-time.After(60 * time.Second):
-		buf := make([]byte, 1e6)
-		buf = buf[:runtime.Stack(buf, true)]
-		t.Logf("STACK DUMP: \n\n%s\n\n", string(buf))
-		t.Fatal("timeout waiting for close to finish")
-	case <-done:
-	}
-}
diff --git a/components/engine/daemon/logger/splunk/splunkhecmock_test.go b/components/engine/daemon/logger/splunk/splunkhecmock_test.go
deleted file mode 100644
index a3a83ac..0000000
--- a/components/engine/daemon/logger/splunk/splunkhecmock_test.go
+++ /dev/null
@@ -1,182 +0,0 @@
-package splunk // import "github.com/docker/docker/daemon/logger/splunk"
-
-import (
-	"compress/gzip"
-	"context"
-	"encoding/json"
-	"fmt"
-	"io"
-	"io/ioutil"
-	"net"
-	"net/http"
-	"sync"
-	"testing"
-)
-
-func (message *splunkMessage) EventAsString() (string, error) {
-	if val, ok := message.Event.(string); ok {
-		return val, nil
-	}
-	return "", fmt.Errorf("Cannot cast Event %v to string", message.Event)
-}
-
-func (message *splunkMessage) EventAsMap() (map[string]interface{}, error) {
-	if val, ok := message.Event.(map[string]interface{}); ok {
-		return val, nil
-	}
-	return nil, fmt.Errorf("Cannot cast Event %v to map", message.Event)
-}
-
-type HTTPEventCollectorMock struct {
-	tcpAddr     *net.TCPAddr
-	tcpListener *net.TCPListener
-
-	mu                  sync.Mutex
-	token               string
-	simulateServerError bool
-	blockingCtx         context.Context
-
-	test *testing.T
-
-	connectionVerified bool
-	gzipEnabled        *bool
-	messages           []*splunkMessage
-	numOfRequests      int
-}
-
-func NewHTTPEventCollectorMock(t *testing.T) *HTTPEventCollectorMock {
-	tcpAddr := &net.TCPAddr{IP: []byte{127, 0, 0, 1}, Port: 0, Zone: ""}
-	tcpListener, err := net.ListenTCP("tcp", tcpAddr)
-	if err != nil {
-		t.Fatal(err)
-	}
-	return &HTTPEventCollectorMock{
-		tcpAddr:             tcpAddr,
-		tcpListener:         tcpListener,
-		token:               "4642492F-D8BD-47F1-A005-0C08AE4657DF",
-		simulateServerError: false,
-		test:                t,
-		connectionVerified:  false}
-}
-
-func (hec *HTTPEventCollectorMock) simulateErr(b bool) {
-	hec.mu.Lock()
-	hec.simulateServerError = b
-	hec.mu.Unlock()
-}
-
-func (hec *HTTPEventCollectorMock) withBlock(ctx context.Context) {
-	hec.mu.Lock()
-	hec.blockingCtx = ctx
-	hec.mu.Unlock()
-}
-
-func (hec *HTTPEventCollectorMock) URL() string {
-	return "http://" + hec.tcpListener.Addr().String()
-}
-
-func (hec *HTTPEventCollectorMock) Serve() error {
-	return http.Serve(hec.tcpListener, hec)
-}
-
-func (hec *HTTPEventCollectorMock) Close() error {
-	return hec.tcpListener.Close()
-}
-
-func (hec *HTTPEventCollectorMock) ServeHTTP(writer http.ResponseWriter, request *http.Request) {
-	var err error
-
-	hec.numOfRequests++
-
-	hec.mu.Lock()
-	simErr := hec.simulateServerError
-	ctx := hec.blockingCtx
-	hec.mu.Unlock()
-
-	if ctx != nil {
-		<-hec.blockingCtx.Done()
-	}
-
-	if simErr {
-		if request.Body != nil {
-			defer request.Body.Close()
-		}
-		writer.WriteHeader(http.StatusInternalServerError)
-		return
-	}
-
-	switch request.Method {
-	case http.MethodOptions:
-		// Verify that options method is getting called only once
-		if hec.connectionVerified {
-			hec.test.Errorf("Connection should not be verified more than once. Got second request with %s method.", request.Method)
-		}
-		hec.connectionVerified = true
-		writer.WriteHeader(http.StatusOK)
-	case http.MethodPost:
-		// Always verify that Driver is using correct path to HEC
-		if request.URL.String() != "/services/collector/event/1.0" {
-			hec.test.Errorf("Unexpected path %v", request.URL)
-		}
-		defer request.Body.Close()
-
-		if authorization, ok := request.Header["Authorization"]; !ok || authorization[0] != ("Splunk "+hec.token) {
-			hec.test.Error("Authorization header is invalid.")
-		}
-
-		gzipEnabled := false
-		if contentEncoding, ok := request.Header["Content-Encoding"]; ok && contentEncoding[0] == "gzip" {
-			gzipEnabled = true
-		}
-
-		if hec.gzipEnabled == nil {
-			hec.gzipEnabled = &gzipEnabled
-		} else if gzipEnabled != *hec.gzipEnabled {
-			// Nothing wrong with that, but we just know that Splunk Logging Driver does not do that
-			hec.test.Error("Driver should not change Content Encoding.")
-		}
-
-		var gzipReader *gzip.Reader
-		var reader io.Reader
-		if gzipEnabled {
-			gzipReader, err = gzip.NewReader(request.Body)
-			if err != nil {
-				hec.test.Fatal(err)
-			}
-			reader = gzipReader
-		} else {
-			reader = request.Body
-		}
-
-		// Read body
-		var body []byte
-		body, err = ioutil.ReadAll(reader)
-		if err != nil {
-			hec.test.Fatal(err)
-		}
-
-		// Parse message
-		messageStart := 0
-		for i := 0; i < len(body); i++ {
-			if i == len(body)-1 || (body[i] == '}' && body[i+1] == '{') {
-				var message splunkMessage
-				err = json.Unmarshal(body[messageStart:i+1], &message)
-				if err != nil {
-					hec.test.Log(string(body[messageStart : i+1]))
-					hec.test.Fatal(err)
-				}
-				hec.messages = append(hec.messages, &message)
-				messageStart = i + 1
-			}
-		}
-
-		if gzipEnabled {
-			gzipReader.Close()
-		}
-
-		writer.WriteHeader(http.StatusOK)
-	default:
-		hec.test.Errorf("Unexpected HTTP method %s", http.MethodOptions)
-		writer.WriteHeader(http.StatusBadRequest)
-	}
-}
diff --git a/components/engine/daemon/logger/syslog/syslog.go b/components/engine/daemon/logger/syslog/syslog.go
deleted file mode 100644
index 61f9f14..0000000
--- a/components/engine/daemon/logger/syslog/syslog.go
+++ /dev/null
@@ -1,266 +0,0 @@
-// Package syslog provides the logdriver for forwarding server logs to syslog endpoints.
-package syslog // import "github.com/docker/docker/daemon/logger/syslog"
-
-import (
-	"crypto/tls"
-	"errors"
-	"fmt"
-	"net"
-	"net/url"
-	"os"
-	"strconv"
-	"strings"
-	"time"
-
-	syslog "github.com/RackSec/srslog"
-
-	"github.com/docker/docker/daemon/logger"
-	"github.com/docker/docker/daemon/logger/loggerutils"
-	"github.com/docker/docker/pkg/urlutil"
-	"github.com/docker/go-connections/tlsconfig"
-	"github.com/sirupsen/logrus"
-)
-
-const (
-	name        = "syslog"
-	secureProto = "tcp+tls"
-)
-
-var facilities = map[string]syslog.Priority{
-	"kern":     syslog.LOG_KERN,
-	"user":     syslog.LOG_USER,
-	"mail":     syslog.LOG_MAIL,
-	"daemon":   syslog.LOG_DAEMON,
-	"auth":     syslog.LOG_AUTH,
-	"syslog":   syslog.LOG_SYSLOG,
-	"lpr":      syslog.LOG_LPR,
-	"news":     syslog.LOG_NEWS,
-	"uucp":     syslog.LOG_UUCP,
-	"cron":     syslog.LOG_CRON,
-	"authpriv": syslog.LOG_AUTHPRIV,
-	"ftp":      syslog.LOG_FTP,
-	"local0":   syslog.LOG_LOCAL0,
-	"local1":   syslog.LOG_LOCAL1,
-	"local2":   syslog.LOG_LOCAL2,
-	"local3":   syslog.LOG_LOCAL3,
-	"local4":   syslog.LOG_LOCAL4,
-	"local5":   syslog.LOG_LOCAL5,
-	"local6":   syslog.LOG_LOCAL6,
-	"local7":   syslog.LOG_LOCAL7,
-}
-
-type syslogger struct {
-	writer *syslog.Writer
-}
-
-func init() {
-	if err := logger.RegisterLogDriver(name, New); err != nil {
-		logrus.Fatal(err)
-	}
-	if err := logger.RegisterLogOptValidator(name, ValidateLogOpt); err != nil {
-		logrus.Fatal(err)
-	}
-}
-
-// rsyslog uses appname part of syslog message to fill in an %syslogtag% template
-// attribute in rsyslog.conf. In order to be backward compatible to rfc3164
-// tag will be also used as an appname
-func rfc5424formatterWithAppNameAsTag(p syslog.Priority, hostname, tag, content string) string {
-	timestamp := time.Now().Format(time.RFC3339)
-	pid := os.Getpid()
-	msg := fmt.Sprintf("<%d>%d %s %s %s %d %s - %s",
-		p, 1, timestamp, hostname, tag, pid, tag, content)
-	return msg
-}
-
-// The timestamp field in rfc5424 is derived from rfc3339. Whereas rfc3339 makes allowances
-// for multiple syntaxes, there are further restrictions in rfc5424, i.e., the maximum
-// resolution is limited to "TIME-SECFRAC" which is 6 (microsecond resolution)
-func rfc5424microformatterWithAppNameAsTag(p syslog.Priority, hostname, tag, content string) string {
-	timestamp := time.Now().Format("2006-01-02T15:04:05.000000Z07:00")
-	pid := os.Getpid()
-	msg := fmt.Sprintf("<%d>%d %s %s %s %d %s - %s",
-		p, 1, timestamp, hostname, tag, pid, tag, content)
-	return msg
-}
-
-// New creates a syslog logger using the configuration passed in on
-// the context. Supported context configuration variables are
-// syslog-address, syslog-facility, syslog-format.
-func New(info logger.Info) (logger.Logger, error) {
-	tag, err := loggerutils.ParseLogTag(info, loggerutils.DefaultTemplate)
-	if err != nil {
-		return nil, err
-	}
-
-	proto, address, err := parseAddress(info.Config["syslog-address"])
-	if err != nil {
-		return nil, err
-	}
-
-	facility, err := parseFacility(info.Config["syslog-facility"])
-	if err != nil {
-		return nil, err
-	}
-
-	syslogFormatter, syslogFramer, err := parseLogFormat(info.Config["syslog-format"], proto)
-	if err != nil {
-		return nil, err
-	}
-
-	var log *syslog.Writer
-	if proto == secureProto {
-		tlsConfig, tlsErr := parseTLSConfig(info.Config)
-		if tlsErr != nil {
-			return nil, tlsErr
-		}
-		log, err = syslog.DialWithTLSConfig(proto, address, facility, tag, tlsConfig)
-	} else {
-		log, err = syslog.Dial(proto, address, facility, tag)
-	}
-
-	if err != nil {
-		return nil, err
-	}
-
-	log.SetFormatter(syslogFormatter)
-	log.SetFramer(syslogFramer)
-
-	return &syslogger{
-		writer: log,
-	}, nil
-}
-
-func (s *syslogger) Log(msg *logger.Message) error {
-	line := string(msg.Line)
-	source := msg.Source
-	logger.PutMessage(msg)
-	if source == "stderr" {
-		return s.writer.Err(line)
-	}
-	return s.writer.Info(line)
-}
-
-func (s *syslogger) Close() error {
-	return s.writer.Close()
-}
-
-func (s *syslogger) Name() string {
-	return name
-}
-
-func parseAddress(address string) (string, string, error) {
-	if address == "" {
-		return "", "", nil
-	}
-	if !urlutil.IsTransportURL(address) {
-		return "", "", fmt.Errorf("syslog-address should be in form proto://address, got %v", address)
-	}
-	url, err := url.Parse(address)
-	if err != nil {
-		return "", "", err
-	}
-
-	// unix and unixgram socket validation
-	if url.Scheme == "unix" || url.Scheme == "unixgram" {
-		if _, err := os.Stat(url.Path); err != nil {
-			return "", "", err
-		}
-		return url.Scheme, url.Path, nil
-	}
-
-	// here we process tcp|udp
-	host := url.Host
-	if _, _, err := net.SplitHostPort(host); err != nil {
-		if !strings.Contains(err.Error(), "missing port in address") {
-			return "", "", err
-		}
-		host = host + ":514"
-	}
-
-	return url.Scheme, host, nil
-}
-
-// ValidateLogOpt looks for syslog specific log options
-// syslog-address, syslog-facility.
-func ValidateLogOpt(cfg map[string]string) error {
-	for key := range cfg {
-		switch key {
-		case "env":
-		case "env-regex":
-		case "labels":
-		case "syslog-address":
-		case "syslog-facility":
-		case "syslog-tls-ca-cert":
-		case "syslog-tls-cert":
-		case "syslog-tls-key":
-		case "syslog-tls-skip-verify":
-		case "tag":
-		case "syslog-format":
-		default:
-			return fmt.Errorf("unknown log opt '%s' for syslog log driver", key)
-		}
-	}
-	if _, _, err := parseAddress(cfg["syslog-address"]); err != nil {
-		return err
-	}
-	if _, err := parseFacility(cfg["syslog-facility"]); err != nil {
-		return err
-	}
-	if _, _, err := parseLogFormat(cfg["syslog-format"], ""); err != nil {
-		return err
-	}
-	return nil
-}
-
-func parseFacility(facility string) (syslog.Priority, error) {
-	if facility == "" {
-		return syslog.LOG_DAEMON, nil
-	}
-
-	if syslogFacility, valid := facilities[facility]; valid {
-		return syslogFacility, nil
-	}
-
-	fInt, err := strconv.Atoi(facility)
-	if err == nil && 0 <= fInt && fInt <= 23 {
-		return syslog.Priority(fInt << 3), nil
-	}
-
-	return syslog.Priority(0), errors.New("invalid syslog facility")
-}
-
-func parseTLSConfig(cfg map[string]string) (*tls.Config, error) {
-	_, skipVerify := cfg["syslog-tls-skip-verify"]
-
-	opts := tlsconfig.Options{
-		CAFile:             cfg["syslog-tls-ca-cert"],
-		CertFile:           cfg["syslog-tls-cert"],
-		KeyFile:            cfg["syslog-tls-key"],
-		InsecureSkipVerify: skipVerify,
-	}
-
-	return tlsconfig.Client(opts)
-}
-
-func parseLogFormat(logFormat, proto string) (syslog.Formatter, syslog.Framer, error) {
-	switch logFormat {
-	case "":
-		return syslog.UnixFormatter, syslog.DefaultFramer, nil
-	case "rfc3164":
-		return syslog.RFC3164Formatter, syslog.DefaultFramer, nil
-	case "rfc5424":
-		if proto == secureProto {
-			return rfc5424formatterWithAppNameAsTag, syslog.RFC5425MessageLengthFramer, nil
-		}
-		return rfc5424formatterWithAppNameAsTag, syslog.DefaultFramer, nil
-	case "rfc5424micro":
-		if proto == secureProto {
-			return rfc5424microformatterWithAppNameAsTag, syslog.RFC5425MessageLengthFramer, nil
-		}
-		return rfc5424microformatterWithAppNameAsTag, syslog.DefaultFramer, nil
-	default:
-		return nil, nil, errors.New("Invalid syslog format")
-	}
-
-}
diff --git a/components/engine/daemon/logger/syslog/syslog_test.go b/components/engine/daemon/logger/syslog/syslog_test.go
deleted file mode 100644
index ea531a2..0000000
--- a/components/engine/daemon/logger/syslog/syslog_test.go
+++ /dev/null
@@ -1,159 +0,0 @@
-package syslog // import "github.com/docker/docker/daemon/logger/syslog"
-
-import (
-	"net"
-	"reflect"
-	"testing"
-
-	syslog "github.com/RackSec/srslog"
-)
-
-func functionMatches(expectedFun interface{}, actualFun interface{}) bool {
-	return reflect.ValueOf(expectedFun).Pointer() == reflect.ValueOf(actualFun).Pointer()
-}
-
-func TestParseLogFormat(t *testing.T) {
-	formatter, framer, err := parseLogFormat("rfc5424", "udp")
-	if err != nil || !functionMatches(rfc5424formatterWithAppNameAsTag, formatter) ||
-		!functionMatches(syslog.DefaultFramer, framer) {
-		t.Fatal("Failed to parse rfc5424 format", err, formatter, framer)
-	}
-
-	formatter, framer, err = parseLogFormat("rfc5424", "tcp+tls")
-	if err != nil || !functionMatches(rfc5424formatterWithAppNameAsTag, formatter) ||
-		!functionMatches(syslog.RFC5425MessageLengthFramer, framer) {
-		t.Fatal("Failed to parse rfc5424 format", err, formatter, framer)
-	}
-
-	formatter, framer, err = parseLogFormat("rfc5424micro", "udp")
-	if err != nil || !functionMatches(rfc5424microformatterWithAppNameAsTag, formatter) ||
-		!functionMatches(syslog.DefaultFramer, framer) {
-		t.Fatal("Failed to parse rfc5424 (microsecond) format", err, formatter, framer)
-	}
-
-	formatter, framer, err = parseLogFormat("rfc5424micro", "tcp+tls")
-	if err != nil || !functionMatches(rfc5424microformatterWithAppNameAsTag, formatter) ||
-		!functionMatches(syslog.RFC5425MessageLengthFramer, framer) {
-		t.Fatal("Failed to parse rfc5424 (microsecond) format", err, formatter, framer)
-	}
-
-	formatter, framer, err = parseLogFormat("rfc3164", "")
-	if err != nil || !functionMatches(syslog.RFC3164Formatter, formatter) ||
-		!functionMatches(syslog.DefaultFramer, framer) {
-		t.Fatal("Failed to parse rfc3164 format", err, formatter, framer)
-	}
-
-	formatter, framer, err = parseLogFormat("", "")
-	if err != nil || !functionMatches(syslog.UnixFormatter, formatter) ||
-		!functionMatches(syslog.DefaultFramer, framer) {
-		t.Fatal("Failed to parse empty format", err, formatter, framer)
-	}
-
-	formatter, framer, err = parseLogFormat("invalid", "")
-	if err == nil {
-		t.Fatal("Failed to parse invalid format", err, formatter, framer)
-	}
-}
-
-func TestValidateLogOptEmpty(t *testing.T) {
-	emptyConfig := make(map[string]string)
-	if err := ValidateLogOpt(emptyConfig); err != nil {
-		t.Fatal("Failed to parse empty config", err)
-	}
-}
-
-func TestValidateSyslogAddress(t *testing.T) {
-	err := ValidateLogOpt(map[string]string{
-		"syslog-address": "this is not an uri",
-	})
-	if err == nil {
-		t.Fatal("Expected error with invalid uri")
-	}
-
-	// File exists
-	err = ValidateLogOpt(map[string]string{
-		"syslog-address": "unix:///",
-	})
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	// File does not exist
-	err = ValidateLogOpt(map[string]string{
-		"syslog-address": "unix:///does_not_exist",
-	})
-	if err == nil {
-		t.Fatal("Expected error when address is non existing file")
-	}
-
-	// accepts udp and tcp URIs
-	err = ValidateLogOpt(map[string]string{
-		"syslog-address": "udp://1.2.3.4",
-	})
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	err = ValidateLogOpt(map[string]string{
-		"syslog-address": "tcp://1.2.3.4",
-	})
-	if err != nil {
-		t.Fatal(err)
-	}
-}
-
-func TestParseAddressDefaultPort(t *testing.T) {
-	_, address, err := parseAddress("tcp://1.2.3.4")
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	_, port, _ := net.SplitHostPort(address)
-	if port != "514" {
-		t.Fatalf("Expected to default to port 514. It used port %s", port)
-	}
-}
-
-func TestValidateSyslogFacility(t *testing.T) {
-	err := ValidateLogOpt(map[string]string{
-		"syslog-facility": "Invalid facility",
-	})
-	if err == nil {
-		t.Fatal("Expected error if facility level is invalid")
-	}
-}
-
-func TestValidateLogOptSyslogFormat(t *testing.T) {
-	err := ValidateLogOpt(map[string]string{
-		"syslog-format": "Invalid format",
-	})
-	if err == nil {
-		t.Fatal("Expected error if format is invalid")
-	}
-}
-
-func TestValidateLogOpt(t *testing.T) {
-	err := ValidateLogOpt(map[string]string{
-		"env":                    "http://127.0.0.1",
-		"env-regex":              "abc",
-		"labels":                 "labelA",
-		"syslog-address":         "udp://1.2.3.4:1111",
-		"syslog-facility":        "daemon",
-		"syslog-tls-ca-cert":     "/etc/ca-certificates/custom/ca.pem",
-		"syslog-tls-cert":        "/etc/ca-certificates/custom/cert.pem",
-		"syslog-tls-key":         "/etc/ca-certificates/custom/key.pem",
-		"syslog-tls-skip-verify": "true",
-		"tag":                    "true",
-		"syslog-format":          "rfc3164",
-	})
-	if err != nil {
-		t.Fatal(err)
-	}
-
-	err = ValidateLogOpt(map[string]string{
-		"not-supported-option": "a",
-	})
-	if err == nil {
-		t.Fatal("Expecting error on unsupported options")
-	}
-}
